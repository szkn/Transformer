{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyRQwYrEYTpv"
   },
   "source": [
    "# 修士論文実験 2022/01/10\n",
    "## マルチモーダルに挑戦\n",
    "## (validationが簡単に行えるようにデータセットを操作するモジュールを拡充)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 843,
     "status": "ok",
     "timestamp": 1636987406075,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "dO5GxI7RzXIc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# sys.path.append(os.path.abspath(\"..\"))\n",
    "# import scripts.compensate\n",
    "# import scripts.kinectImg2video\n",
    "# from scripts.conpemsate_suppresser import *\n",
    "# from scripts.ground_angle_analysis import ground_shoulder_angle_analyzer\n",
    "# import scripts.ground_angle_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日付の追加\n",
    "df_annotate = pd.read_excel(\"annotate_dataset.xlsx\")\n",
    "df_annotate['date'] = pd.to_datetime(df_annotate['date'], format='%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>uid</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>point</th>\n",
       "      <th>shoulder</th>\n",
       "      <th>body</th>\n",
       "      <th>flag_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-06 18:56:20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-06 18:56:20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-06 18:56:41</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-06 18:56:41</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-06 18:56:58</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  uid  subject_id  task_id point  shoulder  body  \\\n",
       "0 2021-12-06 18:56:20    1           1        1     3         0     0   \n",
       "1 2021-12-06 18:56:20    2           1        1     4         0     0   \n",
       "2 2021-12-06 18:56:41    3           1        1     3         0     0   \n",
       "3 2021-12-06 18:56:41    4           1        1     4         0     0   \n",
       "4 2021-12-06 18:56:58    5           1        1     3         0     0   \n",
       "\n",
       "   flag_usage  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           2  \n",
       "4           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>x_Pelvis</th>\n",
       "      <th>y_Pelvis</th>\n",
       "      <th>z_Pelvis</th>\n",
       "      <th>x_SpineNaval</th>\n",
       "      <th>y_SpineNaval</th>\n",
       "      <th>z_SpineNaval</th>\n",
       "      <th>x_SpineChest</th>\n",
       "      <th>...</th>\n",
       "      <th>x_REar</th>\n",
       "      <th>y_REar</th>\n",
       "      <th>z_REar</th>\n",
       "      <th>N</th>\n",
       "      <th>v_RWrist</th>\n",
       "      <th>z_v_RWrist</th>\n",
       "      <th>flag_active</th>\n",
       "      <th>flag_moving</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-158.973129</td>\n",
       "      <td>353.261841</td>\n",
       "      <td>698.233093</td>\n",
       "      <td>-149.886017</td>\n",
       "      <td>218.100922</td>\n",
       "      <td>780.778748</td>\n",
       "      <td>-142.035919</td>\n",
       "      <td>...</td>\n",
       "      <td>-178.933960</td>\n",
       "      <td>-236.272278</td>\n",
       "      <td>842.268127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.917988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-156.911919</td>\n",
       "      <td>356.031863</td>\n",
       "      <td>697.378637</td>\n",
       "      <td>-147.957493</td>\n",
       "      <td>219.063530</td>\n",
       "      <td>781.238292</td>\n",
       "      <td>-142.348493</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.788628</td>\n",
       "      <td>-241.853940</td>\n",
       "      <td>862.009244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.131710</td>\n",
       "      <td>0.480634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.891892</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-157.406120</td>\n",
       "      <td>356.970863</td>\n",
       "      <td>697.867036</td>\n",
       "      <td>-148.184343</td>\n",
       "      <td>219.214968</td>\n",
       "      <td>781.799317</td>\n",
       "      <td>-142.899719</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.093690</td>\n",
       "      <td>-243.703880</td>\n",
       "      <td>867.831643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.690953</td>\n",
       "      <td>0.198082</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.783784</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-159.493486</td>\n",
       "      <td>356.687710</td>\n",
       "      <td>699.214911</td>\n",
       "      <td>-149.753131</td>\n",
       "      <td>218.849632</td>\n",
       "      <td>782.412353</td>\n",
       "      <td>-143.553739</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.457427</td>\n",
       "      <td>-243.071735</td>\n",
       "      <td>864.096621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.280899</td>\n",
       "      <td>0.313779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.675676</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-162.211771</td>\n",
       "      <td>355.791270</td>\n",
       "      <td>700.938883</td>\n",
       "      <td>-151.850422</td>\n",
       "      <td>218.261918</td>\n",
       "      <td>783.027933</td>\n",
       "      <td>-144.174692</td>\n",
       "      <td>...</td>\n",
       "      <td>-177.488121</td>\n",
       "      <td>-241.207140</td>\n",
       "      <td>855.165480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.247976</td>\n",
       "      <td>0.307322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.567568</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1   id    x_Pelvis    y_Pelvis    z_Pelvis  \\\n",
       "0           0             0  1.0 -158.973129  353.261841  698.233093   \n",
       "1           1             1  1.0 -156.911919  356.031863  697.378637   \n",
       "2           2             2  1.0 -157.406120  356.970863  697.867036   \n",
       "3           3             3  1.0 -159.493486  356.687710  699.214911   \n",
       "4           4             4  1.0 -162.211771  355.791270  700.938883   \n",
       "\n",
       "   x_SpineNaval  y_SpineNaval  z_SpineNaval  x_SpineChest  ...      x_REar  \\\n",
       "0   -149.886017    218.100922    780.778748   -142.035919  ... -178.933960   \n",
       "1   -147.957493    219.063530    781.238292   -142.348493  ... -176.788628   \n",
       "2   -148.184343    219.214968    781.799317   -142.899719  ... -176.093690   \n",
       "3   -149.753131    218.849632    782.412353   -143.553739  ... -176.457427   \n",
       "4   -151.850422    218.261918    783.027933   -144.174692  ... -177.488121   \n",
       "\n",
       "       y_REar      z_REar   N  v_RWrist  z_v_RWrist  flag_active  flag_moving  \\\n",
       "0 -236.272278  842.268127 NaN       NaN   -0.917988          0.0          1.0   \n",
       "1 -241.853940  862.009244 NaN  7.131710    0.480634          1.0          1.0   \n",
       "2 -243.703880  867.831643 NaN  5.690953    0.198082          1.0          1.0   \n",
       "3 -243.071735  864.096621 NaN  6.280899    0.313779          1.0          1.0   \n",
       "4 -241.207140  855.165480 NaN  6.247976    0.307322          1.0          1.0   \n",
       "\n",
       "    timestamp                date  \n",
       "0    0.000000 2021-12-04 18:20:18  \n",
       "1   39.891892 2021-12-04 18:20:18  \n",
       "2   79.783784 2021-12-04 18:20:18  \n",
       "3  119.675676 2021-12-04 18:20:18  \n",
       "4  159.567568 2021-12-04 18:20:18  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataSetの呼び出し\n",
    "df_data = pd.read_csv(\"bigdata_trimmed.csv\")\n",
    "df_data['date'] = pd.to_datetime(df_data['date'], format='%Y-%m-%d-%H-%M-%S')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1636987406076,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "GZlVgJy1zXIc"
   },
   "outputs": [],
   "source": [
    "# pd_merged = pd.merge(df_annotate, df_data, on='date', how='inner')\n",
    "# pd_3 = pd_merged[pd_merged['point'] == 3]\n",
    "# pd_2A = pd_merged[pd_merged['point'] == '2A']\n",
    "# pd_2B = pd_merged[pd_merged['point'] == '2B']\n",
    "# pd_2C = pd_merged[pd_merged['point'] == '2C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### このデータセットはGraspのものかつ，usageが1のものが取り出されている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# データセットにNN入力用のスコアを割り振る．\n",
    "# これが正解ラベルになる\n",
    "dataset = pd.merge(df_annotate, df_data, on='date', how='inner')\n",
    "\n",
    "dataset = dataset[(dataset['task_id'] == 1) & (dataset['flag_usage'] == 1)]\n",
    "dataset['point'] = dataset['point'].astype(str)\n",
    "dataset.loc[dataset['point'] == '3', 'score'] = 3\n",
    "dataset.loc[dataset['point'] == '2A', 'score'] = 2\n",
    "dataset.loc[dataset['point'] == '2B', 'score'] = 1\n",
    "dataset.loc[dataset['point'] == '2C', 'score'] = 0\n",
    "print(dataset['score'].max())\n",
    "\n",
    "# Nanのものを削除\n",
    "dataset.dropna(subset=['score'], inplace=True)\n",
    "# scoreの行をintにする\n",
    "dataset['score'] = dataset['score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['uid'].unique()\n",
    "dataset['date'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grasp動作だけを抜き出す\n",
    "# dataset_grasp = dataset[dataset['task_id'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RElbow2RWrist と Rshoulder2RElbow と Pelvis2RShoulder と Pelvis2Neck の速度を入れてみる "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_annotate\n",
    "# l_date = df_annotate['date'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vector(df, joint1, joint2, word=\"\"):\n",
    "    df[f\"{word}_x_{joint1}2{joint2}\"] = df[f\"x_{joint1}\"].astype('float64') - df[f\"x_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_y_{joint1}2{joint2}\"] = df[f\"y_{joint1}\"].astype('float64') - df[f\"y_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_z_{joint1}2{joint2}\"] = df[f\"z_{joint1}\"].astype('float64') - df[f\"z_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_ave_{joint1}2{joint2}\"] = (df[f\"{word}_x_{joint1}2{joint2}\"] + df[f\"{word}_y_{joint1}2{joint2}\"] + df[f\"{word}_z_{joint1}2{joint2}\"])/3\n",
    "    return df\n",
    "\n",
    "def calc_angle(df, joint1, joint2, joint3):\n",
    "    l_theta = []\n",
    "    # 角度を算出する関数。p2を支点として、他の二点間の角度を算出する。\n",
    "    x1, y1 ,z1= df[f\"x_{joint1}\"].astype('float64'), df[f\"y_{joint1}\"].astype('float64'), df[f\"z_{joint1}\"].astype('float64')\n",
    "    x2, y2 ,z2= df[f\"x_{joint2}\"].astype('float64'), df[f\"y_{joint2}\"].astype('float64'), df[f\"z_{joint2}\"].astype('float64')\n",
    "    x3, y3 ,z3= df[f\"x_{joint3}\"].astype('float64'), df[f\"y_{joint3}\"].astype('float64'), df[f\"z_{joint3}\"].astype('float64')\n",
    "    v1 = np.array([x1-x2, y1-y2, z1-z2])\n",
    "    v2 = np.array([x3-x2, y3-y2, z3-z2])\n",
    "    for i in range(v1.shape[1]):\n",
    "        cos = np.dot(v1[:,i], v2[:,i])/(np.linalg.norm(v1[:,i], ord=2) * np.linalg.norm(v2[:,i], ord=2))\n",
    "        theta = np.degrees(math.acos(cos))\n",
    "        l_theta.append(theta)\n",
    "    return np.array(l_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 角度と角度の速度を入力とする\n",
    "angle_RElbow = calc_angle(dataset, 'RShoulder', 'RElbow', 'RWrist')\n",
    "diff_angle_RElbow = np.diff(angle_RElbow)\n",
    "\n",
    "angle_RShoulder = calc_angle(dataset, 'RElbow', 'RShoulder', 'Neck')\n",
    "diff_angle_RShoulder = np.diff(angle_RShoulder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_date_name = np.array(dataset['date'].unique())\n",
    "# l = []\n",
    "# for date in l_date_name:\n",
    "#     score = dataset[dataset[\"date\"] == date]['score'].mode()\n",
    "#     l.append(score)\n",
    "# return np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解ラベルで用いるyのone hotベクトルを作成\n",
    "def extract_y(df, augment_flag=False, rate_augment=10):\n",
    "    l = []\n",
    "    l_date_name = np.array(df['date'].unique())\n",
    "    for date in l_date_name:\n",
    "        score = df[df[\"date\"] == date]['score'].mode()\n",
    "        l.append(score)\n",
    "        if augment_flag:\n",
    "            for i in range(rate_augment):\n",
    "                l.append(score)\n",
    "    y = np.array(l).flatten()\n",
    "    \n",
    "    # l_date_name = np.array(df['date'].unique())\n",
    "    # y = np.array(df[\"score\"]) #一番多いものをscoreとして最後にyとして返す\n",
    "    # y_arr = np.ones(l_date_name.shape)\n",
    "    # y_arr = y_arr * y\n",
    "    return y\n",
    "\n",
    "def interpolate1(array, length=100):\n",
    "    x_old = np.linspace(0, 1, array.shape[0])\n",
    "    y_old = array\n",
    "    \n",
    "    f = interpolate.interp1d(x_old, y_old)\n",
    "\n",
    "    x = np.linspace(0, 1, length)\n",
    "    y_new = f(x)\n",
    "    return y_new\n",
    "\n",
    "def zscore(x, axis = 1):\n",
    "    xmean = x.mean(axis=axis, keepdims=True)\n",
    "    xstd  = np.std(x, axis=axis, keepdims=True)\n",
    "    zscore = (x-xmean)/xstd\n",
    "    return zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xの系列を入力とすると，rateのものを10倍作成して返す\n",
    "def augmentation(arr_data, rate=0.8, num_arr=10, origin_length=100):\n",
    "    #まず100個に補間 shape:(100, num_feature)\n",
    "    interpolate = interpolate_one_sample(arr_data)\n",
    "    interpolate = interpolate.reshape(interpolate.shape[1], -1)\n",
    "    \n",
    "    num_data = origin_length * rate #実際に用いるデータ点列\n",
    "    \n",
    "    for i in range(num_arr):\n",
    "        first_idx = round( i/num_arr * origin_length * (1-rate))\n",
    "        end_idx = round( i/num_arr * origin_length * (1-rate) + origin_length * rate )\n",
    "        # print(f\"first index is {first_idx}, end index is {end_idx}\")\n",
    "        one_trimmed = interpolate[first_idx:end_idx, :]\n",
    "        one_arr = interpolate_one_sample(one_trimmed)\n",
    "        if i == 0:\n",
    "                x = one_arr #(1, 100, num_feature)\n",
    "        else:\n",
    "            x = np.concatenate([x, one_arr],0)\n",
    "    return x # (num_arr, 100, num_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_one_sample(arr_data):\n",
    "    num_feature = arr_data.shape[1]\n",
    "    for i in range(num_feature):\n",
    "            tmp_interpolate = interpolate1(arr_data[:, i])\n",
    "            #3次元に拡張\n",
    "            origin = tmp_interpolate.reshape(1, tmp_interpolate.shape[0], 1)\n",
    "            \n",
    "            if i == 0:\n",
    "                x = origin\n",
    "            else:\n",
    "                # print(f\"x shape is {x.shape}, \")\n",
    "                x = np.concatenate([x, origin],2)\n",
    "    return x #(1, 100, num_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# この関数を実行しさえすればデータセットが作成される\n",
    "def create_Xy(dataset, augment_flag=False, rate_augment=5, rate=0.9):\n",
    "    #正解ラベルの作成\n",
    "    y = extract_y(dataset, augment_flag, rate_augment=rate_augment)\n",
    "    X = None\n",
    "    \n",
    "    # Xの作成\n",
    "    l_date_name = np.array(dataset['date'].unique())\n",
    "    for k, date in enumerate(l_date_name):\n",
    "        #一連のデータ，1サンプル\n",
    "        series = dataset[dataset['date'] == l_date_name[k]]\n",
    "        series.drop(columns='point', inplace=True)\n",
    "        series.drop(columns='date', inplace=True)\n",
    "        #差分ベクトルを取得\n",
    "        diff = series.diff()\n",
    "        diff.fillna(0, inplace=True)\n",
    "\n",
    "        # 間接点同士のベクトルのカラムをデータフレームに追加\n",
    "        # これらがデータセットになる\n",
    "        diff = add_vector(diff, 'RElbow', \"RWrist\", 'v')\n",
    "        diff = add_vector(diff, 'RShoulder', \"RElbow\", 'v')\n",
    "        diff = add_vector(diff, 'Pelvis', \"RShoulder\", 'v')\n",
    "        diff = add_vector(diff, 'Pelvis', \"Neck\", 'v')\n",
    "        diff = add_vector(diff, 'Neck', 'RShoulder', 'v')\n",
    "        diff = add_vector(diff, 'Neck', 'LShoulder', 'v')\n",
    "        \n",
    "        # 1サンプルに関するデータ shape = (num_timestep, num_feature)\n",
    "        arr_data = diff.loc[:, \"v_x_RElbow2RWrist\":].values\n",
    "        \n",
    "        origin = interpolate_one_sample(arr_data)\n",
    "        \n",
    "        # augmentで増やす\n",
    "        # この関数の出力 (augmented_num, 100, num_feature)\n",
    "        if augment_flag:\n",
    "            augmented_arr = augmentation(arr_data, rate=rate, num_arr=rate_augment)\n",
    "            augmented_origin_arr = np.concatenate([origin, augmented_arr], 0)\n",
    "        else:\n",
    "            augmented_origin_arr = origin\n",
    "                \n",
    "        #最初だけ条件分岐\n",
    "        if k == 0:\n",
    "            out = augmented_origin_arr\n",
    "        else:\n",
    "            out = np.concatenate([out, augmented_origin_arr], axis=0)     \n",
    "    # 最後にzscore変換\n",
    "        # print(X.shape)\n",
    "    X = zscore(out)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxW659H6YTpz"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "Our model processes a tensor of shape `(batch size, sequence length, features)`,\n",
    "where `sequence length` is the number of time steps and `features` is each input\n",
    "timeseries.\n",
    "\n",
    "You can replace your classification RNN layers with this one: the\n",
    "inputs are fully compatible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urNK4ym-YTp0"
   },
   "source": [
    "We include residual connections, layer normalization, and dropout.\n",
    "The resulting layer can be stacked multiple times.\n",
    "\n",
    "The projection layers are implemented through `keras.layers.Conv1D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    '''入力された単語の位置を示すベクトル情報を付加する'''\n",
    "\n",
    "    def __init__(self, d_model=12, max_seq_len=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model  # 単語ベクトルの次元数\n",
    "\n",
    "        # 単語の順番（pos）と埋め込みベクトルの次元の位置（i）によって一意に定まる値の表をpeとして作成\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "\n",
    "        # GPUが使える場合はGPUへ送る、ここでは省略。実際に学習時には使用する\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        pe = pe.to(device)\n",
    "\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                \n",
    "                # 誤植修正_200510 #79\n",
    "                # pe[pos, i + 1] = math.cos(pos /\n",
    "                #                          (10000 ** ((2 * (i + 1))/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos /\n",
    "                                          (10000 ** ((2 * i)/d_model)))\n",
    "\n",
    "        # 表peの先頭に、ミニバッチ次元となる次元を足す\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "        # 勾配を計算しないようにする\n",
    "        self.pe.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 入力xとPositonal Encodingを足し算する\n",
    "        # xがpeよりも小さいので、大きくする\n",
    "        ret = math.sqrt(self.d_model)*x + self.pe\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # SAGANでは1dConvを使用したが、今回は全結合層で特徴量を変換する\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # 出力時に使用する全結合層\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Attentionの大きさ調整の変数\n",
    "        self.d_k = d_model\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        # 全結合層で特徴量を変換\n",
    "        k = self.k_linear(k)\n",
    "        q = self.q_linear(q)\n",
    "        v = self.v_linear(v)\n",
    "\n",
    "        # Attentionの値を計算する\n",
    "        # 各値を足し算すると大きくなりすぎるので、root(d_k)で割って調整\n",
    "        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)\n",
    "\n",
    "        # ここでmaskを計算\n",
    "        # mask = mask.unsqueeze(1)\n",
    "        # print(mask)\n",
    "        # weights = weights.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # softmaxで規格化をする\n",
    "        normlized_weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "        # AttentionをValueとかけ算\n",
    "        output = torch.matmul(normlized_weights, v)\n",
    "\n",
    "        # 全結合層で特徴量を変換\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, normlized_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
    "        '''Attention層から出力を単純に全結合層2つで特徴量を変換するだけのユニットです'''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.dropout(F.relu(x))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # LayerNormalization層\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=layernorm\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Attention層\n",
    "        self.attn = Attention(d_model)\n",
    "\n",
    "        # Attentionのあとの全結合層2つ\n",
    "        self.ff = FeedForward(d_model)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # 正規化とAttention\n",
    "        # print(f\"input shape is {x.shape}\")\n",
    "        x_normlized = self.norm_1(x)\n",
    "        output, attn_weights = self.attn(x_normlized, x_normlized, x_normlized, mask)\n",
    "        \n",
    "        x2 = x + self.dropout_1(output)\n",
    "\n",
    "        # 正規化と全結合層\n",
    "        x_normlized2 = self.norm_2(x2)\n",
    "        output = x2 + self.dropout_2(self.ff(x_normlized2))\n",
    "        # print(f\"output shape is {output.shape}\")\n",
    "\n",
    "        return output, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringHead(nn.Module):\n",
    "    '''Transformer_Blockの出力を使用して，最後にスコアリングを行う'''\n",
    "    \n",
    "    def __init__(self, d_model=300, output_dim=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # 全結合層\n",
    "        self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # 重み初期化処理\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n",
    "        weights = self.linear.weight\n",
    "        out = self.linear(x0)\n",
    "        \n",
    "        # print(f\"Scoring input shape is {x0.shape}\")\n",
    "        # print(f\"Scoring weight shape is {weights.shape}\")\n",
    "        # print(f\"Scoring output shape is {out.shape}\")\n",
    "\n",
    "        return out, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ClassificationHead(nn.Module):\n",
    "#     '''Transformer_Blockの出力を使用し、最後にクラス分類させる'''\n",
    "\n",
    "#     def __init__(self, d_model=300, output_dim=4):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # 全結合層\n",
    "#         self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n",
    "#         self.output_dim = output_dim\n",
    "\n",
    "#         # 重み初期化処理\n",
    "#         nn.init.normal_(self.linear.weight, std=0.02)\n",
    "#         nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n",
    "#         x1 = self.linear(x0)\n",
    "#         # print(x1.shape)\n",
    "#         out = F.softmax(x1, dim=-1)\n",
    "\n",
    "#         return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここで複数入力のAttentionにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 最終的なTransformerモデルのクラス\n",
    "\n",
    "# class TransformerClassification(nn.Module):\n",
    "#     '''Transformerでクラス分類させる'''\n",
    "\n",
    "#     def __init__(self, d_model=12, max_seq_len=101, output_dim=4):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # モデル構築\n",
    "#         self.net_Positional = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
    "        \n",
    "#         self.net_Attention_1 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_2 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_3 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_4 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_5 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_6 = TransformerBlock(d_model=4)\n",
    "        \n",
    "#         self.net_Attention_all = TransformerBlock(d_model=24)\n",
    "#         # self.net3_2 = TransformerBlock(d_model=d_model)\n",
    "        \n",
    "#         self.net_Classification = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
    "\n",
    "#     def forward(self, x, mask):\n",
    "#         x = self.net_Positional(x)  # Positon情報を足し算\n",
    "#         #ここでいくつのAttentionアーキテクチャを利用するか決定する\n",
    "#         # num_attention_block = x.shape[2]/4\n",
    "        \n",
    "#         x1, attn_weights_1 = self.net_Attention_1(x[:,:,0:4], mask[:,:,0:4])  # Self-Attentionで特徴量を変換\n",
    "#         x2, attn_weights_2 = self.net_Attention_2(x[:,:,4:8], mask[:,:,4:8])\n",
    "#         x3, attn_weights_3 = self.net_Attention_3(x[:,:,8:12], mask[:,:,8:12])\n",
    "#         x4, attn_weights_4 = self.net_Attention_4(x[:,:,12:16], mask[:,:,12:16])\n",
    "#         x5, attn_weights_5 = self.net_Attention_5(x[:,:,16:20], mask[:,:,16:20])\n",
    "#         x6, attn_weights_6 = self.net_Attention_6(x[:,:,20:24], mask[:,:,20:24])\n",
    "        \n",
    "#         #出力を全部つなぎ合わせる\n",
    "#         x_concat = torch.cat((x1,x2,x3,x4,x5,x6), 2)\n",
    "#         # x_attn, attn_weights_all = self.net_Attention_all(x_concat, mask)\n",
    "        \n",
    "#         x_out = self.net_Classification(x_concat)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
    "        \n",
    "#         l_attn_weights = [attn_weights_1,attn_weights_2,attn_weights_3,attn_weights_4,attn_weights_5,attn_weights_6\n",
    "#                           # , attn_weights_all\n",
    "#                          ] \n",
    "#         return x_out, l_attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的なTransformerモデルのクラス\n",
    "\n",
    "class TransformerScoring(nn.Module):\n",
    "    '''Transformerでクラス分類させる'''\n",
    "\n",
    "    def __init__(self, d_model=12, max_seq_len=101, output_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # モデル構築\n",
    "        self.net_Positional = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
    "        \n",
    "        self.net_Attention_1 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_2 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_3 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_4 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_5 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_6 = TransformerBlock(d_model=4)\n",
    "        \n",
    "        self.net_Attention_all = TransformerBlock(d_model=24)\n",
    "        # self.net3_2 = TransformerBlock(d_model=d_model)\n",
    "        \n",
    "        # self.net_Classification = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
    "        self.net_Scoring = ScoringHead(output_dim=output_dim, d_model=d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.net_Positional(x)  # Positon情報を足し算\n",
    "        #ここでいくつのAttentionアーキテクチャを利用するか決定する\n",
    "        # num_attention_block = x.shape[2]/4\n",
    "        \n",
    "        x1, attn_weights_1 = self.net_Attention_1(x[:,:,0:4], mask[:,:,0:4])  # Self-Attentionで特徴量を変換\n",
    "        x2, attn_weights_2 = self.net_Attention_2(x[:,:,4:8], mask[:,:,4:8])\n",
    "        x3, attn_weights_3 = self.net_Attention_3(x[:,:,8:12], mask[:,:,8:12])\n",
    "        x4, attn_weights_4 = self.net_Attention_4(x[:,:,12:16], mask[:,:,12:16])\n",
    "        x5, attn_weights_5 = self.net_Attention_5(x[:,:,16:20], mask[:,:,16:20])\n",
    "        x6, attn_weights_6 = self.net_Attention_6(x[:,:,20:24], mask[:,:,20:24])\n",
    "        \n",
    "        #出力を全部つなぎ合わせる\n",
    "        x_concat = torch.cat((x1,x2,x3,x4,x5,x6), 2)\n",
    "        # x_attn, attn_weights_all = self.net_Attention_all(x_concat, mask)\n",
    "        \n",
    "        x_out, _ = self.net_Scoring(x_concat)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
    "        \n",
    "        l_attn_weights = [attn_weights_1,attn_weights_2,attn_weights_3,attn_weights_4,attn_weights_5,attn_weights_6\n",
    "                          # , attn_weights_all\n",
    "                         ] \n",
    "        return x_out, l_attn_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# validation用に1人のデータを検証データに回す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset\n",
    "# [~(dataset['subject_id'] == 4)]\n",
    "val_df = dataset[dataset['subject_id'] == 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PyTorchのdatasetの作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = create_Xy(train_df, augment_flag=True, rate_augment=5, rate=0.95)\n",
    "x_test, y_test = create_Xy(val_df, augment_flag=True, rate_augment=5, rate=0.95)\n",
    "\n",
    "# y_train = y_train.astype('int64')\n",
    "# y_test = y_test.astype('int64')\n",
    "\n",
    "\n",
    "# 正解データをone hotベクトルに変換\n",
    "n_classes = len(np.unique(y_train))\n",
    "y_train_onehot = np.identity(n_classes)[y_train]\n",
    "y_test_onehot = np.identity(n_classes)[y_test]\n",
    "\n",
    "\n",
    "### 先頭にclassification用のトークンを追加する\n",
    "score_train = np.zeros((x_train.shape[0], 1 , x_train.shape[2]))\n",
    "x_train = np.concatenate([score_train, x_train], axis=1)\n",
    "\n",
    "score_test = np.zeros((x_test.shape[0], 1 , x_test.shape[2]))\n",
    "x_test = np.concatenate([score_test, x_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(282, 101, 24)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 先頭にclassification用のトークンを追加する\n",
    "# score_train = np.zeros((x_train.shape[0], 1 , x_train.shape[2]))\n",
    "# x_train = np.concatenate([score_train, x_train], axis=1)\n",
    "\n",
    "# score_test = np.zeros((x_test.shape[0], 1 , x_test.shape[2]))\n",
    "# x_test = np.concatenate([score_test, x_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LakZIHM8YTp1"
   },
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 動作確認\n",
    "# # ミニバッチの用意\n",
    "# batch = next(iter(train_dataloader))\n",
    "\n",
    "# # モデル構築\n",
    "\n",
    "# # 変数の固定\n",
    "# torch.manual_seed(1234)\n",
    "# torch.cuda.manual_seed(1234)\n",
    "\n",
    "# net = TransformerScoring(\n",
    "#     d_model=24, max_seq_len=101, output_dim=1)\n",
    "\n",
    "# # 入出力\n",
    "# _device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# net.to(_device)\n",
    "# x = batch[0].to(_device)\n",
    "# input_pad = 1\n",
    "# input_mask = (x != input_pad)\n",
    "# out, l_weights = net(x, input_mask)\n",
    "\n",
    "# print(\"出力のテンソルサイズ：\", out.shape)\n",
    "# # print(\"出力テンソル\", out)\n",
    "# # print(\"出力テンソルのsigmoid：\", F.softmax(out, dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elTTH_9KYTp0"
   },
   "source": [
    "The main part of our model is now complete. We can stack multiple of those\n",
    "`transformer_encoder` blocks and we can also proceed to add the final\n",
    "Multi-Layer Perceptron classification head. Apart from a stack of `Dense`\n",
    "layers, we need to reduce the output tensor of the `TransformerEncoder` part of\n",
    "our model down to a vector of features for each data point in the current\n",
    "batch. A common way to achieve this is to use a pooling layer. For\n",
    "this example, a `GlobalAveragePooling1D` layer is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ネットワークの初期化を定義\n",
    "\n",
    "# def weights_init(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     if classname.find('Linear') != -1:\n",
    "#         # Liner層の初期化\n",
    "#         nn.init.kaiming_normal_(m.weight)\n",
    "#         if m.bias is not None:\n",
    "#             nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "# # 訓練モードに設定\n",
    "# net.train()\n",
    "\n",
    "# # TransformerBlockモジュールを初期化実行\n",
    "\n",
    "# net.net_Attention_1.apply(weights_init)\n",
    "\n",
    "\n",
    "\n",
    "# print('ネットワーク設定完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の設定\n",
    "# # criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "# # nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n",
    "\n",
    "# # 最適化手法の設定\n",
    "# learning_rate = 3e-4\n",
    "# optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs, patience):\n",
    "    # Early Stopping を定義\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "    print('-----start-------')\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # epochのループ\n",
    "    flag = False\n",
    "    for epoch in range(num_epochs):\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "        # for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和\n",
    "            epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "            # データローダーからミニバッチを取り出すループ\n",
    "            for batch in (dataloaders_dict[phase]):\n",
    "                # batchはTextとLableの辞書オブジェクト\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                inputs = batch[0].to(device)  # 文章\n",
    "                labels = batch[1].to(device)  # ラベル\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    # mask作成\n",
    "                    input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "                    input_mask = (inputs != input_pad)\n",
    "\n",
    "                    # Transformerに入力\n",
    "                    outputs, _ = net(inputs, input_mask)\n",
    "                    _, labels_true = torch.max(labels.data, 1)  # ワンホットラベルを平坦化\n",
    "                    labels_true_float = labels_true.float()\n",
    "                    # print(type(labels_true_float.dtype))\n",
    "                    # print(f\"outputs shape is {outputs.flatten().shape}, label shape is {labels_true.shape}\")\n",
    "                    outputs = outputs.flatten()\n",
    "                    loss = criterion(outputs, labels_true_float)  # 損失を計算\n",
    "                    # print(f\"output is {outputs}, labels float are {labels_true_float}\")\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # 結果の計算\n",
    "                    # print(np.array(preds))\n",
    "                    # print(np.array(np.argmax(labels.data)))\n",
    "                    # print(preds == labels.data)\n",
    "                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n",
    "                    # 正解数の合計を更新\n",
    "                    \n",
    "                    # one_hot=F.one_hot(preds,num_classes=4)\n",
    "                    # epoch_corrects += torch.sum(preds == labels_true)\n",
    "                    # print(labels_true)\n",
    "                    # print(torch.flatten(preds))\n",
    "                    preds = torch.round(outputs)  # ラベルを予測\n",
    "                    # print(f\"predicts are {preds}, labels {labels_true}\")\n",
    "                    # print(preds == labels_true)\n",
    "                    epoch_corrects += torch.sum(preds == labels_true)\n",
    "\n",
    "            # epochごとのlossと正解率\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
    "                                                                           phase, epoch_loss, epoch_acc))\n",
    "                # print(f\"epoch corrects {epoch_corrects.double()}\")\n",
    "                # print(f\"dataset size = {len(dataloaders_dict[phase].dataset)}\")\n",
    "                \n",
    "            if phase == 'train':\n",
    "                writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "\n",
    "            else:\n",
    "                writer.add_scalar(\"Loss/test\", loss, epoch)\n",
    "                early_stopping(loss, net) # 最良モデルならモデルパラメータ保存\n",
    "                if early_stopping.early_stop: \n",
    "                # 一定epochだけval_lossが最低値を更新しなかった場合、ここに入り学習を終了\n",
    "                    print(f\"Early Stopping!! Epoch {epoch+1}/{num_epochs} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "                    flag = True\n",
    "        if flag:\n",
    "            break\n",
    "\n",
    "    return net, epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1636987650297,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "8vf0x--aaZjE",
    "outputId": "57c2d515-00a5-443a-b22e-6fa77d359e84"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Subset\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "seed is 1000\n",
      "---------------------------------------------------------------------------------\n",
      "test subject id : 1\n",
      "learning_rate is 1e-05\n",
      "使用デバイス： cuda:0\n",
      "-----start-------\n",
      "Epoch 1/1000 | train |  Loss: 10.7939 Acc: 0.0000\n",
      "Epoch 1/1000 |  val  |  Loss: 10.8170 Acc: 0.0000\n",
      "Epoch 101/1000 | train |  Loss: 4.4564 Acc: 0.2524\n",
      "Epoch 101/1000 |  val  |  Loss: 4.4402 Acc: 0.2500\n",
      "Epoch 201/1000 | train |  Loss: 1.4930 Acc: 0.2571\n",
      "Epoch 201/1000 |  val  |  Loss: 1.3831 Acc: 0.2500\n",
      "Early Stopping!! Epoch 217/1000 Loss: 1.3166 Acc: 0.2500\n",
      "43.61370301246643\n",
      "---------------------------------------------------------------------------------\n",
      "test subject id : 2\n",
      "learning_rate is 1e-05\n",
      "使用デバイス： cuda:0\n",
      "-----start-------\n",
      "Epoch 1/1000 | train |  Loss: 11.5182 Acc: 0.0000\n",
      "Epoch 1/1000 |  val  |  Loss: 11.4964 Acc: 0.0000\n",
      "Epoch 101/1000 | train |  Loss: 4.4165 Acc: 0.2571\n",
      "Epoch 101/1000 |  val  |  Loss: 4.3754 Acc: 0.2500\n",
      "Epoch 201/1000 | train |  Loss: 1.4540 Acc: 0.2571\n",
      "Epoch 201/1000 |  val  |  Loss: 1.3705 Acc: 0.2500\n",
      "Early Stopping!! Epoch 217/1000 Loss: 1.3078 Acc: 0.2500\n",
      "44.08429431915283\n",
      "---------------------------------------------------------------------------------\n",
      "test subject id : 3\n",
      "learning_rate is 1e-05\n",
      "使用デバイス： cuda:0\n",
      "-----start-------\n",
      "Epoch 1/1000 | train |  Loss: 1.5297 Acc: 0.2500\n",
      "Epoch 1/1000 |  val  |  Loss: 1.6626 Acc: 0.1818\n",
      "Epoch 101/1000 | train |  Loss: 1.2423 Acc: 0.2685\n",
      "Epoch 101/1000 |  val  |  Loss: 1.3451 Acc: 0.1818\n",
      "Epoch 201/1000 | train |  Loss: 1.2388 Acc: 0.3194\n",
      "Epoch 201/1000 |  val  |  Loss: 1.3325 Acc: 0.2727\n",
      "Epoch 301/1000 | train |  Loss: 1.1871 Acc: 0.3519\n",
      "Epoch 301/1000 |  val  |  Loss: 1.3116 Acc: 0.2727\n",
      "Epoch 401/1000 | train |  Loss: 1.1569 Acc: 0.3657\n",
      "Epoch 401/1000 |  val  |  Loss: 1.2765 Acc: 0.2727\n",
      "Epoch 501/1000 | train |  Loss: 1.0892 Acc: 0.3704\n",
      "Epoch 501/1000 |  val  |  Loss: 1.2375 Acc: 0.2727\n",
      "Epoch 601/1000 | train |  Loss: 1.0519 Acc: 0.3796\n",
      "Epoch 601/1000 |  val  |  Loss: 1.1989 Acc: 0.2727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\suzuk\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\suzuk\\AppData\\Local\\Temp/ipykernel_2168/925679061.py\", line 70, in <module>\n",
      "    net_trained, loss, acc= train_model(net,\n",
      "  File \"C:\\Users\\suzuk\\AppData\\Local\\Temp/ipykernel_2168/250106693.py\", line 61, in train_model\n",
      "    loss.backward()\n",
      "  File \"C:\\Users\\suzuk\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py\", line 307, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"C:\\Users\\suzuk\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 154, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\suzuk\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\suzuk\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\suzuk\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\suzuk\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\suzuk\\anaconda3\\envs\\torch\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\suzuk\\anaconda3\\envs\\torch\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\suzuk\\anaconda3\\envs\\torch\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\suzuk\\anaconda3\\envs\\torch\\lib\\inspect.py\", line 745, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\suzuk\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\utils\\shimmodule.py\", line 92, in __getattr__\n",
      "    return import_item(name)\n",
      "  File \"C:\\Users\\suzuk\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\utils\\importstring.py\", line 31, in import_item\n",
      "    module = __import__(package, fromlist=[obj])\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 914, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1407, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1379, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1506, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 142, in _path_stat\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2168/925679061.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#時間計測スタート\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             net_trained, loss, acc= train_model(net, \n\u001b[0m\u001b[0;32m     71\u001b[0m                                       \u001b[0mdataloaders_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2168/250106693.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(net, dataloaders_dict, criterion, optimizer, num_epochs, patience)\u001b[0m\n\u001b[0;32m     60\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2063\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2064\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2066\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2067\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "#損失関数\n",
    "criterion = nn.MSELoss()\n",
    "num_epochs = 1000\n",
    "patience = 100\n",
    "batch_size = 32\n",
    "\n",
    "n_classes = 4\n",
    "\n",
    "# グリッドサーチを行う．\n",
    "l_rate = [1e-5, 1e-4, 1e-3, 1e-2]\n",
    "# l_rate = [1e-3]\n",
    "\n",
    "seeds = [1000, 1001, 1002, 1003, 1004]\n",
    "seed = 1000\n",
    "# for i in range(15):\n",
    "#     seeds.append(1000+i)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    print(\"---------------------------------------------------------------------------------\")\n",
    "    print(f\"seed is {seed}\")\n",
    "    # 変数の固定\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    for learning_rate in l_rate:\n",
    "\n",
    "        # kf = KFold(n_splits=5, shuffle=True, random_state=2022)\n",
    "        cv_loss = 0\n",
    "        cv_acc = 0\n",
    "\n",
    "        for subject_id in range(n_classes): \n",
    "            print(\"---------------------------------------------------------------------------------\")\n",
    "            print(f\"test subject id : {subject_id+1}\")\n",
    "            train_df = dataset[~(dataset['subject_id'] == (subject_id+1))]\n",
    "            val_df = dataset[dataset['subject_id'] == (subject_id+1)]\n",
    "\n",
    "            x_train, y_train = create_Xy(train_df, augment_flag=True, rate_augment=5, rate=0.95)\n",
    "            x_test, y_test = create_Xy(val_df, augment_flag=True, rate_augment=5, rate=0.95)\n",
    "\n",
    "            ### 先頭にclassification用のトークンを追加する\n",
    "            score_train = np.zeros((x_train.shape[0], 1 , x_train.shape[2]))\n",
    "            x_train = np.concatenate([score_train, x_train], axis=1)\n",
    "            score_test = np.zeros((x_test.shape[0], 1 , x_test.shape[2]))\n",
    "            x_test = np.concatenate([score_test, x_test], axis=1)\n",
    "            y_train_onehot = np.identity(n_classes)[y_train]\n",
    "            y_test_onehot = np.identity(n_classes)[y_test]\n",
    "\n",
    "            train_dataset = torch.utils.data.TensorDataset(torch.tensor(x_train, dtype=torch.float32)\n",
    "                                                       , torch.tensor(y_train_onehot, dtype=torch.int8))\n",
    "            val_dataset = torch.utils.data.TensorDataset(torch.tensor(x_test, dtype=torch.float32),\n",
    "                                                         torch.tensor(y_test_onehot, dtype=torch.int8))\n",
    "            train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "            val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=False)\n",
    "            dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "\n",
    "            writer = SummaryWriter()\n",
    "            print(f\"learning_rate is {learning_rate}\")\n",
    "\n",
    "            # モデル構築\n",
    "            net = TransformerScoring(d_model=24, max_seq_len=101, output_dim=1)\n",
    "            # 訓練モードに設定\n",
    "            net.train()\n",
    "            optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "            start = time.time() #時間計測スタート\n",
    "            net_trained, loss, acc= train_model(net, \n",
    "                                      dataloaders_dict,\n",
    "                                      criterion,\n",
    "                                      optimizer,\n",
    "                                      num_epochs,\n",
    "                                      patience\n",
    "                                     )\n",
    "            print(time.time() - start)\n",
    "            writer.flush()\n",
    "            cv_loss += loss / n_classes\n",
    "            cv_acc += acc /n_classes\n",
    "        print(f\"cv_acc is {cv_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "seed is 1000\n",
      "learning_rate is 0.0005\n",
      "使用デバイス： cuda:0\n",
      "-----start-------\n",
      "Epoch 1/1000 | train |  Loss: 10.5634 Acc: 0.0000\n",
      "Epoch 1/1000 |  val  |  Loss: 6.9421 Acc: 0.0000\n",
      "Epoch 101/1000 | train |  Loss: 1.0333 Acc: 0.3243\n",
      "Epoch 101/1000 |  val  |  Loss: 0.4157 Acc: 0.6000\n",
      "Epoch 201/1000 | train |  Loss: 0.4472 Acc: 0.5676\n",
      "Epoch 201/1000 |  val  |  Loss: 0.3759 Acc: 0.6000\n",
      "Early Stopping!! Epoch 223/1000 Loss: 0.4655 Acc: 0.5000\n",
      "24.26670503616333\n",
      "seed is 1000\n",
      "learning_rate is 0.0005\n",
      "使用デバイス： cuda:0\n",
      "-----start-------\n",
      "Epoch 1/1000 | train |  Loss: 10.2711 Acc: 0.0000\n",
      "Epoch 1/1000 |  val  |  Loss: 9.2134 Acc: 0.0000\n",
      "Epoch 101/1000 | train |  Loss: 0.6444 Acc: 0.5676\n",
      "Epoch 101/1000 |  val  |  Loss: 0.6499 Acc: 0.2000\n",
      "Early Stopping!! Epoch 109/1000 Loss: 0.6021 Acc: 0.4000\n",
      "11.793780088424683\n",
      "seed is 1000\n",
      "learning_rate is 0.0005\n",
      "使用デバイス： cuda:0\n",
      "-----start-------\n",
      "Epoch 1/1000 | train |  Loss: 2.6436 Acc: 0.2432\n",
      "Epoch 1/1000 |  val  |  Loss: 2.9071 Acc: 0.3000\n",
      "Epoch 101/1000 | train |  Loss: 0.3367 Acc: 0.6486\n",
      "Epoch 101/1000 |  val  |  Loss: 1.4105 Acc: 0.3000\n",
      "Epoch 201/1000 | train |  Loss: 0.2961 Acc: 0.6486\n",
      "Epoch 201/1000 |  val  |  Loss: 1.0306 Acc: 0.4000\n",
      "Early Stopping!! Epoch 239/1000 Loss: 1.2043 Acc: 0.4000\n",
      "25.908702850341797\n",
      "seed is 1000\n",
      "learning_rate is 0.0005\n",
      "使用デバイス： cuda:0\n",
      "-----start-------\n",
      "Epoch 1/1000 | train |  Loss: 8.1629 Acc: 0.0000\n",
      "Epoch 1/1000 |  val  |  Loss: 6.4996 Acc: 0.0000\n",
      "Epoch 101/1000 | train |  Loss: 0.6708 Acc: 0.3514\n",
      "Epoch 101/1000 |  val  |  Loss: 1.1678 Acc: 0.5000\n",
      "Early Stopping!! Epoch 105/1000 Loss: 1.1985 Acc: 0.5000\n",
      "11.398813724517822\n",
      "seed is 1000\n",
      "learning_rate is 0.0005\n",
      "使用デバイス： cuda:0\n",
      "-----start-------\n",
      "Epoch 1/1000 | train |  Loss: 2.6439 Acc: 0.2703\n",
      "Epoch 1/1000 |  val  |  Loss: 2.5420 Acc: 0.2000\n",
      "Epoch 101/1000 | train |  Loss: 0.5485 Acc: 0.4865\n",
      "Epoch 101/1000 |  val  |  Loss: 0.8404 Acc: 0.5000\n",
      "Early Stopping!! Epoch 103/1000 Loss: 0.8356 Acc: 0.5000\n",
      "11.051000595092773\n",
      "k fold accuracy:0.45999999999999996\n"
     ]
    }
   ],
   "source": [
    "all_df = dataset\n",
    "\n",
    "x_all, y_all = create_Xy(all_df, augment_flag=False, rate_augment=5, rate=0.95)\n",
    "\n",
    "# 正解データをone hotベクトルに変換\n",
    "n_classes = len(np.unique(y_all))\n",
    "y_all_onehot = np.identity(n_classes)[y_all]\n",
    "\n",
    "### 先頭にclassification用のトークンを追加する\n",
    "score_train = np.zeros((x_all.shape[0], 1 , x_all.shape[2]))\n",
    "x_all = np.concatenate([score_train, x_all], axis=1)\n",
    "\n",
    "dataset_all = torch.utils.data.TensorDataset(torch.tensor(x_all, dtype=torch.float32)\n",
    "                                               , torch.tensor(y_all_onehot, dtype=torch.int8))\n",
    "\n",
    "\n",
    "#損失関数\n",
    "criterion = nn.MSELoss()\n",
    "num_epochs = 1000\n",
    "patience = 100\n",
    "batch_size = 8\n",
    "\n",
    "# グリッドサーチを行う．\n",
    "l_rate = [5e-4]\n",
    "# l_rate = [1e-3]\n",
    "\n",
    "seeds = [1000]\n",
    "seed = 1000\n",
    "# for i in range(15):\n",
    "#     seeds.append(1000+i)\n",
    "\n",
    "# 変数の固定\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=2022)\n",
    "    for learning_rate in l_rate:\n",
    "        print(\"---------------------------------------------------------------------------------\")\n",
    "        cv = 0\n",
    "        for _fold, (train_index, test_index) in enumerate(kf.split(dataset_all)):  \n",
    "            train_index, valid_index = train_test_split(range(len(dataset_all)), test_size=0.2)\n",
    "            train_dataset = Subset(dataset_all, train_index)\n",
    "            train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "            val_dataset = Subset(dataset_all, valid_index)\n",
    "            val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=False)\n",
    "            dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "\n",
    "            print(f\"seed is {seed}\")\n",
    "\n",
    "            writer = SummaryWriter()\n",
    "            print(f\"learning_rate is {learning_rate}\")\n",
    "\n",
    "            # モデル構築\n",
    "            net = TransformerScoring(d_model=24, max_seq_len=101, output_dim=1)\n",
    "            # 訓練モードに設定\n",
    "            net.train()\n",
    "            optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "            start = time.time() #時間計測スタート\n",
    "            net_trained, loss , acc = train_model(net, \n",
    "                                      dataloaders_dict,\n",
    "                                      criterion,\n",
    "                                      optimizer,\n",
    "                                      num_epochs,\n",
    "                                      patience\n",
    "                                     )\n",
    "            print(time.time() - start)\n",
    "            writer.flush()\n",
    "            cv += acc / kf.n_splits\n",
    "        print(f\"k fold accuracy:{cv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 学習・検証を実行する 15分ほどかかります\n",
    "# net = TransformerClassification(d_model=24, max_seq_len=101, output_dim=4)\n",
    "# # 訓練モードに設定\n",
    "# net.train()\n",
    "\n",
    "# # 損失関数の設定\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# # nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n",
    "\n",
    "# # 最適化手法の設定\n",
    "# learning_rate = 2e-4\n",
    "# optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# print('ネットワーク設定完了')\n",
    "\n",
    "# num_epochs = 300\n",
    "# net_trained = train_model(net, dataloaders_dict,\n",
    "#                           criterion, optimizer, num_epochs=num_epochs)\n",
    "# writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN2SeFtLHbyT"
   },
   "source": [
    "# SaveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テストデータ10個での正解率：0.5000\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 新しいモデル\n",
    "net_trained.eval()\n",
    "net_trained.to(device)\n",
    "\n",
    "epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=300)\n",
    "# test_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=300)\n",
    "\n",
    "for batch in (test_dataloader):  # testデータのDataLoader\n",
    "    # batchはTextとLableの辞書オブジェクト\n",
    "    \n",
    "    # GPUが使えるならGPUにデータを送る\n",
    "    inputs = batch[0].to(device)  # 文章\n",
    "    labels = batch[1].to(device)  # ラベル\n",
    "\n",
    "    # 順伝搬（forward）計算\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        # mask作成\n",
    "        input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "        input_mask = (inputs != input_pad)\n",
    "\n",
    "        # Transformerに入力\n",
    "        outputs, l_attention_weights = net_trained(inputs, input_mask)\n",
    "        _, labels_true = torch.max(labels.data, 1)  # ワンホットラベルを平坦化\n",
    "        outputs = outputs.flatten()\n",
    "\n",
    "        # 正解数の合計を更新\n",
    "        preds = torch.round(outputs)  # ラベルを予測\n",
    "        # print(f\"predicts are {preds}, labels {labels_true}\")\n",
    "        epoch_corrects += torch.sum(preds == labels_true)\n",
    "\n",
    "# 正解率\n",
    "epoch_acc = epoch_corrects.double() / len(test_dataloader.dataset)\n",
    "\n",
    "print('テストデータ{}個での正解率：{:.4f}'.format(len(test_dataloader.dataset),epoch_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGTCAYAAAD6CBJZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnzElEQVR4nO3de5yWdZ3/8deHEUIFgcoDCIpmZiJaWYmVh1Y7Lh7q56bWruXWmoYpKHZue7S1W5HVlrluHrbaVDxmbq556GQamZqKpYuagpgaiTIQIAjj5/fHfaPjMEe57/s7c9+v5+Mxj3Gu65pr3uOXa+Y91+F7R2YiSZJUyrDSASRJUmuzjEiSpKIsI5IkqSjLiCRJKsoyIkmSirKMSJKkojYrHaBeLpv/mM8st4DpU8aXjqA6u+rux0pHUAN4LDe/kZsRPa3zzIgkSSrKMiJJkoqyjEiSpKIsI5IkqSjLiCRJKsoyIkmSirKMSJKkoiwjkiSpKMuIJEkqyjIiSZKKsoxIkqSiLCOSJKkoy4gkSSrKMiJJkoqyjEiSpKIsI5IkqSjLiCRJKsoyIkmSirKMSJKkoiwjkiSpKMuIJEkqyjIiSZKKsoxIkqSiLCOSJKkoy4gkSSrKMiJJkoqyjEiSpKIsI5IkqSjLiCRJKsoyIkmSirKMSJKkoiwjkiSpKMuIJEkqarNSXzgidgBeDIyrvp+XmY912WYiMCEzbykQUZIkNUCxMgLMAGYDNwOndS0iAJn5p4h4VUS8KzOvaHjCIWLFk0v5zTU/5P75t3LiV84pHUd10NHRwVlnnsG8m24khg1jj6l7MvOU2Wy++ealo6mGPJabn8dy90peprkc+BlwQGbO62mjzLwK2C4iXt6wZEPI4vvu5taf/pibfnwxT61cUTqO6uTjs2dx1/w7+f75czl/7iWsWN7OzJNmkJmlo6lGPJZbg8dy90qWkQ8AJ2Xm+n5s+9/Ah+obZ2jaYdcpHPSeYxk/eZfSUVQn115zNddfdy2zTj2N4SNGEBHMOGkmN8/7NVdcflnpeKoRj+Xm57Hcs5JlZNfMXNCfDTNzFbBDnfMMacNHjCwdQXVy0YUXMHbsWHZ75e7PLps4cRITJmzPRXMvKJhM9eCx3Lw8lntWsoy0DXD77euSoklElE6geli1aiXz77yD7cZPILoM8k4778x99y5gxfLlhdKpHjyWm5PHcu9KlpF+360TEZsBk+qYRRqUlvx5CR0dHYwdN26jdaNGjyYzeeTRRwokkzQQHsu9K1lGHo2Id/Zz2yOAx+sZRhqMli9vB2Dc2I1/gLW1VU4url2zppGRJL0AHsu9K1lG/gs4LyJe2dtGEfEK4FvAjxoRShpMRo6s3D+wbt26jdY9vfZpAMaMGdPQTJIGzmO5d8XKSPWR3VuBOyLi2xFxcERsFxGbRcRWEfGaiPgi8DvgaSqFpFcRcVxE3BYRt11/2fl1/g6k+ps4qXLfdnv7so3Wtbcvo62tja232bbRsSQNkMdy70pOegZwDHAF8BHghG7WB/AE8M7MXNnXzjLzbOBsgMvmP9baD22rKYwePZrdp0xh0cKFG61bvPghpk7dk1GjRhVIJmkgPJZ7V/S1aTKzHTgImAU8SKV8bHhbS2V+kb0y865SGYeKTMD61ZSOPPp9LF36OPcueO5J+EWLFvKXJUs44j1HFUymevBYbl4eyz0r/kJ5mflMZn4zM18OTAT2BV4NjM3MD2Tmo2UTDn6ZyaoV7axZvZL16ze+Hqmh7dDD3sU+0/blvHO/Q2ayfv16vvWNr7Pf/gcw/dDDSsdTDXksNzeP5Z5F6SloI2IbYDLwYGYu7Wb9dsAXgOsy89L+7rdVLtPcNe/n/OyS77L00YcBGLfNeN50yJFMe9vhZYM1yPQp40tHaIjVq1dz+pwvs+Ceu4lhw5i27xs4/oQZDB8xonS0urvq7o1etqopeSx7LDe7kZvR4yw6RctIRJwOnEzlDM0zwE+AUzPz/i7bHQ5cnpn9niitVcpIq2uVH2CtrFXKSKvzWG5+vZWRYpdpImIWcAowH/gklftGngJuj4gTu2x+X4PjSZKkBin5NM0MKmdCDsnMZ6rLvh0ROwJnRsRewIer6zpKhZQkSfVV8gbWCcCcTkUEgMx8KDOnU3m65tLqVPCSJKlJlSwjDwA93i6emV8CLgOuBLZoVChJktRYJc86nAF8EJjX0waZOTci1gI/aFgqSZLUUCWngz8bWBARcyLipb1s90Mqj/b6dIwkSU2o6P0YmfnViBgObNXHdhdHRL8f65UkSUNH8ZtDM3Mdldef6Wu7CxsQR5IkNVjx6eAlSVJrs4xIkqSiLCOSJKkoy4gkSSrKMiJJkoqyjEiSpKIsI5IkqSjLiCRJKsoyIkmSirKMSJKkoiwjkiSpKMuIJEkqyjIiSZKKsoxIkqSiLCOSJKkoy4gkSSrKMiJJkoqyjEiSpKIsI5IkqSjLiCRJKsoyIkmSirKMSJKkoiwjkiSpKMuIJEkqyjIiSZKKsoxIkqSiLCOSJKkoy4gkSSoqMrN0hrpYs57m/Mb0PONed2LpCKqzZbd+u3QESTUwcjOip3WeGZEkSUVZRiRJUlGWEUmSVJRlRJIkFWUZkSRJRVlGJElSUZYRSZJUlGVEkiQVZRmRJElFWUYkSVJRlhFJklSUZUSSJBVlGZEkSUVZRiRJUlGWEUmSVJRlRJIkFWUZkSRJRVlGJElSUZYRSZJUlGVEkiQVZRmRJElFWUYkSVJRlhFJklSUZUSSJBVlGZEkSUVZRiRJUlGWEUmSVJRlRJIkFWUZkSRJRVlGJElSUZYRSZJUlGVEkiQVZRmRJElFDdoyEhFbRcRrImJU6SySJKl+Niv5xSNiM+AfgT2A3wE/yMxnIuIE4OvACGBlRJyWmWcXjDqodXR0cNaZZzDvphuJYcPYY+qezDxlNptvvnnpaKqRo97xWmb/41uZvP1LeOjRJ/na967nwqtuKR1LNeax3Pwc4+4VOzMSEcOBXwBnAScC/wVcEBF7AWcALwICGA2cFRF/UyrrYPfx2bO4a/6dfP/8uZw/9xJWLG9n5kkzyMzS0VQD753+evZ8xUSO+9z5HPOJ77JZ2zDO+8Ix/O0BU0tHU415LDc/x7h7JS/TnAC8ETifShn5LvB3wLeB1cB7gVHAG4A/AjOLpBzkrr3maq6/7lpmnXoaw0eMICKYcdJMbp73a664/LLS8VQDK1et4VP//iNuv2cxV//qD7z/k98F4KBpuxVOplryWG5+jnHPSpaRvwNOzsz3Z+Z/ZOaHgFOolI9PZOZFmbk6M28GjgFeVTDroHXRhRcwduxYdnvl7s8umzhxEhMmbM9Fcy8omEy18j+/uOt5H9+7aAkAt/x+UYE0qheP5ebnGPesZBkZTeUsSGfnAuuBuZ0XZuZvgbUNyjVkrFq1kvl33sF24ycQEc9bt9POO3PfvQtYsXx5oXSqlze//hVcft3tXHT1raWjqEY8lpufY9y7kmXk4exykSwzVwP3Z+aybrb/S2NiDR1L/ryEjo4Oxo4bt9G6UaNHk5k88ugjBZKpXt76xt355ieP5NJrf1c6imrIY7n5Oca9K1lGnu5h+RM9LB9bpxxD1vLl7QCMG7vxP+62tjYA1q5Z08hIqpOIYMbRB/Kp497BxO3GcdHX/olT3n9w6ViqEY/l5ucY965kGdkpIkZX5xPZ8DYGGN/D8okFsw5KI0eOBGDdunUbrXt6baXrjRkzpqGZVB+ZyZlzf8mB7/8a00/4NqueWstnjn8nY0a19uOAzcJjufk5xr0rWUZeBbQDyzq9PQm8rIflfU5+FhHHRcRtEXHbeec0/7QkEyftAEB7+8ZXtdrbl9HW1sbW22zb6Fiqs5/dvICzLrqBzUeO4OU7blM6jmrAY7n5Oca9KzrpGfAHKkWjNwFsDfT5HGN1YrSzAdasp+kf2h49ejS7T5nCooULN1q3ePFDTJ26J6NGOYFtM7rxd39k9rFv5Ynlq0pHUQ14LDc/x7h3Jc+MfCUz98rMN/fxdmBmTgG+VzDroHXk0e9j6dLHuXfBgmeXLVq0kL8sWcIR7zmqYDLV044TXswtdy1k4Z+Wlo6iGvFYbn6Occ9KlpGrBrh9a88I04NDD3sX+0zbl/PO/Q6Zyfr16/nWN77OfvsfwPRDDysdT5to9JYj+deTD2P6gc/Ntrrr5G15/2H78sHP/qBgMtWax3Lzc4x7FqWnoI2IbYDJwIOZudGfeRGxHfAF4PrMvKS/+22FyzQbrF69mtPnfJkF99xNDBvGtH3fwPEnzGD4iBGlo9XduNedWDpCXb1k7JZc+o3jeNVuk3j4z8u4/Z7FPPTok5x54S94fNnK0vEaYtmtXacjal6tfCy3ilYe45GbET2tK1pGIuJ04GQqZ2ieAa4GZmfm/V22Oxy4PDPb+rvvViojrazZy4haq4xIzay3MlLyhfJmUZn+fT7wSWAWsAa4PSK6/oa5r8HxJElSg5R8mmYG8BPgkMx8prrs2xGxI3Bm9dV7P1xd11EqpCRJqq+SN7BOAOZ0KiIAZOZDmTkdeBC4NCJKP34sSZLqqGQZeQDYeCq6qsz8EpUnaK4EtmhUKEmS1FglzzqcAXwQmNfTBpk5NyLWAj7DKElSkyp2ZqQ6W+qCiJgTES/tZbsfUnm016djJElqQkXvx8jMr0bEcGCrPra7OCL6/VivJEkaOorfHJqZ64An+rHdhQ2II0mSGqzkDaySJEmWEUmSVJZlRJIkFWUZkSRJRdW0jETE6FruT5IkNb9anxn5VY33J0mSmlyPj/ZGxLkMrKxMAvbc5ESSJKml9DbPyETgrQPcn7OkSpKkAentzMc5wEeBF2XmsL7egB2ARxuSWpIkNY3ezoxcCexUnSG1T5n5p4g4qjaxJElSq+ixjGTmeuD+/u4oIl4GrK5FKEmS1DoG/No0EbENsBMwAohOq7YAPgB4dkSSJPXbgMpI9TLM93v5vD5f8E6SJKmzgZ4Z+TRwXfXtAGAezxWQg4Ef1SyZJElqCQMtI5GZhwBExE3AgZn5/erHlwEfAy6vbURJktTMBjoD6182/Edm3gG8OSK2qH68CnhV7aJJkqRWMNAycn9E/CIiTo+IrYBLgP+JiHdGxOeB/WsfUZIkNbOBlpFPAE8BxwDjM/P86sdXAZ8BflDbeJIkqdkN6J6RzFwGvLPL4ncB7wBWZOYNtQomSZJaw4DnGemqOjnajwEiYv/M9JV7JUlSvw10npFjeloFvASYClhGJElSvw30zMj3qLwyb/SwfukmpZEkSS1noGVkNfAh4LEuywP4e2BuLUJJkqTWMdAy8p+ZeVF3KyLiLuBY4GebnEqSJLWMAT3am5mze1n3JPDaTU4kSZJayiY/TQMQES+i8lo1b6nF/iRJUusY6NM0HX1scsEmZJEkSS1owC+UR+UVezvfwJpUbmy9A/jvGuWSJEktYqBl5PeZ+fa6JJEkSS1poGXk4p5WRMQbgccy88FNiyT13w++9+nSESTVwFV3d50xQs3miL3G97huoC+Ud3BPKzLz18DHBrg/SZLU4vo8MxIRpwCjqh9OjojP0v0MrNsD7waOr108SZLU7PpzmeZc4LPAqVRuVv18D9sl8Lka5ZIkSS2izzKSmSuA0yLiTuAjwHu72wx4MjNX1jaeJElqdv2+gTUzL4iIxzPzoXoGkiRJrWWg08FfFxETImK3DcsiYmJEHFjrYJIkqTUMqIxExL7AvcCvNizLzD8BqyPinOq08JIkSf020Ed75wB/BL7ceWFm3gL8FvhMjXJJkqQWMdAyMjozX52ZX+9m3a3AP9QgkyRJaiEDLSPLe1m3D/DSTcgiSZJa0EDLyD0R8bGIeHbSs6g4msolnBtrmk6SJDW9gb42zWeAm4EPV+cdGQ7sBUykctZkVk3TSZKkpjfQR3ufAKYBPwFeB7wdGAFcALwWeLrWASVJUnMb6JmRDYXkxOrb80TEH4FdapBLkiS1iIHeM9KtiBgXEecBO9Vif5IkqXUM+MxIZxExCTgJ+CdgKyqvUSNJktRvL+jMSETsHREXAg8ApwAjqTxJYxmRJEkDMtDp4A+NiF8CtwBHVRefAUzOzAOA+bWNJ0mSml2fl2kiYiTwASqP7e4CBHA/lRJyZGbO7LT5tNpHlCRJzazXMhIRXwCOB15MpYT8FPj3zLy6uv7dnbfPzHV1yilJkppUX5dpbqRy6SWAzwNv31BEJEmSaqHXMpKZ12XmwcDewCuAeyNiVkRs2ZB0kiSp6fXrBtbMvCMz3wu8BZgM3BcRXwM277xdRLym5gklSVJTG+h08Isy82RgD+BJYMeIuDAiNsy6+t1aB5QkSc3tBc0zkpnLMvNfqcy4egPwvxExn0pJkSRJ6rdNmg4+M9dm5neAKcDFtYkkSZJaySZNB79BZq4H/i0i3lyL/UmSpNZRkxfK2yAz31LL/UmSpOZX0zIiSZI0UJYRSZJUlGVEkiQVNWTKSETsXDqDJEmqvSFTRoDrSgeQJEm1N+jLSESMi4jzqEywJkmSmkxN5hmph4iYBJwE/BOwFZBlEw1eHR0dnHXmGcy76UZi2DD2mLonM0+Zzeabb973J2vIWPHkUn5zzQ+5f/6tnPiVc0rHUR14LLcGj+WNDbozIxGxd0RcCDwAnAKMBG7EMtKjj8+exV3z7+T758/l/LmXsGJ5OzNPmkGm/8uaxeL77ubWn/6Ym358MU+tXFE6jurEY7n5eSx3b9CUkYg4NCJ+CdwCHFVdfAYwOTMPAOaXyjaYXXvN1Vx/3bXMOvU0ho8YQUQw46SZ3Dzv11xx+WWl46lGdth1Cge951jGT96l7401JHkstwaP5e4VLSMRMTIijo+Ie4ErgP2BP1K5PPPbzJyZmX+ubj6tVM7B7KILL2Ds2LHs9srdn102ceIkJkzYnovmXlAwmeph+IiRpSOoTjyWW4vH8vMVKyMR8QXgYeBM4OXAz4DpmfmKzPw2sK7z9pm5buO9tLZVq1Yy/8472G78BCLieet22nln7rt3ASuWLy+UTvXQZZjVJDyWW4/H8vOVPDNyI5VLLwF8Hnh7Zl5dMM+Qs+TPS+jo6GDsuHEbrRs1ejSZySOPPlIgmaSB8FhWqytWRjLzusw8GNgbeAVwb0TMiogtS2UaapYvbwdg3NiNf4C1tbUBsHbNmkZGkvQCeCyr1RW/gTUz78jM9wJvASYD90XE14DnPcsWEa8pEG9QGzmycs1x3bqNr2A9vfZpAMaMGdPQTJIGzmNZra54GdkgMxdl5snAHsCTwI4RcWFEbLjl+Lt97SMijouI2yLitvPOObuecQeFiZN2AKC9fdlG69rbl9HW1sbW22zb6FiSBshjWa1u0E16lpnLgH+NiNOBDwD/GxFrqJSUvj73bOBsgDXrm39ektGjR7P7lCksWrhwo3WLFz/E1Kl7MmrUqALJJA2Ex7Ja3aA5M9JVZq7NzO8AU4CLS+cZrI48+n0sXfo49y5Y8OyyRYsW8pclSzjiPUf18pkaijJx+r8m5bHcWjyWn2/QlpENMnN9Zv4b8PPSWQajQw97F/tM25fzzv0Omcn69ev51je+zn77H8D0Qw8rHU81lJmsWtHOmtUrWb/eJ92bjcdy6/BY3liUnmY4IrahcuPqg5m5tJv12wFfAK7PzEv6u99WuEyzwerVqzl9zpdZcM/dxLBhTNv3DRx/wgyGjxhROlrdXXX3Y6UjNMRd837Ozy75LksffRiAcduM502HHMm0tx1eNlgDTJ8yvnSEhvFYbn6tfCwfsdf4HmdXKVpGqveFnEzlDM0zwNXA7My8v8t2hwOXZ2Zbf/fdSmWklbXKD7BW1kplpJV5LDe/3spIyRlYZ1F5Ibz5wCeBWcAa4PaIOLHL5vc1OJ4kSWqQkk/TzAB+AhySmc9Ul307InYEzoyIvYAPV9d1lAopSZLqq+QNrBOAOZ2KCACZ+VBmTgceBC6NiEH3+LEkSaqdkmXkAbq8GF5nmfkl4DLgSmCLRoWSJEmNVfKswxnAB4F5PW2QmXMjYi3wg4alkiRJDVXyhfLOBhZExJyIeGkv2/2QyqO9Ph0jSVITKno/RmZ+NSKGA1v1sd3FEdHvx3olSdLQUfzm0MxcBzzRj+0ubEAcSZLUYIN+OnhJktTcLCOSJKkoy4gkSSrKMiJJkoqyjEiSpKIsI5IkqSjLiCRJKsoyIkmSirKMSJKkoiwjkiSpKMuIJEkqyjIiSZKKsoxIkqSiLCOSJKkoy4gkSSrKMiJJkoqyjEiSpKIsI5IkqSjLiCRJKsoyIkmSirKMSJKkoiwjkiSpKMuIJEkqyjIiSZKKsoxIkqSiLCOSJKkoy4gkSSrKMiJJkorarHQAaVNMnzK+dATV2YGn31A6ghpg9jt2LR1BBXlmRJIkFWUZkSRJRVlGJElSUZYRSZJUlGVEkiQVZRmRJElFWUYkSVJRlhFJklSUZUSSJBVlGZEkSUVZRiRJUlGWEUmSVJRlRJIkFWUZkSRJRVlGJElSUZYRSZJUlGVEkiQVZRmRJElFWUYkSVJRlhFJklSUZUSSJBVlGZEkSUVZRiRJUlGWEUmSVJRlRJIkFWUZkSRJRVlGJElSUZYRSZJUlGVEkiQVZRmRJElFWUYkSVJRlhFJklSUZUSSJBVlGZEkSUVtVjqANl1HRwdnnXkG8266kRg2jD2m7snMU2az+eabl46mGnGMm9/hrxrP3+29PduPHcnSlU9z+e2PMvfWP5WOpTpY8eRSfnPND7l//q2c+JVzSscZFDwz0gQ+PnsWd82/k++fP5fz517CiuXtzDxpBplZOppqxDFubn+/zyT2mLAVc669j1Mu/QMPP/kUJx/0Mk7+m5eVjqYaW3zf3dz60x9z048v5qmVK0rHGTQsI0PctddczfXXXcusU09j+IgRRAQzTprJzfN+zRWXX1Y6nmrAMW5umw0Lxm0xnC9efS/z/7SC2xe3c+plv2fBn//Ke167PS/ecnjpiKqhHXadwkHvOZbxk3cpHWVQsYwMcRddeAFjx45lt1fu/uyyiRMnMWHC9lw094KCyVQrjnFz2/JFbZz/24eft+yZhJ/93+O0DQvGjxlZKJnqafgIx7Uzy8gQtmrVSubfeQfbjZ9ARDxv3U4778x99y5gxfLlhdKpFhzj5rf8qfUsW71uo+Vr1nfQ8UzyaPuaAqlUb10O55Y3KMtIRGwVEa+NiJ1KZxnMlvx5CR0dHYwdN26jdaNGjyYzeeTRRwokU604xq1rr4lj+M2DT3ZbVKRmU7SMRMT0iPhmRBzdadls4DHgt8AfI2JeRHgXVzeWL28HYNzYjX9RtbW1AbB2jX9VDWWOcWvabqsX8caXvYQzfv5A6ShSQxR7tDci/gH4HhDARyPiMOAiYA6wuvr+BmAn4MKI+NvMXFoo7qA0cmTlmuO6dRv/5fT02qcBGDNmTEMzqbYc49Z02ltfzlm/WshDTz5VOorUECXPjHwcuB/YG9gSuAD4FpDA4Zn5ycy8JjPPAt4PnNzXDiPiuIi4LSJuO++cs+sYfXCYOGkHANrbl220rr19GW1tbWy9zbaNjqUacoxbzzHTJvHEqqe55DYvv6l1lJz0bDJwZGbeUf34xxGxHvhsZv6084aZuSAiJve1w8w8GzgbYM16mn4ChtGjR7P7lCksWrhwo3WLFz/E1Kl7MmrUqALJVCuOcWt5yyu3ZvcJW/HpK+4uHUVqqJJnRhZSuTfkWZn5EyqXarrz2ronGoKOPPp9LF36OPcuWPDsskWLFvKXJUs44j1HFUymWnGMW8OBu76Ud+6xHZ+98h46Ov0p9ZItR5QLpbrJhOb/k7n/SpaRLwFHdrP8jK4LIuJQYIe6JxqCDj3sXewzbV/OO/c7ZCbr16/nW9/4OvvtfwDTDz2sdDzVgGPc/A7ebWuO228y//mrhUwYM5IdX7w5O710C/Z/+Uv48P6TS8dTjWUmq1a0s2b1Stav92kpgCg5nXT1JtYVmXllH9t9BXhjZr6pv/tuhcs0G6xevZrT53yZBffcTQwbxrR938DxJ8xg+Aj/omoWrTzGB55+Q+kIdfW23bfhn6fvRtuw7iee+MyV9/DT/3u8wakab/Y7di0doSHumvdzfnbJd1n6aGWiu3HbjOdNhxzJtLcdXjZYAxyx1/geZ1cpWkb6KyJGAyMy84n+fk4rlRGpmTV7GVFFq5SRVtZbGRkSr9qbmX8tnUGSJNXHoJyBVZIktQ7LiCRJKsoyIkmSirKMSJKkoiwjkiSpKMuIJEkqyjIiSZKKsoxIkqSiLCOSJKkoy4gkSSrKMiJJkoqyjEiSpKIsI5IkqSjLiCRJKsoyIkmSirKMSJKkoiwjkiSpKMuIJEkqyjIiSZKKsoxIkqSiLCOSJKkoy4gkSSrKMiJJkoqyjEiSpKIsI5IkqSjLiCRJKsoyIkmSirKMSJKkoiwjkiSpKMuIJEkqyjIiSZKKsoxIkqSiLCOSJKkoy4gkSSrKMiJJkoqyjEiSpKIiM0tnUI1ExHGZeXbpHKofx7g1OM7NzzF+Ps+MNJfjSgdQ3TnGrcFxbn6OcSeWEUmSVJRlRJIkFWUZaS5ef2x+jnFrcJybn2PciTewSpKkojwzIkmSirKMSJKkoiwjQ0BUfDgi/hART0XEAxFxSkRED9tPj4grIuKWiLghIn4eEf8ZEftExJyImNzgb0F96GuMI+JNEfHliMjq253VMb4qIuZHxE0RcXJEjCj9vah7Az2OO33e2yLii43KqfqKiPdV/w2sioi7I+KY0pkGA+8ZGQIi4mPAK4HzgOHAx4C3A9/IzFM6bTcO+D6wD/Ah4KqsDnBE7A58EzgY2Dszb2/oN6FeDWCM7wKmAuMys726rA2YQWV85wFvzsynG/oNqE/9HeNuPu+nwKuBSZm5uhFZVR/V4jEVuBgYD5wO7Aoclpn/UzJbcZnp2yB+A0YAp3dZ1gb8DugAtuu07BfA08AePexrOPAb4KDS35dvAx/j6vJfAgmM7WY//11dd3zp78m3Fz7GXbZ5TXVME/hI6e/Dt03+d/CuHsb3jNLZSr95mWbw2wqY03lBZnYAl1C5zDa5uvhE4EDgvMz8Q3c7ysx1wGnAi+uUVS9Mf8e4L7+tvt+jZslUKy90jE8D/qX637Miwp/ZQ1hmXtFl0YLq+9923bbVbFY6gHqXmUt7WLUaeAZ4sHrN+cTq8q7/2Lvu76aI2L6GEbWJ+jPG/dzVq6vvvQQ3yLyQMa7e2/V64B+AN1C5xHoo8KO6hFQJBwGXAheUDlKaLXvo2g/4SWb+BZgA7FJd3u1Zkc4y85F6BlPNdB7jHkXElhFxEnAslR9s/92IcKqJ3sb4FOA/MnM98O+dlqkJRMQ7gP8ALsrqNZtW5pmRISgidgT+Fti7umhSp9U9/QWmIaSbMe7qtoh4jMolt5dTuR9oHvCl6i8vDXK9jXFEvBj4O+AV1UVXA/cD+0XE6zLz1oYFVU1VL7V9FDgKmAhcHhEfz8w5vX9mc/PMyND0H8CnMnPD9cY1ndZtUSCPaq/rGHf12szcLzOnULkr/6PAnlRKyoxGhdQm6W2MP0LlL+YVANW/nM+orju1QflUB5n5TGZ+MzP3Bd5G5VLd5yNibNlkZflo7xATEZ8EdsnMD3Za9iKgHRgJvC4zbysUTzXQ3Rh3WvdL4AA6Pdrbad3RwIVUnqjatut6DR59jPFIYCGwGHiq06rhVO4hCeBlmflQI7KqviLiy8DHgX0y85bSeUrxzMgQUv1l83rgw52XZ+ZaKnflA7y7H/uZ1Nc2KqOnMe6nDfMUjOC5e4g0yPRjjN8P3JCZ+2TmgZ3e3kjlbEobcFKD4qr+bqi+f6JoisIsI0NERLwbOAY4qvM9ARExvvo0zaeo/GOeGRG79bKfQwCfphmE+jHGUPmruCdTq+9XAvfVJ6U2RV9jHBHDqVyG+VwPu/gylTNf/xQRL6l7YDXCZOC3mflA6SAlWUaGgIg4EvgC8Blgp4jYLSKmRMThwBez4hEqj/61AzdFxNHVH2wb9jEqIj4CjMjMmxv/Xag3/Rnj6qYv7eHz9+G5p2g+tuFeAw0e/Rzj04C1mXlvd/vIzMeozEkxGvhqX1PJa/CIiK2qL8dxWKeXedgN+EcqBbWlec/IIBcR76PyS6an4nh0Zl7UafutqJzCPRzYGngYeITK9edze/ohp3L6M8bACuAIKo/vQuXsx5+olM+tqdwvdCfwzcy8vo5x9QL0c4w/RGXeCag8on9s5/u/qq87dDPwKp47Q7YQeGtm/rEOsVVDEfFS4Eoqs64uBm4DFlE5Znt9fL8VWEYkSVJRXqaRJElFWUYkSVJRlhFJklSUZUSSJBVlGZEkSUVZRiRJUlGWEUmSVJRlRFJxETGsOjPlLyLic52WbxERD0TEhYMtm6TasYxIAiAiPh0RiyMiO72ti4gnImJeRMzs/BIDNfZGKrMGH8jzX3+nA3iSygy0pfSUTVKNWEYkAZCZ/wrsTGWaeYBDgX2AmcC2wDeAK+vxeiiZeSPw1W6Wr83M12Xm8QPdZ0S01eJMRk/ZJNWOZUTSs6qvJLuo+uGNmXl7Zv6AyoswrgPeAUyv05dfU+P9nQDsVKN91TqbpE4sI5K66ui6IDMXAvOrH+5ep6/7TK12FBFvBr5Wq/1Rw2ySNmYZkdSniGgDJlY/XFy9f+SWiPhcRBwbEY9HxE0RMay6/f4RcUVE/Kq67jsRsWWXfU6NiKsj4uaIuBn4YJf1L4qIoyLi+oj4ry7rtoiIr0TEjRFxa0TcERGHVNftDXwSGAG8PSJ+GRFzOn3uJmeTVFuWEUk92VAsRgH/CWwH/Aq4BXgaeB2VmzrXAWcDj1S3fzvwFeDYzNwfeD+VX+bnbNhxREwFbgJ+mJnTgAOA13f5+tsCbVQuEQ3r9LkjgZ8DWwH7Z+brgIeBKyLitZn5u8x8a3XzazLzwMz8WI2zSaohy4iknnwrIv4XmAdMAmYAB2XmA8C11W3+mJnnZ+anM/PIzHwGOAP4Yma2A2Tm1cCdwNERsUv1884F7snMc6vbrAVO7/zFM3MxcEk3uU4EpgIfy8ysLvsB8FdgbB/fU02ySaqtzUoHkDRonbjhl3Y3NtxX8kjnhdVf6LsA/xwRp3VaNQp4CJgcEZtTOdPQ9Z6O+7t+kcxc183DO4cB92XmXzttdylwaW/fTK2zSaody4ikWtq2+v7UzLypuw0i4qjqfy59gV9jO2DtC/i8RmST9AJ4mUZSLbVX3/+/risiYlRE7MxzRWLSC/waTwAvi4gx3XyN3vbZiGySXgDLiKSuNvxc6M+Z067XUP6PyqWbkyPiExHxIoBqcTgXeAq4GVgP/G1EjOjl6/fkemAklXtHngsSMRl4Uy+f14hskl4ADyxJz6r+At6h+mFv84lsV32/R+eF1RtYZ1U//BLw14hYBPwFuD8zH8vMx4BvAjsCX60+NgywX/X9zp2KwoTqsu07fZlvULnH43PVUvHq6uWVrwA/6rTdExs+LyLeVOtskmrHMiIJqLw2DfAAlV/EAFdX5w5p67Ld8cD/Vj98d0T8ofMlk+rNpIcAvwOSyhmWfwH+udNuTqMyF8i7gd9HxDlUHtVtr27/7oh4E5UzFQAHR8SdETEqM5+kcgbkSuDTwNXA/sAJmflUp6/xceDV1RfZW1PLbL3/n5Q0UPHck3GSJEmN55kRSZJUlGVEkiQVZRmRJElFWUYkSVJRlhFJklSUZUSSJBVlGZEkSUVZRiRJUlGWEUmSVJRlRJIkFfX/AZzmn2g5qB/uAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "preds_heat = np.array(preds.cpu())\n",
    "trues_heat = np.array(labels_true.cpu())\n",
    "# preds_heat[0] = \"3A\"\n",
    "# print(preds_heat)\n",
    "# print(trues_heat)\n",
    "\n",
    "heat = confusion_matrix(trues_heat, preds_heat)\n",
    "# print(heat)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"   # 使用するフォント\n",
    "plt.rcParams[\"font.size\"] = 20        \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "xtics = [\"2C\", \"2B\", \"2A\", \"3\"]\n",
    "ytics = [\"2C\", \"2B\", \"2A\", \"3\"]\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(heat, annot=True, xticklabels=xtics, yticklabels=ytics, cmap=\"Blues\", cbar=False)\n",
    "# sns.heatmap(heat, annot=True, cmap=\"Blues\", cbar=False)\n",
    "#*以下2行がポイント*  X,Y軸ラベルを追加\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "#グラフをはみ出さないようにして画面に出力\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"nn-heatmap_crossvalid.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1cb3c84ef40>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# サンプルごとに代償動作の度合いをセッティングしてみる\n",
    "preds = np.array(outputs.cpu())\n",
    "ans = np.array(labels_true.cpu())\n",
    "plt.scatter(preds, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([225, 101, 101])\n"
     ]
    }
   ],
   "source": [
    "print(l_attention_weights[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 25\n",
    "\n",
    "print(f\"predicts are {preds[index]}, labels {labels_true[index]}\")\n",
    "\n",
    "RElbow2RWrist_weight = np.array(l_attention_weights[0].cpu()[index, 0, 1:]).reshape(1, -1)\n",
    "RShoulder2RElbow_weight = np.array(l_attention_weights[1].cpu()[index, 0, 1:]).reshape(1, -1)\n",
    "Pelvis2RShoulder_weight = np.array(l_attention_weights[2].cpu()[index, 0, 1:]).reshape(1, -1)\n",
    "Pelvis2RNeck_weight = np.array(l_attention_weights[3].cpu()[index, 0, 1:]).reshape(1, -1)\n",
    "Nect2RShoulder_weight = np.array(l_attention_weights[4].cpu()[index, 0, 1:]).reshape(1, -1)\n",
    "Neck2LShoulder_weight = np.array(l_attention_weights[5].cpu()[index, 0, 1:]).reshape(1, -1)\n",
    "\n",
    "weights = np.concatenate([RElbow2RWrist_weight, RShoulder2RElbow_weight, Pelvis2RShoulder_weight, Pelvis2RNeck_weight,\n",
    "                         Nect2RShoulder_weight, Neck2LShoulder_weight])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "# Set the palette using the name of a palette:\n",
    "# sns.heatmap(RElbow2RWrist_weight, cmap='OrRd')\n",
    "# sns.heatmap(RShoulder2RElbow_weight, cmap='OrRd')\n",
    "# sns.heatmap(Pelvis2RShoulder_weight, cmap='OrRd')\n",
    "# sns.heatmap(Pelvis2RNeck_weight, cmap='OrRd')\n",
    "# sns.heatmap(Nect2RShoulder_weight, cmap='OrRd')\n",
    "# sns.heatmap(Neck2LShoulder_weight, cmap='OrRd')\n",
    "\n",
    "sns.heatmap(weights, cmap='OrRd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.1'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "extract_data = np.array(X[19, 1:, 2]).flatten()\n",
    "print(extract_data.shape)\n",
    "\n",
    "\n",
    "time = np.linspace(0, 100, 100)\n",
    "fig, ax = plt.subplots(2, 1, gridspec_kw={'height_ratios': [6, 1]}, figsize=(15,10))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.lineplot(time, extract_data, ax=ax[0])\n",
    "sns.heatmap(extract_weight, cmap='OrRd', cbar=False, ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data = np.array(attn_weights1[:, 0, :])\n",
    "print(data.shape)\n",
    "data = data.reshape(attn_weights1.shape[0], -1)\n",
    "\n",
    "# print(outputs)\n",
    "print(data.shape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 20))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(data, cmap='OrRd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data[0])):\n",
    "    print(data[0,i], end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_trained.net_Attention_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelの読み込みだけ\n",
    "# 保存したモデルパラメータの読み込み\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net_trained = TransformerClassification().to(device)\n",
    "\n",
    "net_trained.load_state_dict(torch.load('highacc2.pth'))\n",
    "# print('読み込み後のモデル:\\n', model2.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(net_trained.state_dict(), 'highacc3.pth')\n",
    "\n",
    "# 新しいモデル\n",
    "model2 = TransformerClassification().to(device)\n",
    "print('新しいモデル:\\n', model2.state_dict())\n",
    "\n",
    "# 保存したモデルパラメータの読み込み\n",
    "model2.load_state_dict(torch.load('highacc3.pth'))\n",
    "print('読み込み後のモデル:\\n', model2.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention weight の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "print(data)\n",
    "print(data.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 同時に入れるデータも作成する\n",
    "# これは時系列スタンプ．0〜100がサンプル数だけ作られる\n",
    "stamp_row = [i%data.shape[1] for i in range(data.shape[0] * data.shape[1])]\n",
    "\n",
    "# いつ撮影されたのかのスタンプ\n",
    "l_date_name = np.array(df_annotate['date'].unique())\n",
    "date_row = []\n",
    "for item in l_date_name:\n",
    "    for i in range(data.shape[1]):\n",
    "        date_row.append(item)\n",
    "        \n",
    "# アテンションウエイト\n",
    "attn_weight = data.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attn = pd.DataFrame()\n",
    "df_attn['date'] = date_row\n",
    "df_attn[\"stamp\"] = stamp_row\n",
    "df_attn[\"attn_weight\"] = attn_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attn.to_excel('/Users/kento/kuhp/experiment/attention_weights.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_attn['date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "timeseries_transformer_classification.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/keras-team/keras-io/blob/master/examples/timeseries/ipynb/timeseries_classification_transformer.ipynb",
     "timestamp": 1636355482830
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
