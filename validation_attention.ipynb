{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyRQwYrEYTpv"
   },
   "source": [
    "# 修士論文実験 2022/01/10\n",
    "# 追記 2022/01/17\n",
    "## validationが簡単に行えるようにデータセットを操作するモジュールを拡充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "executionInfo": {
     "elapsed": 843,
     "status": "ok",
     "timestamp": 1636987406075,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "dO5GxI7RzXIc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "%matplotlib inline\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# sys.path.append(os.path.abspath(\"..\"))\n",
    "# import scripts.compensate\n",
    "# import scripts.kinectImg2video\n",
    "# from scripts.conpemsate_suppresser import *\n",
    "# from scripts.ground_angle_analysis import ground_shoulder_angle_analyzer\n",
    "# import scripts.ground_angle_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日付の追加\n",
    "df_annotate = pd.read_excel(\"/Users/kento/kuhp/experiment/annotate_dataset.xlsx\")\n",
    "df_annotate['date'] = pd.to_datetime(df_annotate['date'], format='%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>uid</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>point</th>\n",
       "      <th>shoulder</th>\n",
       "      <th>body</th>\n",
       "      <th>flag_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-06 18:56:20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-06 18:56:20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-06 18:56:41</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-06 18:56:41</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-06 18:56:58</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  uid  subject_id  task_id point  shoulder  body  \\\n",
       "0 2021-12-06 18:56:20    1           1        1     3         0     0   \n",
       "1 2021-12-06 18:56:20    2           1        1     4         0     0   \n",
       "2 2021-12-06 18:56:41    3           1        1     3         0     0   \n",
       "3 2021-12-06 18:56:41    4           1        1     4         0     0   \n",
       "4 2021-12-06 18:56:58    5           1        1     3         0     0   \n",
       "\n",
       "   flag_usage  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           2  \n",
       "4           1  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>x_Pelvis</th>\n",
       "      <th>y_Pelvis</th>\n",
       "      <th>z_Pelvis</th>\n",
       "      <th>x_SpineNaval</th>\n",
       "      <th>y_SpineNaval</th>\n",
       "      <th>z_SpineNaval</th>\n",
       "      <th>x_SpineChest</th>\n",
       "      <th>...</th>\n",
       "      <th>x_REar</th>\n",
       "      <th>y_REar</th>\n",
       "      <th>z_REar</th>\n",
       "      <th>N</th>\n",
       "      <th>v_RWrist</th>\n",
       "      <th>z_v_RWrist</th>\n",
       "      <th>flag_active</th>\n",
       "      <th>flag_moving</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-158.973129</td>\n",
       "      <td>353.261841</td>\n",
       "      <td>698.233093</td>\n",
       "      <td>-149.886017</td>\n",
       "      <td>218.100922</td>\n",
       "      <td>780.778748</td>\n",
       "      <td>-142.035919</td>\n",
       "      <td>...</td>\n",
       "      <td>-178.933960</td>\n",
       "      <td>-236.272278</td>\n",
       "      <td>842.268127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.917988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-156.911919</td>\n",
       "      <td>356.031863</td>\n",
       "      <td>697.378637</td>\n",
       "      <td>-147.957493</td>\n",
       "      <td>219.063530</td>\n",
       "      <td>781.238292</td>\n",
       "      <td>-142.348493</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.788628</td>\n",
       "      <td>-241.853940</td>\n",
       "      <td>862.009244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.131710</td>\n",
       "      <td>0.480634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.891892</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-157.406120</td>\n",
       "      <td>356.970863</td>\n",
       "      <td>697.867036</td>\n",
       "      <td>-148.184343</td>\n",
       "      <td>219.214968</td>\n",
       "      <td>781.799317</td>\n",
       "      <td>-142.899719</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.093690</td>\n",
       "      <td>-243.703880</td>\n",
       "      <td>867.831643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.690953</td>\n",
       "      <td>0.198082</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.783784</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-159.493486</td>\n",
       "      <td>356.687710</td>\n",
       "      <td>699.214911</td>\n",
       "      <td>-149.753131</td>\n",
       "      <td>218.849632</td>\n",
       "      <td>782.412353</td>\n",
       "      <td>-143.553739</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.457427</td>\n",
       "      <td>-243.071735</td>\n",
       "      <td>864.096621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.280899</td>\n",
       "      <td>0.313779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.675676</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-162.211771</td>\n",
       "      <td>355.791270</td>\n",
       "      <td>700.938883</td>\n",
       "      <td>-151.850422</td>\n",
       "      <td>218.261918</td>\n",
       "      <td>783.027933</td>\n",
       "      <td>-144.174692</td>\n",
       "      <td>...</td>\n",
       "      <td>-177.488121</td>\n",
       "      <td>-241.207140</td>\n",
       "      <td>855.165480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.247976</td>\n",
       "      <td>0.307322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.567568</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1   id    x_Pelvis    y_Pelvis    z_Pelvis  \\\n",
       "0           0             0  1.0 -158.973129  353.261841  698.233093   \n",
       "1           1             1  1.0 -156.911919  356.031863  697.378637   \n",
       "2           2             2  1.0 -157.406120  356.970863  697.867036   \n",
       "3           3             3  1.0 -159.493486  356.687710  699.214911   \n",
       "4           4             4  1.0 -162.211771  355.791270  700.938883   \n",
       "\n",
       "   x_SpineNaval  y_SpineNaval  z_SpineNaval  x_SpineChest  ...      x_REar  \\\n",
       "0   -149.886017    218.100922    780.778748   -142.035919  ... -178.933960   \n",
       "1   -147.957493    219.063530    781.238292   -142.348493  ... -176.788628   \n",
       "2   -148.184343    219.214968    781.799317   -142.899719  ... -176.093690   \n",
       "3   -149.753131    218.849632    782.412353   -143.553739  ... -176.457427   \n",
       "4   -151.850422    218.261918    783.027933   -144.174692  ... -177.488121   \n",
       "\n",
       "       y_REar      z_REar   N  v_RWrist  z_v_RWrist  flag_active  flag_moving  \\\n",
       "0 -236.272278  842.268127 NaN       NaN   -0.917988          0.0          1.0   \n",
       "1 -241.853940  862.009244 NaN  7.131710    0.480634          1.0          1.0   \n",
       "2 -243.703880  867.831643 NaN  5.690953    0.198082          1.0          1.0   \n",
       "3 -243.071735  864.096621 NaN  6.280899    0.313779          1.0          1.0   \n",
       "4 -241.207140  855.165480 NaN  6.247976    0.307322          1.0          1.0   \n",
       "\n",
       "    timestamp                date  \n",
       "0    0.000000 2021-12-04 18:20:18  \n",
       "1   39.891892 2021-12-04 18:20:18  \n",
       "2   79.783784 2021-12-04 18:20:18  \n",
       "3  119.675676 2021-12-04 18:20:18  \n",
       "4  159.567568 2021-12-04 18:20:18  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataSetの呼び出し\n",
    "df_data = pd.read_csv(\"/Users/kento/kuhp/experiment/bigdata_trimmed.csv\")\n",
    "df_data['date'] = pd.to_datetime(df_data['date'], format='%Y-%m-%d-%H-%M-%S')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1636987406076,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "GZlVgJy1zXIc"
   },
   "outputs": [],
   "source": [
    "# pd_merged = pd.merge(df_annotate, df_data, on='date', how='inner')\n",
    "# pd_3 = pd_merged[pd_merged['point'] == 3]\n",
    "# pd_2A = pd_merged[pd_merged['point'] == '2A']\n",
    "# pd_2B = pd_merged[pd_merged['point'] == '2B']\n",
    "# pd_2C = pd_merged[pd_merged['point'] == '2C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### このデータセットはGraspのものかつ，usageが1のものが取り出されている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# データセットにNN入力用のスコアを割り振る．\n",
    "# これが正解ラベルになる\n",
    "dataset = pd.merge(df_annotate, df_data, on='date', how='inner')\n",
    "\n",
    "dataset = dataset[(dataset['task_id'] == 1) & (dataset['flag_usage'] == 1)]\n",
    "dataset['point'] = dataset['point'].astype(str)\n",
    "dataset.loc[dataset['point'] == '3', 'score'] = 3\n",
    "dataset.loc[dataset['point'] == '2A', 'score'] = 2\n",
    "dataset.loc[dataset['point'] == '2B', 'score'] = 1\n",
    "dataset.loc[dataset['point'] == '2C', 'score'] = 0\n",
    "print(dataset['score'].max())\n",
    "\n",
    "# Nanのものを削除\n",
    "dataset.dropna(subset=['score'], inplace=True)\n",
    "# scoreの行をintにする\n",
    "dataset['score'] = dataset['score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['uid'].unique()\n",
    "dataset['date'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grasp動作だけを抜き出す\n",
    "# dataset_grasp = dataset[dataset['task_id'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RElbow2RWrist と Rshoulder2RElbow と Pelvis2RShoulder と Pelvis2Neck の速度を入れてみる "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_annotate\n",
    "# l_date = df_annotate['date'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vector(df, joint1, joint2, word=\"\"):\n",
    "    df[f\"{word}_x_{joint1}2{joint2}\"] = df[f\"x_{joint1}\"].astype('float64') - df[f\"x_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_y_{joint1}2{joint2}\"] = df[f\"y_{joint1}\"].astype('float64') - df[f\"y_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_z_{joint1}2{joint2}\"] = df[f\"z_{joint1}\"].astype('float64') - df[f\"z_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_ave_{joint1}2{joint2}\"] = (df[f\"{word}_x_{joint1}2{joint2}\"] + df[f\"{word}_y_{joint1}2{joint2}\"] + df[f\"{word}_z_{joint1}2{joint2}\"])/3\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_date_name = np.array(dataset['date'].unique())\n",
    "# l = []\n",
    "# for date in l_date_name:\n",
    "#     score = dataset[dataset[\"date\"] == date]['score'].mode()\n",
    "#     l.append(score)\n",
    "# return np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解ラベルで用いるyのone hotベクトルを作成\n",
    "def one_hot_enc(df):\n",
    "    l = []\n",
    "    l_date_name = np.array(df['date'].unique())\n",
    "    for date in l_date_name:\n",
    "        score = df[df[\"date\"] == date]['score'].mode()\n",
    "        l.append(score)\n",
    "    y = np.array(l).flatten()\n",
    "    \n",
    "    # l_date_name = np.array(df['date'].unique())\n",
    "    # y = np.array(df[\"score\"]) #一番多いものをscoreとして最後にyとして返す\n",
    "    # y_arr = np.ones(l_date_name.shape)\n",
    "    # y_arr = y_arr * y\n",
    "    return y\n",
    "\n",
    "def interpolate1(array):\n",
    "    x_old = np.linspace(0, 1, array.shape[0])\n",
    "    y_old = array\n",
    "    \n",
    "    f = interpolate.interp1d(x_old, y_old)\n",
    "\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    y_new = f(x)\n",
    "    return y_new\n",
    "\n",
    "def zscore(x, axis = 1):\n",
    "    xmean = x.mean(axis=axis, keepdims=True)\n",
    "    xstd  = np.std(x, axis=axis, keepdims=True)\n",
    "    zscore = (x-xmean)/xstd\n",
    "    return zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ara = np.array([[[1,2,3,4,5],[4,5,6,7,8],[7,8,9,10,11]]])\n",
    "# ara.shape\n",
    "# z = zscore(ara)\n",
    "# print(z.shape)\n",
    "# print(ara)\n",
    "# print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# この関数を実行しさえすればデータセットが作成される\n",
    "def create_Xy(dataset):\n",
    "    #正解ラベルの作成\n",
    "    y = one_hot_enc(dataset)\n",
    "    \n",
    "    # Xの作成\n",
    "    l_date_name = np.array(dataset['date'].unique())\n",
    "    for k, date in enumerate(l_date_name):\n",
    "        #一連のデータ，1サンプル\n",
    "        series = dataset[dataset['date'] == l_date_name[k]]\n",
    "        series.drop(columns='point', inplace=True)\n",
    "        series.drop(columns='date', inplace=True)\n",
    "        #差分ベクトルを取得\n",
    "        diff = series.diff()\n",
    "        diff.fillna(0, inplace=True)\n",
    "\n",
    "        # 間接点同士のベクトルのカラムをデータフレームに追加\n",
    "        # これらがデータセットになる\n",
    "        diff = add_vector(diff, 'RElbow', \"RWrist\", 'v')\n",
    "        diff = add_vector(diff, 'RShoulder', \"RElbow\", 'v')\n",
    "        diff = add_vector(diff, 'Pelvis', \"RShoulder\", 'v')\n",
    "        diff = add_vector(diff, 'Pelvis', \"Neck\", 'v')\n",
    "        diff = add_vector(diff, 'Neck', 'RShoulder', 'v')\n",
    "        diff = add_vector(diff, 'Neck', 'LShoulder', 'v')\n",
    "        \n",
    "        # arr_data = diff.loc[:, columns].values\n",
    "        arr_data = diff.loc[:, \"v_x_RElbow2RWrist\":].values\n",
    "        \n",
    "        # 補間を行う\n",
    "        for i in range(arr_data.shape[1]):\n",
    "            tmp_interpolate = interpolate1(arr_data[:, i])\n",
    "            # print(tmp_interpolate.shape)\n",
    "            #二次元に拡張\n",
    "            tmp_interpolate = tmp_interpolate.reshape(tmp_interpolate.shape[0], 1)\n",
    "            if i == 0:\n",
    "                x = tmp_interpolate\n",
    "            else:\n",
    "                x = np.concatenate([x, tmp_interpolate],1)\n",
    "                \n",
    "        # サンプル数の次元を拡張する\n",
    "        x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "        \n",
    "        #最初だけ条件分岐\n",
    "        if k == 0:\n",
    "            X = x\n",
    "        else:\n",
    "            X = np.concatenate([X, x], axis=0)\n",
    "        \n",
    "       # 最後にzscore変換\n",
    "        X = zscore(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# validation用に1人のデータを検証データに回す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset[~(dataset['subject_id'] == 3)]\n",
    "val_df = dataset[dataset['subject_id'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kento/miniforge3/envs/torch/lib/python3.8/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = create_Xy(train_df)\n",
    "X_val, y_val = create_Xy(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 101, 24])\n",
      "torch.Size([35, 4])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (X_3, y_3) = create_Xy(pd_3)\n",
    "# (X_2, y_2) = create_Xy(pd_2A)\n",
    "# (X_1, y_1) = create_Xy(pd_2B)\n",
    "# (X_0, y_0) = create_Xy(pd_2C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataSetの結合\n",
    "# x_train = np.concatenate([X_3, X_2, X_1, X_0])\n",
    "# y_train = np.concatenate([y_3, y_2, y_1, y_0])\n",
    "# y_train = y_train.astype('int64')\n",
    "# x_test = np.concatenate([X_3, X_2, X_1, X_0])\n",
    "# y_test = np.concatenate([y_3, y_2, y_1, y_0])\n",
    "# y_test = y_test.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train\n",
    "y_train = y_train\n",
    "y_train = y_train.astype('int64')\n",
    "x_test = X_val\n",
    "y_test = y_val\n",
    "y_test = y_test.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2335,
     "status": "ok",
     "timestamp": 1636987414597,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "k9FusOpOct7Z",
    "outputId": "53480609-b57f-45a1-c988-5f330dc69d11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(np.unique(y_train))\n",
    "print(n_classes)\n",
    "\n",
    "y_train_onehot = np.identity(n_classes)[y_train]\n",
    "y_test_onehot = np.identity(n_classes)[y_test]\n",
    "# print(y_train_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PyTorchのdatasetの作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 先頭にclassification用のトークンを追加する\n",
    "score_train = np.zeros((x_train.shape[0], 1 , x_train.shape[2]))\n",
    "x_train = np.concatenate([score_train, x_train], axis=1)\n",
    "\n",
    "score_test = np.zeros((x_test.shape[0], 1 , x_test.shape[2]))\n",
    "x_test = np.concatenate([score_test, x_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(x_train, dtype=torch.float32)\n",
    "y = torch.tensor(y_train_onehot, dtype=torch.int8)\n",
    "\n",
    "X_val = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_test_onehot, dtype=torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1636987552788,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "xdm8NB-cYTpy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X, y)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1)\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1636987650297,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "8vf0x--aaZjE",
    "outputId": "57c2d515-00a5-443a-b22e-6fa77d359e84"
   },
   "outputs": [],
   "source": [
    "idx = np.random.permutation(len(x_train))\n",
    "x_train = x_train[idx]\n",
    "y_train = y_train[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxW659H6YTpz"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "Our model processes a tensor of shape `(batch size, sequence length, features)`,\n",
    "where `sequence length` is the number of time steps and `features` is each input\n",
    "timeseries.\n",
    "\n",
    "You can replace your classification RNN layers with this one: the\n",
    "inputs are fully compatible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urNK4ym-YTp0"
   },
   "source": [
    "We include residual connections, layer normalization, and dropout.\n",
    "The resulting layer can be stacked multiple times.\n",
    "\n",
    "The projection layers are implemented through `keras.layers.Conv1D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    '''入力された単語の位置を示すベクトル情報を付加する'''\n",
    "\n",
    "    def __init__(self, d_model=12, max_seq_len=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model  # 単語ベクトルの次元数\n",
    "\n",
    "        # 単語の順番（pos）と埋め込みベクトルの次元の位置（i）によって一意に定まる値の表をpeとして作成\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "\n",
    "        # GPUが使える場合はGPUへ送る、ここでは省略。実際に学習時には使用する\n",
    "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # pe = pe.to(device)\n",
    "\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                \n",
    "                # 誤植修正_200510 #79\n",
    "                # pe[pos, i + 1] = math.cos(pos /\n",
    "                #                          (10000 ** ((2 * (i + 1))/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos /\n",
    "                                          (10000 ** ((2 * i)/d_model)))\n",
    "\n",
    "        # 表peの先頭に、ミニバッチ次元となる次元を足す\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "        # 勾配を計算しないようにする\n",
    "        self.pe.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 入力xとPositonal Encodingを足し算する\n",
    "        # xがpeよりも小さいので、大きくする\n",
    "        ret = math.sqrt(self.d_model)*x + self.pe\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # SAGANでは1dConvを使用したが、今回は全結合層で特徴量を変換する\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # 出力時に使用する全結合層\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Attentionの大きさ調整の変数\n",
    "        self.d_k = d_model\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        # 全結合層で特徴量を変換\n",
    "        k = self.k_linear(k)\n",
    "        q = self.q_linear(q)\n",
    "        v = self.v_linear(v)\n",
    "\n",
    "        # Attentionの値を計算する\n",
    "        # 各値を足し算すると大きくなりすぎるので、root(d_k)で割って調整\n",
    "        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)\n",
    "\n",
    "        # ここでmaskを計算\n",
    "        # mask = mask.unsqueeze(1)\n",
    "        # print(mask)\n",
    "        # weights = weights.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # softmaxで規格化をする\n",
    "        normlized_weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "        # AttentionをValueとかけ算\n",
    "        output = torch.matmul(normlized_weights, v)\n",
    "\n",
    "        # 全結合層で特徴量を変換\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, normlized_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
    "        '''Attention層から出力を単純に全結合層2つで特徴量を変換するだけのユニットです'''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.dropout(F.relu(x))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # LayerNormalization層\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=layernorm\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Attention層\n",
    "        self.attn = Attention(d_model)\n",
    "\n",
    "        # Attentionのあとの全結合層2つ\n",
    "        self.ff = FeedForward(d_model)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # 正規化とAttention\n",
    "        # print(f\"input shape is {x.shape}\")\n",
    "        x_normlized = self.norm_1(x)\n",
    "        output, normlized_weights = self.attn(\n",
    "            x_normlized, x_normlized, x_normlized, mask)\n",
    "        \n",
    "        x2 = x + self.dropout_1(output)\n",
    "\n",
    "        # 正規化と全結合層\n",
    "        x_normlized2 = self.norm_2(x2)\n",
    "        output = x2 + self.dropout_2(self.ff(x_normlized2))\n",
    "        # print(f\"output shape is {output.shape}\")\n",
    "\n",
    "        return output, normlized_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringHead(nn.Module):\n",
    "    '''Transformer_Blockの出力を使用して，最後にスコアリングを行う'''\n",
    "    \n",
    "    def __init__(self, d_model=300, output_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # 全結合層\n",
    "        self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # 重み初期化処理\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n",
    "        x1 = self.linear(x0)\n",
    "        out = F.softmax(x1, dim=-1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    '''Transformer_Blockの出力を使用し、最後にクラス分類させる'''\n",
    "\n",
    "    def __init__(self, d_model=300, output_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # 全結合層\n",
    "        self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # 重み初期化処理\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n",
    "        x1 = self.linear(x0)\n",
    "        # print(x1.shape)\n",
    "        out = F.softmax(x1, dim=-1)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的なTransformerモデルのクラス\n",
    "\n",
    "class TransformerClassification(nn.Module):\n",
    "    '''Transformerでクラス分類させる'''\n",
    "\n",
    "    def __init__(self, d_model=12, max_seq_len=101, output_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # モデル構築\n",
    "        self.net_Positional = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
    "        self.net_Attention_1 = TransformerBlock(d_model=d_model)\n",
    "        # self.net3_2 = TransformerBlock(d_model=d_model)\n",
    "        self.net_Classification = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x1 = self.net_Positional(x)  # Positon情報を足し算\n",
    "        x2, normlized_weights_1 = self.net_Attention_1(x1, mask)  # Self-Attentionで特徴量を変換\n",
    "        # x3_2, normlized_weights_2 = self.net3_2(x3_1, mask)  # Self-Attentionで特徴量を変換\n",
    "        x3 = self.net_Classification(x2)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
    "        return x3, normlized_weights_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# validation用に1人のデータを検証データに回す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset[~(dataset['subject_id'] == 3)]\n",
    "val_df = dataset[dataset['subject_id'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_Xy(train_df)\n",
    "X_val, y_val = create_Xy(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 101, 24])\n",
      "torch.Size([35, 4])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train\n",
    "y_train = y_train\n",
    "y_train = y_train.astype('int64')\n",
    "x_test = X_val\n",
    "y_test = y_val\n",
    "y_test = y_test.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2335,
     "status": "ok",
     "timestamp": 1636987414597,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "k9FusOpOct7Z",
    "outputId": "53480609-b57f-45a1-c988-5f330dc69d11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(np.unique(y_train))\n",
    "print(n_classes)\n",
    "\n",
    "y_train_onehot = np.identity(n_classes)[y_train]\n",
    "y_test_onehot = np.identity(n_classes)[y_test]\n",
    "# print(y_train_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PyTorchのdatasetの作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 先頭にclassification用のトークンを追加する\n",
    "score_train = np.zeros((x_train.shape[0], 1 , x_train.shape[2]))\n",
    "x_train = np.concatenate([score_train, x_train], axis=1)\n",
    "\n",
    "score_test = np.zeros((x_test.shape[0], 1 , x_test.shape[2]))\n",
    "x_test = np.concatenate([score_test, x_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(x_train, dtype=torch.float32)\n",
    "y = torch.tensor(y_train_onehot, dtype=torch.int8)\n",
    "\n",
    "X_val = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_test_onehot, dtype=torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1636987552788,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "xdm8NB-cYTpy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X, y)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1)\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1636987650297,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "8vf0x--aaZjE",
    "outputId": "57c2d515-00a5-443a-b22e-6fa77d359e84"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yt/fsd0dzhn23z2jcmc2hrkjcn00000gn/T/ipykernel_9740/2268775.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Setup seeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup seeds\n",
    "np.random.seed(1234)\n",
    "idx = np.random.permutation(len(x_train))\n",
    "x_train = x_train[idx]\n",
    "y_train = y_train[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LakZIHM8YTp1"
   },
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力のテンソルサイズ： torch.Size([1, 4])\n",
      "出力テンソルのsigmoid： tensor([[0.2036, 0.3161, 0.2714, 0.2089]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 動作確認\n",
    "# ミニバッチの用意\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "# モデル構築\n",
    "net = TransformerClassification(\n",
    "    d_model=24, max_seq_len=101, output_dim=4)\n",
    "\n",
    "# 入出力\n",
    "x = batch[0]\n",
    "input_pad = 1\n",
    "input_mask = (x != input_pad)\n",
    "out, normlized_weights_1 = net(x, input_mask)\n",
    "\n",
    "print(\"出力のテンソルサイズ：\", out.shape)\n",
    "print(\"出力テンソルのsigmoid：\", F.softmax(out, dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elTTH_9KYTp0"
   },
   "source": [
    "The main part of our model is now complete. We can stack multiple of those\n",
    "`transformer_encoder` blocks and we can also proceed to add the final\n",
    "Multi-Layer Perceptron classification head. Apart from a stack of `Dense`\n",
    "layers, we need to reduce the output tensor of the `TransformerEncoder` part of\n",
    "our model down to a vector of features for each data point in the current\n",
    "batch. A common way to achieve this is to use a pooling layer. For\n",
    "this example, a `GlobalAveragePooling1D` layer is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ネットワーク設定完了\n"
     ]
    }
   ],
   "source": [
    "# ネットワークの初期化を定義\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        # Liner層の初期化\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "# 訓練モードに設定\n",
    "net.train()\n",
    "\n",
    "# TransformerBlockモジュールを初期化実行\n",
    "net.net_Attention_1.apply(weights_init)\n",
    "# net.net3_2.apply(weights_init)\n",
    "\n",
    "\n",
    "print('ネットワーク設定完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の設定\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n",
    "\n",
    "# 最適化手法の設定\n",
    "learning_rate = 3e-4\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "    print('-----start-------')\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "        # for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和\n",
    "            epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "            # データローダーからミニバッチを取り出すループ\n",
    "            for batch in (dataloaders_dict[phase]):\n",
    "                # batchはTextとLableの辞書オブジェクト\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                inputs = batch[0].to(device)  # 文章\n",
    "                labels = batch[1].to(device)  # ラベル\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    # mask作成\n",
    "                    input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "                    input_mask = (inputs != input_pad)\n",
    "\n",
    "                    # Transformerに入力\n",
    "                    outputs, _ = net(inputs, input_mask)\n",
    "                    # print(f\"outputs shape is {outputs.dtype}, label shape is {labels.float()}\")\n",
    "                    loss = criterion(outputs, labels.float())  # 損失を計算\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # 結果の計算\n",
    "                    # print(np.array(preds))\n",
    "                    # print(np.array(np.argmax(labels.data)))\n",
    "                    # print(preds == labels.data)\n",
    "                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n",
    "                    # 正解数の合計を更新\n",
    "                    epoch_corrects += torch.sum(preds == np.argmax(labels.data))\n",
    "\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "            else:\n",
    "                writer.add_scalar(\"Loss/test\", loss, epoch)\n",
    "\n",
    "            # epochごとのlossと正解率\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double(\n",
    "            ) / len(dataloaders_dict[phase].dataset)\n",
    "            # print(epoch_corrects.double())\n",
    "            # print(len(dataloaders_dict[phase].dataset))\n",
    "\n",
    "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
    "                                                                           phase, epoch_loss, epoch_acc))\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # グリッドサーチを行う．\n",
    "# l_rate = [2e-4, 3e-4, 4e-4, 5e-4]\n",
    "\n",
    "# for learning_rate in l_rate:\n",
    "#     print(learning_rate)\n",
    "#     # 訓練モードに設定\n",
    "#     net.train()\n",
    "\n",
    "#     # TransformerBlockモジュールを初期化実行\n",
    "#     net.net_Attention_1.apply(weights_init)\n",
    "#     net.net_Classification.apply(weights_init)\n",
    "    \n",
    "#     num_epochs = 300\n",
    "#     optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "#     net_trained = train_model(net, dataloaders_dict,\n",
    "#                           criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ネットワーク設定完了\n",
      "使用デバイス： cpu\n",
      "-----start-------\n",
      "Epoch 1/70 | train |  Loss: 1.4264 Acc: 0.2778\n",
      "Epoch 1/70 |  val  |  Loss: 1.3767 Acc: 0.2727\n",
      "Epoch 2/70 | train |  Loss: 1.4219 Acc: 0.2222\n",
      "Epoch 2/70 |  val  |  Loss: 1.3304 Acc: 0.3636\n",
      "Epoch 3/70 | train |  Loss: 1.3801 Acc: 0.2778\n",
      "Epoch 3/70 |  val  |  Loss: 1.3126 Acc: 0.3636\n",
      "Epoch 4/70 | train |  Loss: 1.3752 Acc: 0.3333\n",
      "Epoch 4/70 |  val  |  Loss: 1.3024 Acc: 0.4545\n",
      "Epoch 5/70 | train |  Loss: 1.3679 Acc: 0.3889\n",
      "Epoch 5/70 |  val  |  Loss: 1.3074 Acc: 0.4545\n",
      "Epoch 6/70 | train |  Loss: 1.3236 Acc: 0.4722\n",
      "Epoch 6/70 |  val  |  Loss: 1.2959 Acc: 0.4545\n",
      "Epoch 7/70 | train |  Loss: 1.3578 Acc: 0.4444\n",
      "Epoch 7/70 |  val  |  Loss: 1.2907 Acc: 0.4545\n",
      "Epoch 8/70 | train |  Loss: 1.3376 Acc: 0.3611\n",
      "Epoch 8/70 |  val  |  Loss: 1.2831 Acc: 0.4545\n",
      "Epoch 9/70 | train |  Loss: 1.3258 Acc: 0.4167\n",
      "Epoch 9/70 |  val  |  Loss: 1.2836 Acc: 0.4545\n",
      "Epoch 10/70 | train |  Loss: 1.3090 Acc: 0.4722\n",
      "Epoch 10/70 |  val  |  Loss: 1.2720 Acc: 0.4545\n",
      "Epoch 11/70 | train |  Loss: 1.3072 Acc: 0.5000\n",
      "Epoch 11/70 |  val  |  Loss: 1.2739 Acc: 0.4545\n",
      "Epoch 12/70 | train |  Loss: 1.2994 Acc: 0.3889\n",
      "Epoch 12/70 |  val  |  Loss: 1.2736 Acc: 0.4545\n",
      "Epoch 13/70 | train |  Loss: 1.2403 Acc: 0.5000\n",
      "Epoch 13/70 |  val  |  Loss: 1.2666 Acc: 0.4545\n",
      "Epoch 14/70 | train |  Loss: 1.2587 Acc: 0.5278\n",
      "Epoch 14/70 |  val  |  Loss: 1.2621 Acc: 0.4545\n",
      "Epoch 15/70 | train |  Loss: 1.2932 Acc: 0.4722\n",
      "Epoch 15/70 |  val  |  Loss: 1.2368 Acc: 0.4545\n",
      "Epoch 16/70 | train |  Loss: 1.2032 Acc: 0.6111\n",
      "Epoch 16/70 |  val  |  Loss: 1.2321 Acc: 0.4545\n",
      "Epoch 17/70 | train |  Loss: 1.2235 Acc: 0.5556\n",
      "Epoch 17/70 |  val  |  Loss: 1.2329 Acc: 0.4545\n",
      "Epoch 18/70 | train |  Loss: 1.2599 Acc: 0.5278\n",
      "Epoch 18/70 |  val  |  Loss: 1.2283 Acc: 0.4545\n",
      "Epoch 19/70 | train |  Loss: 1.2365 Acc: 0.4722\n",
      "Epoch 19/70 |  val  |  Loss: 1.2311 Acc: 0.4545\n",
      "Epoch 20/70 | train |  Loss: 1.2408 Acc: 0.5000\n",
      "Epoch 20/70 |  val  |  Loss: 1.2320 Acc: 0.4545\n",
      "Epoch 21/70 | train |  Loss: 1.1978 Acc: 0.5833\n",
      "Epoch 21/70 |  val  |  Loss: 1.2223 Acc: 0.4545\n",
      "Epoch 22/70 | train |  Loss: 1.1920 Acc: 0.5833\n",
      "Epoch 22/70 |  val  |  Loss: 1.2016 Acc: 0.5455\n",
      "Epoch 23/70 | train |  Loss: 1.2031 Acc: 0.5556\n",
      "Epoch 23/70 |  val  |  Loss: 1.1958 Acc: 0.5455\n",
      "Epoch 24/70 | train |  Loss: 1.1567 Acc: 0.6111\n",
      "Epoch 24/70 |  val  |  Loss: 1.1891 Acc: 0.5455\n",
      "Epoch 25/70 | train |  Loss: 1.1463 Acc: 0.6667\n",
      "Epoch 25/70 |  val  |  Loss: 1.1898 Acc: 0.4545\n",
      "Epoch 26/70 | train |  Loss: 1.1547 Acc: 0.6667\n",
      "Epoch 26/70 |  val  |  Loss: 1.1953 Acc: 0.5455\n",
      "Epoch 27/70 | train |  Loss: 1.1958 Acc: 0.5556\n",
      "Epoch 27/70 |  val  |  Loss: 1.1937 Acc: 0.5455\n",
      "Epoch 28/70 | train |  Loss: 1.1468 Acc: 0.5833\n",
      "Epoch 28/70 |  val  |  Loss: 1.1758 Acc: 0.5455\n",
      "Epoch 29/70 | train |  Loss: 1.1161 Acc: 0.6944\n",
      "Epoch 29/70 |  val  |  Loss: 1.1737 Acc: 0.5455\n",
      "Epoch 30/70 | train |  Loss: 1.1637 Acc: 0.5833\n",
      "Epoch 30/70 |  val  |  Loss: 1.1725 Acc: 0.5455\n",
      "Epoch 31/70 | train |  Loss: 1.1157 Acc: 0.6667\n",
      "Epoch 31/70 |  val  |  Loss: 1.1781 Acc: 0.5455\n",
      "Epoch 32/70 | train |  Loss: 1.0947 Acc: 0.6944\n",
      "Epoch 32/70 |  val  |  Loss: 1.1570 Acc: 0.5455\n",
      "Epoch 33/70 | train |  Loss: 1.0684 Acc: 0.6944\n",
      "Epoch 33/70 |  val  |  Loss: 1.1481 Acc: 0.5455\n",
      "Epoch 34/70 | train |  Loss: 1.0899 Acc: 0.6944\n",
      "Epoch 34/70 |  val  |  Loss: 1.1609 Acc: 0.5455\n",
      "Epoch 35/70 | train |  Loss: 1.0436 Acc: 0.7222\n",
      "Epoch 35/70 |  val  |  Loss: 1.1460 Acc: 0.5455\n",
      "Epoch 36/70 | train |  Loss: 1.0610 Acc: 0.7222\n",
      "Epoch 36/70 |  val  |  Loss: 1.1319 Acc: 0.5455\n",
      "Epoch 37/70 | train |  Loss: 1.0832 Acc: 0.6944\n",
      "Epoch 37/70 |  val  |  Loss: 1.1215 Acc: 0.5455\n",
      "Epoch 38/70 | train |  Loss: 1.0855 Acc: 0.6667\n",
      "Epoch 38/70 |  val  |  Loss: 1.1200 Acc: 0.5455\n",
      "Epoch 39/70 | train |  Loss: 1.0393 Acc: 0.7222\n",
      "Epoch 39/70 |  val  |  Loss: 1.1182 Acc: 0.5455\n",
      "Epoch 40/70 | train |  Loss: 1.0442 Acc: 0.7500\n",
      "Epoch 40/70 |  val  |  Loss: 1.0887 Acc: 0.7273\n",
      "Epoch 41/70 | train |  Loss: 0.9992 Acc: 0.7778\n",
      "Epoch 41/70 |  val  |  Loss: 1.0650 Acc: 0.7273\n",
      "Epoch 42/70 | train |  Loss: 1.0226 Acc: 0.7778\n",
      "Epoch 42/70 |  val  |  Loss: 1.0643 Acc: 0.7273\n",
      "Epoch 43/70 | train |  Loss: 1.0357 Acc: 0.7778\n",
      "Epoch 43/70 |  val  |  Loss: 1.0665 Acc: 0.7273\n",
      "Epoch 44/70 | train |  Loss: 1.0101 Acc: 0.7778\n",
      "Epoch 44/70 |  val  |  Loss: 1.0784 Acc: 0.7273\n",
      "Epoch 45/70 | train |  Loss: 1.0155 Acc: 0.7778\n",
      "Epoch 45/70 |  val  |  Loss: 1.0510 Acc: 0.7273\n",
      "Epoch 46/70 | train |  Loss: 1.0197 Acc: 0.8056\n",
      "Epoch 46/70 |  val  |  Loss: 1.0745 Acc: 0.6364\n",
      "Epoch 47/70 | train |  Loss: 1.0058 Acc: 0.8056\n",
      "Epoch 47/70 |  val  |  Loss: 1.0426 Acc: 0.8182\n",
      "Epoch 48/70 | train |  Loss: 0.9954 Acc: 0.8056\n",
      "Epoch 48/70 |  val  |  Loss: 1.0440 Acc: 0.7273\n",
      "Epoch 49/70 | train |  Loss: 0.9861 Acc: 0.8056\n",
      "Epoch 49/70 |  val  |  Loss: 1.0364 Acc: 0.8182\n",
      "Epoch 50/70 | train |  Loss: 0.9780 Acc: 0.8611\n",
      "Epoch 50/70 |  val  |  Loss: 1.0451 Acc: 0.7273\n",
      "Epoch 51/70 | train |  Loss: 0.9523 Acc: 0.8611\n",
      "Epoch 51/70 |  val  |  Loss: 1.0296 Acc: 0.8182\n",
      "Epoch 52/70 | train |  Loss: 0.9966 Acc: 0.7778\n",
      "Epoch 52/70 |  val  |  Loss: 1.0351 Acc: 0.8182\n",
      "Epoch 53/70 | train |  Loss: 0.9664 Acc: 0.8333\n",
      "Epoch 53/70 |  val  |  Loss: 1.0280 Acc: 0.8182\n",
      "Epoch 54/70 | train |  Loss: 0.9789 Acc: 0.8056\n",
      "Epoch 54/70 |  val  |  Loss: 1.0284 Acc: 0.8182\n",
      "Epoch 55/70 | train |  Loss: 0.9698 Acc: 0.8333\n",
      "Epoch 55/70 |  val  |  Loss: 0.9937 Acc: 0.8182\n",
      "Epoch 56/70 | train |  Loss: 0.9868 Acc: 0.8333\n",
      "Epoch 56/70 |  val  |  Loss: 1.0228 Acc: 0.7273\n",
      "Epoch 57/70 | train |  Loss: 0.9382 Acc: 0.8611\n",
      "Epoch 57/70 |  val  |  Loss: 1.0237 Acc: 0.8182\n",
      "Epoch 58/70 | train |  Loss: 0.9582 Acc: 0.8333\n",
      "Epoch 58/70 |  val  |  Loss: 1.0151 Acc: 0.8182\n",
      "Epoch 59/70 | train |  Loss: 0.9459 Acc: 0.8611\n",
      "Epoch 59/70 |  val  |  Loss: 1.0236 Acc: 0.8182\n",
      "Epoch 60/70 | train |  Loss: 0.9586 Acc: 0.8333\n",
      "Epoch 60/70 |  val  |  Loss: 0.9933 Acc: 0.8182\n",
      "Epoch 61/70 | train |  Loss: 0.9540 Acc: 0.8056\n",
      "Epoch 61/70 |  val  |  Loss: 1.0132 Acc: 0.8182\n",
      "Epoch 62/70 | train |  Loss: 0.9807 Acc: 0.8056\n",
      "Epoch 62/70 |  val  |  Loss: 1.0071 Acc: 0.8182\n",
      "Epoch 63/70 | train |  Loss: 0.9198 Acc: 0.8611\n",
      "Epoch 63/70 |  val  |  Loss: 1.0059 Acc: 0.8182\n",
      "Epoch 64/70 | train |  Loss: 0.9399 Acc: 0.8333\n",
      "Epoch 64/70 |  val  |  Loss: 0.9978 Acc: 0.8182\n",
      "Epoch 65/70 | train |  Loss: 0.9328 Acc: 0.8333\n",
      "Epoch 65/70 |  val  |  Loss: 1.0164 Acc: 0.8182\n",
      "Epoch 66/70 | train |  Loss: 0.9340 Acc: 0.8611\n",
      "Epoch 66/70 |  val  |  Loss: 1.0271 Acc: 0.7273\n",
      "Epoch 67/70 | train |  Loss: 0.9298 Acc: 0.8611\n",
      "Epoch 67/70 |  val  |  Loss: 1.0165 Acc: 0.8182\n",
      "Epoch 68/70 | train |  Loss: 0.9293 Acc: 0.8611\n",
      "Epoch 68/70 |  val  |  Loss: 1.0080 Acc: 0.8182\n",
      "Epoch 69/70 | train |  Loss: 0.9214 Acc: 0.8611\n",
      "Epoch 69/70 |  val  |  Loss: 1.0094 Acc: 0.8182\n",
      "Epoch 70/70 | train |  Loss: 0.9273 Acc: 0.8333\n",
      "Epoch 70/70 |  val  |  Loss: 1.0245 Acc: 0.8182\n"
     ]
    }
   ],
   "source": [
    "# 学習・検証を実行する 15分ほどかかります\n",
    "\n",
    "# 訓練モードに設定\n",
    "net.train()\n",
    "\n",
    "\n",
    "# 損失関数の設定\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n",
    "\n",
    "# 最適化手法の設定\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# TransformerBlockモジュールを初期化実行\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "troch.cuda.manual_seed(1234)\n",
    "net.net_Attention_1.apply(weights_init)\n",
    "print('ネットワーク設定完了')\n",
    "\n",
    "num_epochs = 70\n",
    "net_trained = train_model(net, dataloaders_dict,\n",
    "                          criterion, optimizer, num_epochs=num_epochs)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN2SeFtLHbyT"
   },
   "source": [
    "# SaveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テストデータ36個での正解率：0.9722\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net_trained.eval()   # モデルを検証モードに\n",
    "net_trained.to(device)\n",
    "\n",
    "epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "# test_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=60)\n",
    "test_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=60)\n",
    "\n",
    "for batch in (test_dataloader):  # testデータのDataLoader\n",
    "    # batchはTextとLableの辞書オブジェクト\n",
    "    \n",
    "    # GPUが使えるならGPUにデータを送る\n",
    "    inputs = batch[0].to(device)  # 文章\n",
    "    labels = batch[1].to(device)  # ラベル\n",
    "\n",
    "    # 順伝搬（forward）計算\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        # mask作成\n",
    "        input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "        input_mask = (inputs != input_pad)\n",
    "\n",
    "        # Transformerに入力\n",
    "        outputs, attn_weights1 = net_trained(inputs, input_mask)\n",
    "        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "\n",
    "        # 結果の計算\n",
    "        # 正解数の合計を更新\n",
    "        # print(torch.argmax(labels.data, ))\n",
    "        epoch_corrects += torch.sum(preds == torch.argmax(labels.data, dim=1))\n",
    "\n",
    "# 正解率\n",
    "epoch_acc = epoch_corrects.double() / len(test_dataloader.dataset)\n",
    "\n",
    "print('テストデータ{}個での正解率：{:.4f}'.format(len(test_dataloader.dataset),epoch_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 2 1 2 1 1 1 0 0 0 3 3 3 2 2 2 1 1 1 0 0 0 3 3 3 2 2 2 1 1 1 0 0 0]\n",
      "[3 3 3 2 2 2 1 1 1 0 0 0 3 3 3 2 2 2 1 1 1 0 0 0 3 3 3 2 2 2 1 1 1 0 0 0]\n",
      "[[9 0 0 0]\n",
      " [0 9 0 0]\n",
      " [0 1 8 0]\n",
      " [0 0 0 9]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "preds_heat = np.array(preds)\n",
    "trues_heat = np.array(torch.argmax(labels.data, dim=1))\n",
    "# preds_heat[0] = \"3A\"\n",
    "print(preds_heat)\n",
    "print(trues_heat)\n",
    "\n",
    "heat = confusion_matrix(trues_heat, preds_heat)\n",
    "print(heat)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"   # 使用するフォント\n",
    "plt.rcParams[\"font.size\"] = 20        \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "xtics = [\"2C\", \"2B\", \"2A\", \"3\"]\n",
    "ytics = [\"2C\", \"2B\", \"2A\", \"3\"]\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(heat, annot=True, xticklabels=xtics, yticklabels=ytics, cmap=\"Blues\", cbar=False)\n",
    "# sns.heatmap(heat, annot=True, cmap=\"Blues\", cbar=False)\n",
    "#*以下2行がポイント*  X,Y軸ラベルを追加\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "#グラフをはみ出さないようにして画面に出力\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"nn-heatmap_3.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(np.array(X[0, 1:, 0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_weight = np.array(attn_weights1[15, 0, 1:]).reshape(1, -1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 1))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(extract_weight, cmap='OrRd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "extract_data = np.array(X[19, 1:, 2]).flatten()\n",
    "print(extract_data.shape)\n",
    "\n",
    "\n",
    "time = np.linspace(0, 100, 100)\n",
    "fig, ax = plt.subplots(2, 1, gridspec_kw={'height_ratios': [6, 1]}, figsize=(15,10))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.lineplot(time, extract_data, ax=ax[0])\n",
    "sns.heatmap(extract_weight, cmap='OrRd', cbar=False, ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data = np.array(attn_weights1[:, 0, :])\n",
    "print(data.shape)\n",
    "data = data.reshape(attn_weights1.shape[0], -1)\n",
    "\n",
    "# print(outputs)\n",
    "print(data.shape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 20))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(data, cmap='OrRd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data[0])):\n",
    "    print(data[0,i], end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_trained.net_Attention_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelの読み込みだけ\n",
    "# 保存したモデルパラメータの読み込み\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net_trained = TransformerClassification().to(device)\n",
    "\n",
    "net_trained.load_state_dict(torch.load('highacc2.pth'))\n",
    "# print('読み込み後のモデル:\\n', model2.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(net_trained.state_dict(), 'highacc3.pth')\n",
    "\n",
    "# 新しいモデル\n",
    "model2 = TransformerClassification().to(device)\n",
    "print('新しいモデル:\\n', model2.state_dict())\n",
    "\n",
    "# 保存したモデルパラメータの読み込み\n",
    "model2.load_state_dict(torch.load('highacc3.pth'))\n",
    "print('読み込み後のモデル:\\n', model2.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention weight の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "print(data)\n",
    "print(data.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 同時に入れるデータも作成する\n",
    "# これは時系列スタンプ．0〜100がサンプル数だけ作られる\n",
    "stamp_row = [i%data.shape[1] for i in range(data.shape[0] * data.shape[1])]\n",
    "\n",
    "# いつ撮影されたのかのスタンプ\n",
    "l_date_name = np.array(df_annotate['date'].unique())\n",
    "date_row = []\n",
    "for item in l_date_name:\n",
    "    for i in range(data.shape[1]):\n",
    "        date_row.append(item)\n",
    "        \n",
    "# アテンションウエイト\n",
    "attn_weight = data.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attn = pd.DataFrame()\n",
    "df_attn['date'] = date_row\n",
    "df_attn[\"stamp\"] = stamp_row\n",
    "df_attn[\"attn_weight\"] = attn_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attn.to_excel('/Users/kento/kuhp/experiment/attention_validate_weights.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_attn['date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "timeseries_transformer_classification.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/keras-team/keras-io/blob/master/examples/timeseries/ipynb/timeseries_classification_transformer.ipynb",
     "timestamp": 1636355482830
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
