{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyRQwYrEYTpv"
   },
   "source": [
    "# 修士論文実験 2022/01/10\n",
    "## マルチモーダルに挑戦\n",
    "## (validationが簡単に行えるようにデータセットを操作するモジュールを拡充)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 843,
     "status": "ok",
     "timestamp": 1636987406075,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "dO5GxI7RzXIc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# sys.path.append(os.path.abspath(\"..\"))\n",
    "# import scripts.compensate\n",
    "# import scripts.kinectImg2video\n",
    "# from scripts.conpemsate_suppresser import *\n",
    "# from scripts.ground_angle_analysis import ground_shoulder_angle_analyzer\n",
    "# import scripts.ground_angle_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日付の追加\n",
    "df_annotate = pd.read_excel(\"/Users/kento/kuhp/experiment/annotate_dataset.xlsx\")\n",
    "df_annotate['date'] = pd.to_datetime(df_annotate['date'], format='%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>uid</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>point</th>\n",
       "      <th>shoulder</th>\n",
       "      <th>body</th>\n",
       "      <th>flag_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-06 18:56:20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-06 18:56:20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-06 18:56:41</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-06 18:56:41</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-06 18:56:58</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  uid  subject_id  task_id point  shoulder  body  \\\n",
       "0 2021-12-06 18:56:20    1           1        1     3         0     0   \n",
       "1 2021-12-06 18:56:20    2           1        1     4         0     0   \n",
       "2 2021-12-06 18:56:41    3           1        1     3         0     0   \n",
       "3 2021-12-06 18:56:41    4           1        1     4         0     0   \n",
       "4 2021-12-06 18:56:58    5           1        1     3         0     0   \n",
       "\n",
       "   flag_usage  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           2  \n",
       "4           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>x_Pelvis</th>\n",
       "      <th>y_Pelvis</th>\n",
       "      <th>z_Pelvis</th>\n",
       "      <th>x_SpineNaval</th>\n",
       "      <th>y_SpineNaval</th>\n",
       "      <th>z_SpineNaval</th>\n",
       "      <th>x_SpineChest</th>\n",
       "      <th>...</th>\n",
       "      <th>x_REar</th>\n",
       "      <th>y_REar</th>\n",
       "      <th>z_REar</th>\n",
       "      <th>N</th>\n",
       "      <th>v_RWrist</th>\n",
       "      <th>z_v_RWrist</th>\n",
       "      <th>flag_active</th>\n",
       "      <th>flag_moving</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-158.973129</td>\n",
       "      <td>353.261841</td>\n",
       "      <td>698.233093</td>\n",
       "      <td>-149.886017</td>\n",
       "      <td>218.100922</td>\n",
       "      <td>780.778748</td>\n",
       "      <td>-142.035919</td>\n",
       "      <td>...</td>\n",
       "      <td>-178.933960</td>\n",
       "      <td>-236.272278</td>\n",
       "      <td>842.268127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.917988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-156.911919</td>\n",
       "      <td>356.031863</td>\n",
       "      <td>697.378637</td>\n",
       "      <td>-147.957493</td>\n",
       "      <td>219.063530</td>\n",
       "      <td>781.238292</td>\n",
       "      <td>-142.348493</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.788628</td>\n",
       "      <td>-241.853940</td>\n",
       "      <td>862.009244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.131710</td>\n",
       "      <td>0.480634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.891892</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-157.406120</td>\n",
       "      <td>356.970863</td>\n",
       "      <td>697.867036</td>\n",
       "      <td>-148.184343</td>\n",
       "      <td>219.214968</td>\n",
       "      <td>781.799317</td>\n",
       "      <td>-142.899719</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.093690</td>\n",
       "      <td>-243.703880</td>\n",
       "      <td>867.831643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.690953</td>\n",
       "      <td>0.198082</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.783784</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-159.493486</td>\n",
       "      <td>356.687710</td>\n",
       "      <td>699.214911</td>\n",
       "      <td>-149.753131</td>\n",
       "      <td>218.849632</td>\n",
       "      <td>782.412353</td>\n",
       "      <td>-143.553739</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.457427</td>\n",
       "      <td>-243.071735</td>\n",
       "      <td>864.096621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.280899</td>\n",
       "      <td>0.313779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.675676</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-162.211771</td>\n",
       "      <td>355.791270</td>\n",
       "      <td>700.938883</td>\n",
       "      <td>-151.850422</td>\n",
       "      <td>218.261918</td>\n",
       "      <td>783.027933</td>\n",
       "      <td>-144.174692</td>\n",
       "      <td>...</td>\n",
       "      <td>-177.488121</td>\n",
       "      <td>-241.207140</td>\n",
       "      <td>855.165480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.247976</td>\n",
       "      <td>0.307322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.567568</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1   id    x_Pelvis    y_Pelvis    z_Pelvis  \\\n",
       "0           0             0  1.0 -158.973129  353.261841  698.233093   \n",
       "1           1             1  1.0 -156.911919  356.031863  697.378637   \n",
       "2           2             2  1.0 -157.406120  356.970863  697.867036   \n",
       "3           3             3  1.0 -159.493486  356.687710  699.214911   \n",
       "4           4             4  1.0 -162.211771  355.791270  700.938883   \n",
       "\n",
       "   x_SpineNaval  y_SpineNaval  z_SpineNaval  x_SpineChest  ...      x_REar  \\\n",
       "0   -149.886017    218.100922    780.778748   -142.035919  ... -178.933960   \n",
       "1   -147.957493    219.063530    781.238292   -142.348493  ... -176.788628   \n",
       "2   -148.184343    219.214968    781.799317   -142.899719  ... -176.093690   \n",
       "3   -149.753131    218.849632    782.412353   -143.553739  ... -176.457427   \n",
       "4   -151.850422    218.261918    783.027933   -144.174692  ... -177.488121   \n",
       "\n",
       "       y_REar      z_REar   N  v_RWrist  z_v_RWrist  flag_active  flag_moving  \\\n",
       "0 -236.272278  842.268127 NaN       NaN   -0.917988          0.0          1.0   \n",
       "1 -241.853940  862.009244 NaN  7.131710    0.480634          1.0          1.0   \n",
       "2 -243.703880  867.831643 NaN  5.690953    0.198082          1.0          1.0   \n",
       "3 -243.071735  864.096621 NaN  6.280899    0.313779          1.0          1.0   \n",
       "4 -241.207140  855.165480 NaN  6.247976    0.307322          1.0          1.0   \n",
       "\n",
       "    timestamp                date  \n",
       "0    0.000000 2021-12-04 18:20:18  \n",
       "1   39.891892 2021-12-04 18:20:18  \n",
       "2   79.783784 2021-12-04 18:20:18  \n",
       "3  119.675676 2021-12-04 18:20:18  \n",
       "4  159.567568 2021-12-04 18:20:18  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataSetの呼び出し\n",
    "df_data = pd.read_csv(\"/Users/kento/kuhp/experiment/bigdata_trimmed.csv\")\n",
    "df_data['date'] = pd.to_datetime(df_data['date'], format='%Y-%m-%d-%H-%M-%S')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1636987406076,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "GZlVgJy1zXIc"
   },
   "outputs": [],
   "source": [
    "# pd_merged = pd.merge(df_annotate, df_data, on='date', how='inner')\n",
    "# pd_3 = pd_merged[pd_merged['point'] == 3]\n",
    "# pd_2A = pd_merged[pd_merged['point'] == '2A']\n",
    "# pd_2B = pd_merged[pd_merged['point'] == '2B']\n",
    "# pd_2C = pd_merged[pd_merged['point'] == '2C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### このデータセットはGraspのものかつ，usageが1のものが取り出されている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# データセットにNN入力用のスコアを割り振る．\n",
    "# これが正解ラベルになる\n",
    "dataset = pd.merge(df_annotate, df_data, on='date', how='inner')\n",
    "\n",
    "dataset = dataset[(dataset['task_id'] == 1) & (dataset['flag_usage'] == 1)]\n",
    "dataset['point'] = dataset['point'].astype(str)\n",
    "dataset.loc[dataset['point'] == '3', 'score'] = 3\n",
    "dataset.loc[dataset['point'] == '2A', 'score'] = 2\n",
    "dataset.loc[dataset['point'] == '2B', 'score'] = 1\n",
    "dataset.loc[dataset['point'] == '2C', 'score'] = 0\n",
    "print(dataset['score'].max())\n",
    "\n",
    "# Nanのものを削除\n",
    "dataset.dropna(subset=['score'], inplace=True)\n",
    "# scoreの行をintにする\n",
    "dataset['score'] = dataset['score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['uid'].unique()\n",
    "dataset['date'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grasp動作だけを抜き出す\n",
    "# dataset_grasp = dataset[dataset['task_id'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RElbow2RWrist と Rshoulder2RElbow と Pelvis2RShoulder と Pelvis2Neck の速度を入れてみる "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_annotate\n",
    "# l_date = df_annotate['date'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vector(df, joint1, joint2, word=\"\"):\n",
    "    df[f\"{word}_x_{joint1}2{joint2}\"] = df[f\"x_{joint1}\"].astype('float64') - df[f\"x_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_y_{joint1}2{joint2}\"] = df[f\"y_{joint1}\"].astype('float64') - df[f\"y_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_z_{joint1}2{joint2}\"] = df[f\"z_{joint1}\"].astype('float64') - df[f\"z_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_ave_{joint1}2{joint2}\"] = (df[f\"{word}_x_{joint1}2{joint2}\"] + df[f\"{word}_y_{joint1}2{joint2}\"] + df[f\"{word}_z_{joint1}2{joint2}\"])/3\n",
    "    return df\n",
    "\n",
    "def calc_angle(df, joint1, joint2, joint3):\n",
    "    l_theta = []\n",
    "    # 角度を算出する関数。p2を支点として、他の二点間の角度を算出する。\n",
    "    x1, y1 ,z1= df[f\"x_{joint1}\"].astype('float64'), df[f\"y_{joint1}\"].astype('float64'), df[f\"z_{joint1}\"].astype('float64')\n",
    "    x2, y2 ,z2= df[f\"x_{joint2}\"].astype('float64'), df[f\"y_{joint2}\"].astype('float64'), df[f\"z_{joint2}\"].astype('float64')\n",
    "    x3, y3 ,z3= df[f\"x_{joint3}\"].astype('float64'), df[f\"y_{joint3}\"].astype('float64'), df[f\"z_{joint3}\"].astype('float64')\n",
    "    v1 = np.array([x1-x2, y1-y2, z1-z2])\n",
    "    v2 = np.array([x3-x2, y3-y2, z3-z2])\n",
    "    for i in range(v1.shape[1]):\n",
    "        cos = np.dot(v1[:,i], v2[:,i])/(np.linalg.norm(v1[:,i], ord=2) * np.linalg.norm(v2[:,i], ord=2))\n",
    "        theta = np.degrees(math.acos(cos))\n",
    "        l_theta.append(theta)\n",
    "    return np.array(l_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 角度と角度の速度を入力とする\n",
    "angle_RElbow = calc_angle(dataset, 'RShoulder', 'RElbow', 'RWrist')\n",
    "diff_angle_RElbow = np.diff(angle_RElbow)\n",
    "\n",
    "angle_RShoulder = calc_angle(dataset, 'RElbow', 'RShoulder', 'Neck')\n",
    "diff_angle_RShoulder = np.diff(angle_RShoulder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_date_name = np.array(dataset['date'].unique())\n",
    "# l = []\n",
    "# for date in l_date_name:\n",
    "#     score = dataset[dataset[\"date\"] == date]['score'].mode()\n",
    "#     l.append(score)\n",
    "# return np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解ラベルで用いるyのone hotベクトルを作成\n",
    "def one_hot_enc(df):\n",
    "    l = []\n",
    "    l_date_name = np.array(df['date'].unique())\n",
    "    for date in l_date_name:\n",
    "        score = df[df[\"date\"] == date]['score'].mode()\n",
    "        l.append(score)\n",
    "    y = np.array(l).flatten()\n",
    "    \n",
    "    # l_date_name = np.array(df['date'].unique())\n",
    "    # y = np.array(df[\"score\"]) #一番多いものをscoreとして最後にyとして返す\n",
    "    # y_arr = np.ones(l_date_name.shape)\n",
    "    # y_arr = y_arr * y\n",
    "    return y\n",
    "\n",
    "def interpolate1(array):\n",
    "    x_old = np.linspace(0, 1, array.shape[0])\n",
    "    y_old = array\n",
    "    \n",
    "    f = interpolate.interp1d(x_old, y_old)\n",
    "\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    y_new = f(x)\n",
    "    return y_new\n",
    "\n",
    "def zscore(x, axis = 1):\n",
    "    xmean = x.mean(axis=axis, keepdims=True)\n",
    "    xstd  = np.std(x, axis=axis, keepdims=True)\n",
    "    zscore = (x-xmean)/xstd\n",
    "    return zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ara = np.array([[[1,2,3,4,5],[4,5,6,7,8],[7,8,9,10,11]]])\n",
    "# ara.shape\n",
    "# z = zscore(ara)\n",
    "# print(z.shape)\n",
    "# print(ara)\n",
    "# print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# この関数を実行しさえすればデータセットが作成される\n",
    "def create_Xy(dataset):\n",
    "    #正解ラベルの作成\n",
    "    y = one_hot_enc(dataset)\n",
    "    \n",
    "    # Xの作成\n",
    "    l_date_name = np.array(dataset['date'].unique())\n",
    "    for k, date in enumerate(l_date_name):\n",
    "        #一連のデータ，1サンプル\n",
    "        series = dataset[dataset['date'] == l_date_name[k]]\n",
    "        series.drop(columns='point', inplace=True)\n",
    "        series.drop(columns='date', inplace=True)\n",
    "        #差分ベクトルを取得\n",
    "        diff = series.diff()\n",
    "        diff.fillna(0, inplace=True)\n",
    "\n",
    "        # 間接点同士のベクトルのカラムをデータフレームに追加\n",
    "        # これらがデータセットになる\n",
    "        diff = add_vector(diff, 'RElbow', \"RWrist\", 'v')\n",
    "        diff = add_vector(diff, 'RShoulder', \"RElbow\", 'v')\n",
    "        diff = add_vector(diff, 'Pelvis', \"RShoulder\", 'v')\n",
    "        diff = add_vector(diff, 'Pelvis', \"Neck\", 'v')\n",
    "        diff = add_vector(diff, 'Neck', 'RShoulder', 'v')\n",
    "        diff = add_vector(diff, 'Neck', 'LShoulder', 'v')\n",
    "        \n",
    "#         diff['x_angle_RElbow'] = angle_RElbow\n",
    "#         diff['x2_angle_RElbow'] = angle_RElbow\n",
    "#         diff['x_diff_angle_RElbow'] = diff_angle_RElbow\n",
    "#         diff['diff_angle_RElbow2'] = diff_angle_RElbow\n",
    "        \n",
    "#         diff['angle_RShoulder'] = angle_RShoulder\n",
    "#         diff['angle_RShoulder2'] = angle_RShoulder\n",
    "#         diff['diff_angle_RShoulder'] = diff_angle_RShoulder\n",
    "#         diff['diff_angle_RShoulder2'] = diff_angle_RShoulder\n",
    "        \n",
    "        # arr_data = diff.loc[:, columns].values\n",
    "        arr_data = diff.loc[:, \"v_x_RElbow2RWrist\":].values\n",
    "        \n",
    "        # 補間を行う\n",
    "        for i in range(arr_data.shape[1]):\n",
    "            tmp_interpolate = interpolate1(arr_data[:, i])\n",
    "            # print(tmp_interpolate.shape)\n",
    "            #二次元に拡張\n",
    "            tmp_interpolate = tmp_interpolate.reshape(tmp_interpolate.shape[0], 1)\n",
    "            if i == 0:\n",
    "                x = tmp_interpolate\n",
    "            else:\n",
    "                x = np.concatenate([x, tmp_interpolate],1)\n",
    "                \n",
    "        # サンプル数の次元を拡張する\n",
    "        x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "        \n",
    "        #最初だけ条件分岐\n",
    "        if k == 0:\n",
    "            X = x\n",
    "        else:\n",
    "            X = np.concatenate([X, x], axis=0)\n",
    "        \n",
    "       # 最後にzscore変換\n",
    "        X = zscore(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxW659H6YTpz"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "Our model processes a tensor of shape `(batch size, sequence length, features)`,\n",
    "where `sequence length` is the number of time steps and `features` is each input\n",
    "timeseries.\n",
    "\n",
    "You can replace your classification RNN layers with this one: the\n",
    "inputs are fully compatible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urNK4ym-YTp0"
   },
   "source": [
    "We include residual connections, layer normalization, and dropout.\n",
    "The resulting layer can be stacked multiple times.\n",
    "\n",
    "The projection layers are implemented through `keras.layers.Conv1D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    '''入力された単語の位置を示すベクトル情報を付加する'''\n",
    "\n",
    "    def __init__(self, d_model=12, max_seq_len=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model  # 単語ベクトルの次元数\n",
    "\n",
    "        # 単語の順番（pos）と埋め込みベクトルの次元の位置（i）によって一意に定まる値の表をpeとして作成\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "\n",
    "        # GPUが使える場合はGPUへ送る、ここでは省略。実際に学習時には使用する\n",
    "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # pe = pe.to(device)\n",
    "\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                \n",
    "                # 誤植修正_200510 #79\n",
    "                # pe[pos, i + 1] = math.cos(pos /\n",
    "                #                          (10000 ** ((2 * (i + 1))/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos /\n",
    "                                          (10000 ** ((2 * i)/d_model)))\n",
    "\n",
    "        # 表peの先頭に、ミニバッチ次元となる次元を足す\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "        # 勾配を計算しないようにする\n",
    "        self.pe.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 入力xとPositonal Encodingを足し算する\n",
    "        # xがpeよりも小さいので、大きくする\n",
    "        ret = math.sqrt(self.d_model)*x + self.pe\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # SAGANでは1dConvを使用したが、今回は全結合層で特徴量を変換する\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # 出力時に使用する全結合層\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Attentionの大きさ調整の変数\n",
    "        self.d_k = d_model\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        # 全結合層で特徴量を変換\n",
    "        k = self.k_linear(k)\n",
    "        q = self.q_linear(q)\n",
    "        v = self.v_linear(v)\n",
    "\n",
    "        # Attentionの値を計算する\n",
    "        # 各値を足し算すると大きくなりすぎるので、root(d_k)で割って調整\n",
    "        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)\n",
    "\n",
    "        # ここでmaskを計算\n",
    "        # mask = mask.unsqueeze(1)\n",
    "        # print(mask)\n",
    "        # weights = weights.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # softmaxで規格化をする\n",
    "        normlized_weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "        # AttentionをValueとかけ算\n",
    "        output = torch.matmul(normlized_weights, v)\n",
    "\n",
    "        # 全結合層で特徴量を変換\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, normlized_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
    "        '''Attention層から出力を単純に全結合層2つで特徴量を変換するだけのユニットです'''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.dropout(F.relu(x))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # LayerNormalization層\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=layernorm\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Attention層\n",
    "        self.attn = Attention(d_model)\n",
    "\n",
    "        # Attentionのあとの全結合層2つ\n",
    "        self.ff = FeedForward(d_model)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # 正規化とAttention\n",
    "        # print(f\"input shape is {x.shape}\")\n",
    "        x_normlized = self.norm_1(x)\n",
    "        output, attn_weights = self.attn(x_normlized, x_normlized, x_normlized, mask)\n",
    "        \n",
    "        x2 = x + self.dropout_1(output)\n",
    "\n",
    "        # 正規化と全結合層\n",
    "        x_normlized2 = self.norm_2(x2)\n",
    "        output = x2 + self.dropout_2(self.ff(x_normlized2))\n",
    "        # print(f\"output shape is {output.shape}\")\n",
    "\n",
    "        return output, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringHead(nn.Module):\n",
    "    '''Transformer_Blockの出力を使用して，最後にスコアリングを行う'''\n",
    "    \n",
    "    def __init__(self, d_model=300, output_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # 全結合層\n",
    "        self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # 重み初期化処理\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n",
    "        x1 = self.linear(x0)\n",
    "        out = F.softmax(x1, dim=-1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    '''Transformer_Blockの出力を使用し、最後にクラス分類させる'''\n",
    "\n",
    "    def __init__(self, d_model=300, output_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # 全結合層\n",
    "        self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # 重み初期化処理\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n",
    "        x1 = self.linear(x0)\n",
    "        # print(x1.shape)\n",
    "        out = F.softmax(x1, dim=-1)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここで複数入力のAttentionにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的なTransformerモデルのクラス\n",
    "\n",
    "class TransformerClassification(nn.Module):\n",
    "    '''Transformerでクラス分類させる'''\n",
    "\n",
    "    def __init__(self, d_model=12, max_seq_len=101, output_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # モデル構築\n",
    "        self.net_Positional = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
    "        \n",
    "        self.net_Attention_1 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_2 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_3 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_4 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_5 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_6 = TransformerBlock(d_model=4)\n",
    "        \n",
    "        self.net_Attention_all = TransformerBlock(d_model=24)\n",
    "        # self.net3_2 = TransformerBlock(d_model=d_model)\n",
    "        \n",
    "        self.net_Classification = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.net_Positional(x)  # Positon情報を足し算\n",
    "        #ここでいくつのAttentionアーキテクチャを利用するか決定する\n",
    "        # num_attention_block = x.shape[2]/4\n",
    "        \n",
    "        x1, attn_weights_1 = self.net_Attention_1(x[:,:,0:4], mask[:,:,0:4])  # Self-Attentionで特徴量を変換\n",
    "        x2, attn_weights_2 = self.net_Attention_2(x[:,:,4:8], mask[:,:,4:8])\n",
    "        x3, attn_weights_3 = self.net_Attention_3(x[:,:,8:12], mask[:,:,8:12])\n",
    "        x4, attn_weights_4 = self.net_Attention_4(x[:,:,12:16], mask[:,:,12:16])\n",
    "        x5, attn_weights_5 = self.net_Attention_5(x[:,:,16:20], mask[:,:,16:20])\n",
    "        x6, attn_weights_6 = self.net_Attention_6(x[:,:,20:24], mask[:,:,20:24])\n",
    "        \n",
    "        #出力を全部つなぎ合わせる\n",
    "        x_concat = torch.cat((x1,x2,x3,x4,x5,x6), 2)\n",
    "        # x_attn, attn_weights_all = self.net_Attention_all(x_concat, mask)\n",
    "        \n",
    "        x_out = self.net_Classification(x_concat)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
    "        \n",
    "        l_attn_weights = [attn_weights_1,attn_weights_2,attn_weights_3,attn_weights_4,attn_weights_5,attn_weights_6\n",
    "                          # , attn_weights_all\n",
    "                         ] \n",
    "        return x_out, l_attn_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# validation用に1人のデータを検証データに回す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset[~(dataset['subject_id'] == 4)]\n",
    "val_df = dataset[dataset['subject_id'] == 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PyTorchのdatasetの作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = create_Xy(train_df)\n",
    "x_test, y_test = create_Xy(val_df)\n",
    "\n",
    "y_train = y_train.astype('int64')\n",
    "y_test = y_test.astype('int64')\n",
    "\n",
    "\n",
    "# 正解データをone hotベクトルに変換\n",
    "n_classes = len(np.unique(y_train))\n",
    "y_train_onehot = np.identity(n_classes)[y_train]\n",
    "y_test_onehot = np.identity(n_classes)[y_test]\n",
    "\n",
    "\n",
    "### 先頭にclassification用のトークンを追加する\n",
    "score_train = np.zeros((x_train.shape[0], 1 , x_train.shape[2]))\n",
    "x_train = np.concatenate([score_train, x_train], axis=1)\n",
    "\n",
    "score_test = np.zeros((x_test.shape[0], 1 , x_test.shape[2]))\n",
    "x_test = np.concatenate([score_test, x_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 先頭にclassification用のトークンを追加する\n",
    "# score_train = np.zeros((x_train.shape[0], 1 , x_train.shape[2]))\n",
    "# x_train = np.concatenate([score_train, x_train], axis=1)\n",
    "\n",
    "# score_test = np.zeros((x_test.shape[0], 1 , x_test.shape[2]))\n",
    "# x_test = np.concatenate([score_test, x_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1636987650297,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "8vf0x--aaZjE",
    "outputId": "57c2d515-00a5-443a-b22e-6fa77d359e84"
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(x_train, dtype=torch.float32)\n",
    "                                               , torch.tensor(y_train_onehot, dtype=torch.int8))\n",
    "val_dataset = torch.utils.data.TensorDataset(torch.tensor(x_test, dtype=torch.float32),\n",
    "                                             torch.tensor(y_test_onehot, dtype=torch.int8))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LakZIHM8YTp1"
   },
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力のテンソルサイズ： torch.Size([8, 4])\n",
      "出力テンソルのsigmoid： tensor([[0.2308, 0.2729, 0.2660, 0.2302],\n",
      "        [0.2315, 0.2739, 0.2637, 0.2310],\n",
      "        [0.2308, 0.2734, 0.2646, 0.2313],\n",
      "        [0.2317, 0.2739, 0.2623, 0.2321],\n",
      "        [0.2309, 0.2719, 0.2657, 0.2315],\n",
      "        [0.2305, 0.2732, 0.2649, 0.2313],\n",
      "        [0.2310, 0.2724, 0.2652, 0.2313],\n",
      "        [0.2318, 0.2710, 0.2662, 0.2311]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 動作確認\n",
    "# ミニバッチの用意\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "# モデル構築\n",
    "\n",
    "# 変数の固定\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "\n",
    "net = TransformerClassification(\n",
    "    d_model=24, max_seq_len=101, output_dim=4)\n",
    "\n",
    "# 入出力\n",
    "_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(_device)\n",
    "x = batch[0].to(_device)\n",
    "input_pad = 1\n",
    "input_mask = (x != input_pad)\n",
    "out, normlized_weights_1 = net(x, input_mask)\n",
    "\n",
    "print(\"出力のテンソルサイズ：\", out.shape)\n",
    "print(\"出力テンソルのsigmoid：\", F.softmax(out, dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elTTH_9KYTp0"
   },
   "source": [
    "The main part of our model is now complete. We can stack multiple of those\n",
    "`transformer_encoder` blocks and we can also proceed to add the final\n",
    "Multi-Layer Perceptron classification head. Apart from a stack of `Dense`\n",
    "layers, we need to reduce the output tensor of the `TransformerEncoder` part of\n",
    "our model down to a vector of features for each data point in the current\n",
    "batch. A common way to achieve this is to use a pooling layer. For\n",
    "this example, a `GlobalAveragePooling1D` layer is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ネットワークの初期化を定義\n",
    "\n",
    "# def weights_init(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     if classname.find('Linear') != -1:\n",
    "#         # Liner層の初期化\n",
    "#         nn.init.kaiming_normal_(m.weight)\n",
    "#         if m.bias is not None:\n",
    "#             nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "# # 訓練モードに設定\n",
    "# net.train()\n",
    "\n",
    "# # TransformerBlockモジュールを初期化実行\n",
    "\n",
    "# net.net_Attention_1.apply(weights_init)\n",
    "\n",
    "\n",
    "\n",
    "# print('ネットワーク設定完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の設定\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n",
    "\n",
    "# 最適化手法の設定\n",
    "learning_rate = 3e-4\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "    print('-----start-------')\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "        # for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和\n",
    "            epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "            # データローダーからミニバッチを取り出すループ\n",
    "            for batch in (dataloaders_dict[phase]):\n",
    "                # batchはTextとLableの辞書オブジェクト\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                inputs = batch[0].to(device)  # 文章\n",
    "                labels = batch[1].to(device)  # ラベル\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    # mask作成\n",
    "                    input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "                    input_mask = (inputs != input_pad)\n",
    "\n",
    "                    # Transformerに入力\n",
    "                    outputs, _ = net(inputs, input_mask)\n",
    "                    # print(f\"outputs shape is {outputs.dtype}, label shape is {labels.float()}\")\n",
    "                    loss = criterion(outputs, labels.float())  # 損失を計算\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # 結果の計算\n",
    "                    # print(np.array(preds))\n",
    "                    # print(np.array(np.argmax(labels.data)))\n",
    "                    # print(preds == labels.data)\n",
    "                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n",
    "                    # 正解数の合計を更新\n",
    "                    _, labels_true = torch.max(labels.data, 1)  # ラベルを予測\n",
    "                    # one_hot=F.one_hot(preds,num_classes=4)\n",
    "                    epoch_corrects += torch.sum(preds == labels_true)\n",
    "\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "            else:\n",
    "                writer.add_scalar(\"Loss/test\", loss, epoch)\n",
    "\n",
    "            # epochごとのlossと正解率\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
    "                                                                           phase, epoch_loss, epoch_acc))\n",
    "                # print(f\"epoch corrects {epoch_corrects.double()}\")\n",
    "                # print(f\"dataset size = {len(dataloaders_dict[phase].dataset)}\")\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "seed is 1000\n",
      "learning_rate is 0.0003\n",
      "使用デバイス： cpu\n",
      "-----start-------\n",
      "Epoch 1/300 | train |  Loss: 1.3910 Acc: 0.1714\n",
      "Epoch 1/300 |  val  |  Loss: 1.3880 Acc: 0.2500\n",
      "Epoch 101/300 | train |  Loss: 1.2863 Acc: 0.4286\n",
      "Epoch 101/300 |  val  |  Loss: 1.4415 Acc: 0.2500\n",
      "Epoch 201/300 | train |  Loss: 1.1075 Acc: 0.6571\n",
      "Epoch 201/300 |  val  |  Loss: 1.4844 Acc: 0.0833\n",
      "111.94531321525574\n",
      "---------------------------\n",
      "seed is 1001\n",
      "learning_rate is 0.0003\n",
      "使用デバイス： cpu\n",
      "-----start-------\n",
      "Epoch 1/300 | train |  Loss: 1.4372 Acc: 0.2286\n",
      "Epoch 1/300 |  val  |  Loss: 1.4207 Acc: 0.2500\n",
      "Epoch 101/300 | train |  Loss: 1.2153 Acc: 0.5429\n",
      "Epoch 101/300 |  val  |  Loss: 1.5317 Acc: 0.1667\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yt/fsd0dzhn23z2jcmc2hrkjcn00000gn/T/ipykernel_9479/3376077334.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         net_trained = train_model(net, \n\u001b[0m\u001b[1;32m     29\u001b[0m                                   \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                   \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yt/fsd0dzhn23z2jcmc2hrkjcn00000gn/T/ipykernel_9479/4114302356.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, dataloaders_dict, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0;31m# Transformerに入力\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                     \u001b[0;31m# print(f\"outputs shape is {outputs.dtype}, label shape is {labels.float()}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 損失を計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yt/fsd0dzhn23z2jcmc2hrkjcn00000gn/T/ipykernel_9479/2280500402.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_Attention_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_Attention_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mx5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_Attention_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mx6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights_6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_Attention_6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yt/fsd0dzhn23z2jcmc2hrkjcn00000gn/T/ipykernel_9479/1696604676.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# print(f\"input shape is {x.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx_normlized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_normlized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_normlized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_normlized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yt/fsd0dzhn23z2jcmc2hrkjcn00000gn/T/ipykernel_9479/3251623267.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# AttentionをValueとかけ算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormlized_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# 全結合層で特徴量を変換\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "# グリッドサーチを行う．\n",
    "l_rate = [3e-4]\n",
    "num_epochs = 300\n",
    "\n",
    "seeds = []\n",
    "for i in range(100):\n",
    "    seeds.append(1000+i)\n",
    "\n",
    "for seed in seeds:\n",
    "    print(\"---------------------------\")\n",
    "    print(f\"seed is {seed}\")\n",
    "    for learning_rate in l_rate:\n",
    "        writer = SummaryWriter()\n",
    "        print(f\"learning_rate is {learning_rate}\")\n",
    "\n",
    "        # 変数の固定\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "        # モデル構築\n",
    "        net = TransformerClassification(d_model=24, max_seq_len=101, output_dim=4)\n",
    "        # 訓練モードに設定\n",
    "        net.train()\n",
    "\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        start = time.time()\n",
    "        net_trained = train_model(net, \n",
    "                                  dataloaders_dict,\n",
    "                                  criterion,\n",
    "                                  optimizer,\n",
    "                                  num_epochs\n",
    "                                 )\n",
    "        print(time.time() - start)\n",
    "        writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 学習・検証を実行する 15分ほどかかります\n",
    "net = TransformerClassification(d_model=24, max_seq_len=101, output_dim=4)\n",
    "# 訓練モードに設定\n",
    "net.train()\n",
    "\n",
    "# 損失関数の設定\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n",
    "\n",
    "# 最適化手法の設定\n",
    "learning_rate = 2e-4\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "print('ネットワーク設定完了')\n",
    "\n",
    "num_epochs = 300\n",
    "net_trained = train_model(net, dataloaders_dict,\n",
    "                          criterion, optimizer, num_epochs=num_epochs)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN2SeFtLHbyT"
   },
   "source": [
    "# SaveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テストデータ11個での正解率：0.8182\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net_trained.eval()   # モデルを検証モードに\n",
    "net_trained.to(device)\n",
    "\n",
    "epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=60)\n",
    "# test_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=60)\n",
    "\n",
    "for batch in (test_dataloader):  # testデータのDataLoader\n",
    "    # batchはTextとLableの辞書オブジェクト\n",
    "    \n",
    "    # GPUが使えるならGPUにデータを送る\n",
    "    inputs = batch[0].to(device)  # 文章\n",
    "    labels = batch[1].to(device)  # ラベル\n",
    "\n",
    "    # 順伝搬（forward）計算\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        # mask作成\n",
    "        input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "        input_mask = (inputs != input_pad)\n",
    "\n",
    "        # Transformerに入力\n",
    "        outputs, attn_weights1 = net_trained(inputs, input_mask)\n",
    "        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "\n",
    "        # 結果の計算\n",
    "        # 正解数の合計を更新\n",
    "        # print(torch.argmax(labels.data, ))\n",
    "        epoch_corrects += torch.sum(preds == torch.argmax(labels.data, dim=1))\n",
    "\n",
    "# 正解率\n",
    "epoch_acc = epoch_corrects.double() / len(test_dataloader.dataset)\n",
    "\n",
    "print('テストデータ{}個での正解率：{:.4f}'.format(len(test_dataloader.dataset),epoch_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 0 0 1 1 1 0 0 0]\n",
      "[3 3 3 2 2 1 1 1 0 0 0]\n",
      "[[3 0 0 0]\n",
      " [0 3 0 0]\n",
      " [2 0 0 0]\n",
      " [0 0 0 3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "preds_heat = np.array(preds)\n",
    "trues_heat = np.array(torch.argmax(labels.data, dim=1))\n",
    "# preds_heat[0] = \"3A\"\n",
    "print(preds_heat)\n",
    "print(trues_heat)\n",
    "\n",
    "heat = confusion_matrix(trues_heat, preds_heat)\n",
    "print(heat)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"   # 使用するフォント\n",
    "plt.rcParams[\"font.size\"] = 20        \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "xtics = [\"2C\", \"2B\", \"2A\", \"3\"]\n",
    "ytics = [\"2C\", \"2B\", \"2A\", \"3\"]\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(heat, annot=True, xticklabels=xtics, yticklabels=ytics, cmap=\"Blues\", cbar=False)\n",
    "# sns.heatmap(heat, annot=True, cmap=\"Blues\", cbar=False)\n",
    "#*以下2行がポイント*  X,Y軸ラベルを追加\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "#グラフをはみ出さないようにして画面に出力\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"nn-heatmap_4.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(np.array(X[0, 1:, 0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_weight = np.array(attn_weights1[15, 0, 1:]).reshape(1, -1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 1))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(extract_weight, cmap='OrRd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "extract_data = np.array(X[19, 1:, 2]).flatten()\n",
    "print(extract_data.shape)\n",
    "\n",
    "\n",
    "time = np.linspace(0, 100, 100)\n",
    "fig, ax = plt.subplots(2, 1, gridspec_kw={'height_ratios': [6, 1]}, figsize=(15,10))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.lineplot(time, extract_data, ax=ax[0])\n",
    "sns.heatmap(extract_weight, cmap='OrRd', cbar=False, ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data = np.array(attn_weights1[:, 0, :])\n",
    "print(data.shape)\n",
    "data = data.reshape(attn_weights1.shape[0], -1)\n",
    "\n",
    "# print(outputs)\n",
    "print(data.shape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 20))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(data, cmap='OrRd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data[0])):\n",
    "    print(data[0,i], end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_trained.net_Attention_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelの読み込みだけ\n",
    "# 保存したモデルパラメータの読み込み\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net_trained = TransformerClassification().to(device)\n",
    "\n",
    "net_trained.load_state_dict(torch.load('highacc2.pth'))\n",
    "# print('読み込み後のモデル:\\n', model2.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(net_trained.state_dict(), 'highacc3.pth')\n",
    "\n",
    "# 新しいモデル\n",
    "model2 = TransformerClassification().to(device)\n",
    "print('新しいモデル:\\n', model2.state_dict())\n",
    "\n",
    "# 保存したモデルパラメータの読み込み\n",
    "model2.load_state_dict(torch.load('highacc3.pth'))\n",
    "print('読み込み後のモデル:\\n', model2.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention weight の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "print(data)\n",
    "print(data.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 同時に入れるデータも作成する\n",
    "# これは時系列スタンプ．0〜100がサンプル数だけ作られる\n",
    "stamp_row = [i%data.shape[1] for i in range(data.shape[0] * data.shape[1])]\n",
    "\n",
    "# いつ撮影されたのかのスタンプ\n",
    "l_date_name = np.array(df_annotate['date'].unique())\n",
    "date_row = []\n",
    "for item in l_date_name:\n",
    "    for i in range(data.shape[1]):\n",
    "        date_row.append(item)\n",
    "        \n",
    "# アテンションウエイト\n",
    "attn_weight = data.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attn = pd.DataFrame()\n",
    "df_attn['date'] = date_row\n",
    "df_attn[\"stamp\"] = stamp_row\n",
    "df_attn[\"attn_weight\"] = attn_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attn.to_excel('/Users/kento/kuhp/experiment/attention_weights.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_attn['date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "timeseries_transformer_classification.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/keras-team/keras-io/blob/master/examples/timeseries/ipynb/timeseries_classification_transformer.ipynb",
     "timestamp": 1636355482830
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
