{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyRQwYrEYTpv"
   },
   "source": [
    "# 修士論文実験 2022/01/10\n",
    "## マルチモーダルに挑戦\n",
    "## (validationが簡単に行えるようにデータセットを操作するモジュールを拡充)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 843,
     "status": "ok",
     "timestamp": 1636987406075,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "dO5GxI7RzXIc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# sys.path.append(os.path.abspath(\"..\"))\n",
    "# import scripts.compensate\n",
    "# import scripts.kinectImg2video\n",
    "# from scripts.conpemsate_suppresser import *\n",
    "# from scripts.ground_angle_analysis import ground_shoulder_angle_analyzer\n",
    "# import scripts.ground_angle_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日付の追加\n",
    "df_annotate = pd.read_excel(\"/Users/kento/kuhp/experiment/annotate_dataset.xlsx\")\n",
    "df_annotate['date'] = pd.to_datetime(df_annotate['date'], format='%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>uid</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>point</th>\n",
       "      <th>shoulder</th>\n",
       "      <th>body</th>\n",
       "      <th>flag_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-06 18:56:20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-06 18:56:20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-06 18:56:41</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-06 18:56:41</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-06 18:56:58</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  uid  subject_id  task_id point  shoulder  body  \\\n",
       "0 2021-12-06 18:56:20    1           1        1     3         0     0   \n",
       "1 2021-12-06 18:56:20    2           1        1     4         0     0   \n",
       "2 2021-12-06 18:56:41    3           1        1     3         0     0   \n",
       "3 2021-12-06 18:56:41    4           1        1     4         0     0   \n",
       "4 2021-12-06 18:56:58    5           1        1     3         0     0   \n",
       "\n",
       "   flag_usage  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           2  \n",
       "4           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>x_Pelvis</th>\n",
       "      <th>y_Pelvis</th>\n",
       "      <th>z_Pelvis</th>\n",
       "      <th>x_SpineNaval</th>\n",
       "      <th>y_SpineNaval</th>\n",
       "      <th>z_SpineNaval</th>\n",
       "      <th>x_SpineChest</th>\n",
       "      <th>...</th>\n",
       "      <th>x_REar</th>\n",
       "      <th>y_REar</th>\n",
       "      <th>z_REar</th>\n",
       "      <th>N</th>\n",
       "      <th>v_RWrist</th>\n",
       "      <th>z_v_RWrist</th>\n",
       "      <th>flag_active</th>\n",
       "      <th>flag_moving</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-158.973129</td>\n",
       "      <td>353.261841</td>\n",
       "      <td>698.233093</td>\n",
       "      <td>-149.886017</td>\n",
       "      <td>218.100922</td>\n",
       "      <td>780.778748</td>\n",
       "      <td>-142.035919</td>\n",
       "      <td>...</td>\n",
       "      <td>-178.933960</td>\n",
       "      <td>-236.272278</td>\n",
       "      <td>842.268127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.917988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-156.911919</td>\n",
       "      <td>356.031863</td>\n",
       "      <td>697.378637</td>\n",
       "      <td>-147.957493</td>\n",
       "      <td>219.063530</td>\n",
       "      <td>781.238292</td>\n",
       "      <td>-142.348493</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.788628</td>\n",
       "      <td>-241.853940</td>\n",
       "      <td>862.009244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.131710</td>\n",
       "      <td>0.480634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.891892</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-157.406120</td>\n",
       "      <td>356.970863</td>\n",
       "      <td>697.867036</td>\n",
       "      <td>-148.184343</td>\n",
       "      <td>219.214968</td>\n",
       "      <td>781.799317</td>\n",
       "      <td>-142.899719</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.093690</td>\n",
       "      <td>-243.703880</td>\n",
       "      <td>867.831643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.690953</td>\n",
       "      <td>0.198082</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.783784</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-159.493486</td>\n",
       "      <td>356.687710</td>\n",
       "      <td>699.214911</td>\n",
       "      <td>-149.753131</td>\n",
       "      <td>218.849632</td>\n",
       "      <td>782.412353</td>\n",
       "      <td>-143.553739</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.457427</td>\n",
       "      <td>-243.071735</td>\n",
       "      <td>864.096621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.280899</td>\n",
       "      <td>0.313779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.675676</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-162.211771</td>\n",
       "      <td>355.791270</td>\n",
       "      <td>700.938883</td>\n",
       "      <td>-151.850422</td>\n",
       "      <td>218.261918</td>\n",
       "      <td>783.027933</td>\n",
       "      <td>-144.174692</td>\n",
       "      <td>...</td>\n",
       "      <td>-177.488121</td>\n",
       "      <td>-241.207140</td>\n",
       "      <td>855.165480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.247976</td>\n",
       "      <td>0.307322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.567568</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1   id    x_Pelvis    y_Pelvis    z_Pelvis  \\\n",
       "0           0             0  1.0 -158.973129  353.261841  698.233093   \n",
       "1           1             1  1.0 -156.911919  356.031863  697.378637   \n",
       "2           2             2  1.0 -157.406120  356.970863  697.867036   \n",
       "3           3             3  1.0 -159.493486  356.687710  699.214911   \n",
       "4           4             4  1.0 -162.211771  355.791270  700.938883   \n",
       "\n",
       "   x_SpineNaval  y_SpineNaval  z_SpineNaval  x_SpineChest  ...      x_REar  \\\n",
       "0   -149.886017    218.100922    780.778748   -142.035919  ... -178.933960   \n",
       "1   -147.957493    219.063530    781.238292   -142.348493  ... -176.788628   \n",
       "2   -148.184343    219.214968    781.799317   -142.899719  ... -176.093690   \n",
       "3   -149.753131    218.849632    782.412353   -143.553739  ... -176.457427   \n",
       "4   -151.850422    218.261918    783.027933   -144.174692  ... -177.488121   \n",
       "\n",
       "       y_REar      z_REar   N  v_RWrist  z_v_RWrist  flag_active  flag_moving  \\\n",
       "0 -236.272278  842.268127 NaN       NaN   -0.917988          0.0          1.0   \n",
       "1 -241.853940  862.009244 NaN  7.131710    0.480634          1.0          1.0   \n",
       "2 -243.703880  867.831643 NaN  5.690953    0.198082          1.0          1.0   \n",
       "3 -243.071735  864.096621 NaN  6.280899    0.313779          1.0          1.0   \n",
       "4 -241.207140  855.165480 NaN  6.247976    0.307322          1.0          1.0   \n",
       "\n",
       "    timestamp                date  \n",
       "0    0.000000 2021-12-04 18:20:18  \n",
       "1   39.891892 2021-12-04 18:20:18  \n",
       "2   79.783784 2021-12-04 18:20:18  \n",
       "3  119.675676 2021-12-04 18:20:18  \n",
       "4  159.567568 2021-12-04 18:20:18  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataSetの呼び出し\n",
    "df_data = pd.read_csv(\"/Users/kento/kuhp/experiment/bigdata_trimmed.csv\")\n",
    "df_data['date'] = pd.to_datetime(df_data['date'], format='%Y-%m-%d-%H-%M-%S')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1636987406076,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "GZlVgJy1zXIc"
   },
   "outputs": [],
   "source": [
    "# pd_merged = pd.merge(df_annotate, df_data, on='date', how='inner')\n",
    "# pd_3 = pd_merged[pd_merged['point'] == 3]\n",
    "# pd_2A = pd_merged[pd_merged['point'] == '2A']\n",
    "# pd_2B = pd_merged[pd_merged['point'] == '2B']\n",
    "# pd_2C = pd_merged[pd_merged['point'] == '2C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### このデータセットはGraspのものかつ，usageが1のものが取り出されている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# データセットにNN入力用のスコアを割り振る．\n",
    "# これが正解ラベルになる\n",
    "dataset = pd.merge(df_annotate, df_data, on='date', how='inner')\n",
    "\n",
    "dataset = dataset[(dataset['task_id'] == 1) & (dataset['flag_usage'] == 1)]\n",
    "dataset['point'] = dataset['point'].astype(str)\n",
    "dataset.loc[dataset['point'] == '3', 'score'] = 3\n",
    "dataset.loc[dataset['point'] == '2A', 'score'] = 2\n",
    "dataset.loc[dataset['point'] == '2B', 'score'] = 1\n",
    "dataset.loc[dataset['point'] == '2C', 'score'] = 0\n",
    "print(dataset['score'].max())\n",
    "\n",
    "# Nanのものを削除\n",
    "dataset.dropna(subset=['score'], inplace=True)\n",
    "# scoreの行をintにする\n",
    "dataset['score'] = dataset['score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['uid'].unique()\n",
    "dataset['date'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grasp動作だけを抜き出す\n",
    "# dataset_grasp = dataset[dataset['task_id'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RElbow2RWrist と Rshoulder2RElbow と Pelvis2RShoulder と Pelvis2Neck の速度を入れてみる "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_annotate\n",
    "# l_date = df_annotate['date'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vector(df, joint1, joint2, word=\"\"):\n",
    "    df[f\"{word}_x_{joint1}2{joint2}\"] = df[f\"x_{joint1}\"].astype('float64') - df[f\"x_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_y_{joint1}2{joint2}\"] = df[f\"y_{joint1}\"].astype('float64') - df[f\"y_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_z_{joint1}2{joint2}\"] = df[f\"z_{joint1}\"].astype('float64') - df[f\"z_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_ave_{joint1}2{joint2}\"] = (df[f\"{word}_x_{joint1}2{joint2}\"] + df[f\"{word}_y_{joint1}2{joint2}\"] + df[f\"{word}_z_{joint1}2{joint2}\"])/3\n",
    "    return df\n",
    "\n",
    "def calc_angle(df, joint1, joint2, joint3):\n",
    "    l_theta = []\n",
    "    # 角度を算出する関数。p2を支点として、他の二点間の角度を算出する。\n",
    "    x1, y1 ,z1= df[f\"x_{joint1}\"].astype('float64'), df[f\"y_{joint1}\"].astype('float64'), df[f\"z_{joint1}\"].astype('float64')\n",
    "    x2, y2 ,z2= df[f\"x_{joint2}\"].astype('float64'), df[f\"y_{joint2}\"].astype('float64'), df[f\"z_{joint2}\"].astype('float64')\n",
    "    x3, y3 ,z3= df[f\"x_{joint3}\"].astype('float64'), df[f\"y_{joint3}\"].astype('float64'), df[f\"z_{joint3}\"].astype('float64')\n",
    "    v1 = np.array([x1-x2, y1-y2, z1-z2])\n",
    "    v2 = np.array([x3-x2, y3-y2, z3-z2])\n",
    "    for i in range(v1.shape[1]):\n",
    "        cos = np.dot(v1[:,i], v2[:,i])/(np.linalg.norm(v1[:,i], ord=2) * np.linalg.norm(v2[:,i], ord=2))\n",
    "        theta = np.degrees(math.acos(cos))\n",
    "        l_theta.append(theta)\n",
    "    return np.array(l_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 角度と角度の速度を入力とする\n",
    "angle_RElbow = calc_angle(dataset, 'RShoulder', 'RElbow', 'RWrist')\n",
    "diff_angle_RElbow = np.diff(angle_RElbow)\n",
    "\n",
    "angle_RShoulder = calc_angle(dataset, 'RElbow', 'RShoulder', 'Neck')\n",
    "diff_angle_RShoulder = np.diff(angle_RShoulder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_date_name = np.array(dataset['date'].unique())\n",
    "# l = []\n",
    "# for date in l_date_name:\n",
    "#     score = dataset[dataset[\"date\"] == date]['score'].mode()\n",
    "#     l.append(score)\n",
    "# return np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解ラベルで用いるyのone hotベクトルを作成\n",
    "def extract_y(df):\n",
    "    l = []\n",
    "    l_date_name = np.array(df['date'].unique())\n",
    "    for date in l_date_name:\n",
    "        score = df[df[\"date\"] == date]['score'].mode()\n",
    "        l.append(score)\n",
    "    y = np.array(l).flatten()\n",
    "    \n",
    "    # l_date_name = np.array(df['date'].unique())\n",
    "    # y = np.array(df[\"score\"]) #一番多いものをscoreとして最後にyとして返す\n",
    "    # y_arr = np.ones(l_date_name.shape)\n",
    "    # y_arr = y_arr * y\n",
    "    return y\n",
    "\n",
    "def interpolate1(array):\n",
    "    x_old = np.linspace(0, 1, array.shape[0])\n",
    "    y_old = array\n",
    "    \n",
    "    f = interpolate.interp1d(x_old, y_old)\n",
    "\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    y_new = f(x)\n",
    "    return y_new\n",
    "\n",
    "def zscore(x, axis = 1):\n",
    "    xmean = x.mean(axis=axis, keepdims=True)\n",
    "    xstd  = np.std(x, axis=axis, keepdims=True)\n",
    "    zscore = (x-xmean)/xstd\n",
    "    return zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ara = np.array([[[1,2,3,4,5],[4,5,6,7,8],[7,8,9,10,11]]])\n",
    "# ara.shape\n",
    "# z = zscore(ara)\n",
    "# print(z.shape)\n",
    "# print(ara)\n",
    "# print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# この関数を実行しさえすればデータセットが作成される\n",
    "def create_Xy(dataset):\n",
    "    #正解ラベルの作成\n",
    "    y = extract_y(dataset)\n",
    "    \n",
    "    # Xの作成\n",
    "    l_date_name = np.array(dataset['date'].unique())\n",
    "    for k, date in enumerate(l_date_name):\n",
    "        #一連のデータ，1サンプル\n",
    "        series = dataset[dataset['date'] == l_date_name[k]]\n",
    "        series.drop(columns='point', inplace=True)\n",
    "        series.drop(columns='date', inplace=True)\n",
    "        #差分ベクトルを取得\n",
    "        diff = series.diff()\n",
    "        diff.fillna(0, inplace=True)\n",
    "\n",
    "        # 間接点同士のベクトルのカラムをデータフレームに追加\n",
    "        # これらがデータセットになる\n",
    "        diff = add_vector(diff, 'RElbow', \"RWrist\", 'v')\n",
    "        diff = add_vector(diff, 'RShoulder', \"RElbow\", 'v')\n",
    "        diff = add_vector(diff, 'Pelvis', \"RShoulder\", 'v')\n",
    "        diff = add_vector(diff, 'Pelvis', \"Neck\", 'v')\n",
    "        diff = add_vector(diff, 'Neck', 'RShoulder', 'v')\n",
    "        diff = add_vector(diff, 'Neck', 'LShoulder', 'v')\n",
    "        \n",
    "#         diff['x_angle_RElbow'] = angle_RElbow\n",
    "#         diff['x2_angle_RElbow'] = angle_RElbow\n",
    "#         diff['x_diff_angle_RElbow'] = diff_angle_RElbow\n",
    "#         diff['diff_angle_RElbow2'] = diff_angle_RElbow\n",
    "        \n",
    "#         diff['angle_RShoulder'] = angle_RShoulder\n",
    "#         diff['angle_RShoulder2'] = angle_RShoulder\n",
    "#         diff['diff_angle_RShoulder'] = diff_angle_RShoulder\n",
    "#         diff['diff_angle_RShoulder2'] = diff_angle_RShoulder\n",
    "        \n",
    "        # arr_data = diff.loc[:, columns].values\n",
    "        arr_data = diff.loc[:, \"v_x_RElbow2RWrist\":].values\n",
    "        \n",
    "        # 補間を行う\n",
    "        for i in range(arr_data.shape[1]):\n",
    "            tmp_interpolate = interpolate1(arr_data[:, i])\n",
    "            # print(tmp_interpolate.shape)\n",
    "            #二次元に拡張\n",
    "            tmp_interpolate = tmp_interpolate.reshape(tmp_interpolate.shape[0], 1)\n",
    "            if i == 0:\n",
    "                x = tmp_interpolate\n",
    "            else:\n",
    "                x = np.concatenate([x, tmp_interpolate],1)\n",
    "                \n",
    "        # サンプル数の次元を拡張する\n",
    "        x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "        \n",
    "        #最初だけ条件分岐\n",
    "        if k == 0:\n",
    "            X = x\n",
    "        else:\n",
    "            X = np.concatenate([X, x], axis=0)\n",
    "        \n",
    "       # 最後にzscore変換\n",
    "        X = zscore(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # この関数を実行しさえすればデータセットが作成される\n",
    "# def create_scoring_Xy(dataset):\n",
    "#     #正解ラベルの作成\n",
    "#     y = (np.array(dataset[\"score\"]) - 1.5) / 1.5\n",
    "    \n",
    "#     # Xの作成\n",
    "#     l_date_name = np.array(dataset['date'].unique())\n",
    "#     for k, date in enumerate(l_date_name):\n",
    "#         #一連のデータ，1サンプル\n",
    "#         series = dataset[dataset['date'] == l_date_name[k]]\n",
    "#         series.drop(columns='point', inplace=True)\n",
    "#         series.drop(columns='date', inplace=True)\n",
    "#         #差分ベクトルを取得\n",
    "#         diff = series.diff()\n",
    "#         diff.fillna(0, inplace=True)\n",
    "\n",
    "#         # 間接点同士のベクトルのカラムをデータフレームに追加\n",
    "#         # これらがデータセットになる\n",
    "#         diff = add_vector(diff, 'RElbow', \"RWrist\", 'v')\n",
    "#         diff = add_vector(diff, 'RShoulder', \"RElbow\", 'v')\n",
    "#         diff = add_vector(diff, 'Pelvis', \"RShoulder\", 'v')\n",
    "#         diff = add_vector(diff, 'Pelvis', \"Neck\", 'v')\n",
    "#         diff = add_vector(diff, 'Neck', 'RShoulder', 'v')\n",
    "#         diff = add_vector(diff, 'Neck', 'LShoulder', 'v')\n",
    "        \n",
    "# #         diff['x_angle_RElbow'] = angle_RElbow\n",
    "# #         diff['x2_angle_RElbow'] = angle_RElbow\n",
    "# #         diff['x_diff_angle_RElbow'] = diff_angle_RElbow\n",
    "# #         diff['diff_angle_RElbow2'] = diff_angle_RElbow\n",
    "        \n",
    "# #         diff['angle_RShoulder'] = angle_RShoulder\n",
    "# #         diff['angle_RShoulder2'] = angle_RShoulder\n",
    "# #         diff['diff_angle_RShoulder'] = diff_angle_RShoulder\n",
    "# #         diff['diff_angle_RShoulder2'] = diff_angle_RShoulder\n",
    "        \n",
    "#         # arr_data = diff.loc[:, columns].values\n",
    "#         arr_data = diff.loc[:, \"v_x_RElbow2RWrist\":].values\n",
    "        \n",
    "#         # 補間を行う\n",
    "#         for i in range(arr_data.shape[1]):\n",
    "#             tmp_interpolate = interpolate1(arr_data[:, i])\n",
    "#             # print(tmp_interpolate.shape)\n",
    "#             #二次元に拡張\n",
    "#             tmp_interpolate = tmp_interpolate.reshape(tmp_interpolate.shape[0], 1)\n",
    "#             if i == 0:\n",
    "#                 x = tmp_interpolate\n",
    "#             else:\n",
    "#                 x = np.concatenate([x, tmp_interpolate],1)\n",
    "                \n",
    "#         # サンプル数の次元を拡張する\n",
    "#         x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "        \n",
    "#         #最初だけ条件分岐\n",
    "#         if k == 0:\n",
    "#             X = x\n",
    "#         else:\n",
    "#             X = np.concatenate([X, x], axis=0)\n",
    "        \n",
    "#        # 最後にzscore変換\n",
    "#         X = zscore(X)\n",
    "#     return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxW659H6YTpz"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "Our model processes a tensor of shape `(batch size, sequence length, features)`,\n",
    "where `sequence length` is the number of time steps and `features` is each input\n",
    "timeseries.\n",
    "\n",
    "You can replace your classification RNN layers with this one: the\n",
    "inputs are fully compatible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urNK4ym-YTp0"
   },
   "source": [
    "We include residual connections, layer normalization, and dropout.\n",
    "The resulting layer can be stacked multiple times.\n",
    "\n",
    "The projection layers are implemented through `keras.layers.Conv1D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    '''入力された単語の位置を示すベクトル情報を付加する'''\n",
    "\n",
    "    def __init__(self, d_model=12, max_seq_len=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model  # 単語ベクトルの次元数\n",
    "\n",
    "        # 単語の順番（pos）と埋め込みベクトルの次元の位置（i）によって一意に定まる値の表をpeとして作成\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "\n",
    "        # GPUが使える場合はGPUへ送る、ここでは省略。実際に学習時には使用する\n",
    "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # pe = pe.to(device)\n",
    "\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                \n",
    "                # 誤植修正_200510 #79\n",
    "                # pe[pos, i + 1] = math.cos(pos /\n",
    "                #                          (10000 ** ((2 * (i + 1))/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos /\n",
    "                                          (10000 ** ((2 * i)/d_model)))\n",
    "\n",
    "        # 表peの先頭に、ミニバッチ次元となる次元を足す\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "        # 勾配を計算しないようにする\n",
    "        self.pe.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 入力xとPositonal Encodingを足し算する\n",
    "        # xがpeよりも小さいので、大きくする\n",
    "        ret = math.sqrt(self.d_model)*x + self.pe\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # SAGANでは1dConvを使用したが、今回は全結合層で特徴量を変換する\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # 出力時に使用する全結合層\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Attentionの大きさ調整の変数\n",
    "        self.d_k = d_model\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        # 全結合層で特徴量を変換\n",
    "        k = self.k_linear(k)\n",
    "        q = self.q_linear(q)\n",
    "        v = self.v_linear(v)\n",
    "\n",
    "        # Attentionの値を計算する\n",
    "        # 各値を足し算すると大きくなりすぎるので、root(d_k)で割って調整\n",
    "        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)\n",
    "\n",
    "        # ここでmaskを計算\n",
    "        # mask = mask.unsqueeze(1)\n",
    "        # print(mask)\n",
    "        # weights = weights.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # softmaxで規格化をする\n",
    "        normlized_weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "        # AttentionをValueとかけ算\n",
    "        output = torch.matmul(normlized_weights, v)\n",
    "\n",
    "        # 全結合層で特徴量を変換\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, normlized_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
    "        '''Attention層から出力を単純に全結合層2つで特徴量を変換するだけのユニットです'''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.dropout(F.relu(x))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # LayerNormalization層\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=layernorm\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Attention層\n",
    "        self.attn = Attention(d_model)\n",
    "\n",
    "        # Attentionのあとの全結合層2つ\n",
    "        self.ff = FeedForward(d_model)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # 正規化とAttention\n",
    "        # print(f\"input shape is {x.shape}\")\n",
    "        x_normlized = self.norm_1(x)\n",
    "        output, attn_weights = self.attn(x_normlized, x_normlized, x_normlized, mask)\n",
    "        \n",
    "        x2 = x + self.dropout_1(output)\n",
    "\n",
    "        # 正規化と全結合層\n",
    "        x_normlized2 = self.norm_2(x2)\n",
    "        output = x2 + self.dropout_2(self.ff(x_normlized2))\n",
    "        # print(f\"output shape is {output.shape}\")\n",
    "\n",
    "        return output, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringHead(nn.Module):\n",
    "    '''Transformer_Blockの出力を使用して，最後にスコアリングを行う'''\n",
    "    \n",
    "    def __init__(self, d_model=300, output_dim=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # 全結合層\n",
    "        self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # 重み初期化処理\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n",
    "        weights = self.linear.weight\n",
    "        out = self.linear(x0)\n",
    "        \n",
    "        # print(f\"Scoring input shape is {x0.shape}\")\n",
    "        # print(f\"Scoring weight shape is {weights.shape}\")\n",
    "        # print(f\"Scoring output shape is {out.shape}\")\n",
    "\n",
    "        return out, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ClassificationHead(nn.Module):\n",
    "#     '''Transformer_Blockの出力を使用し、最後にクラス分類させる'''\n",
    "\n",
    "#     def __init__(self, d_model=300, output_dim=4):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # 全結合層\n",
    "#         self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n",
    "#         self.output_dim = output_dim\n",
    "\n",
    "#         # 重み初期化処理\n",
    "#         nn.init.normal_(self.linear.weight, std=0.02)\n",
    "#         nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n",
    "#         x1 = self.linear(x0)\n",
    "#         # print(x1.shape)\n",
    "#         out = F.softmax(x1, dim=-1)\n",
    "\n",
    "#         return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここで複数入力のAttentionにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 最終的なTransformerモデルのクラス\n",
    "\n",
    "# class TransformerClassification(nn.Module):\n",
    "#     '''Transformerでクラス分類させる'''\n",
    "\n",
    "#     def __init__(self, d_model=12, max_seq_len=101, output_dim=4):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # モデル構築\n",
    "#         self.net_Positional = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
    "        \n",
    "#         self.net_Attention_1 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_2 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_3 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_4 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_5 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_6 = TransformerBlock(d_model=4)\n",
    "        \n",
    "#         self.net_Attention_all = TransformerBlock(d_model=24)\n",
    "#         # self.net3_2 = TransformerBlock(d_model=d_model)\n",
    "        \n",
    "#         self.net_Classification = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
    "\n",
    "#     def forward(self, x, mask):\n",
    "#         x = self.net_Positional(x)  # Positon情報を足し算\n",
    "#         #ここでいくつのAttentionアーキテクチャを利用するか決定する\n",
    "#         # num_attention_block = x.shape[2]/4\n",
    "        \n",
    "#         x1, attn_weights_1 = self.net_Attention_1(x[:,:,0:4], mask[:,:,0:4])  # Self-Attentionで特徴量を変換\n",
    "#         x2, attn_weights_2 = self.net_Attention_2(x[:,:,4:8], mask[:,:,4:8])\n",
    "#         x3, attn_weights_3 = self.net_Attention_3(x[:,:,8:12], mask[:,:,8:12])\n",
    "#         x4, attn_weights_4 = self.net_Attention_4(x[:,:,12:16], mask[:,:,12:16])\n",
    "#         x5, attn_weights_5 = self.net_Attention_5(x[:,:,16:20], mask[:,:,16:20])\n",
    "#         x6, attn_weights_6 = self.net_Attention_6(x[:,:,20:24], mask[:,:,20:24])\n",
    "        \n",
    "#         #出力を全部つなぎ合わせる\n",
    "#         x_concat = torch.cat((x1,x2,x3,x4,x5,x6), 2)\n",
    "#         # x_attn, attn_weights_all = self.net_Attention_all(x_concat, mask)\n",
    "        \n",
    "#         x_out = self.net_Classification(x_concat)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
    "        \n",
    "#         l_attn_weights = [attn_weights_1,attn_weights_2,attn_weights_3,attn_weights_4,attn_weights_5,attn_weights_6\n",
    "#                           # , attn_weights_all\n",
    "#                          ] \n",
    "#         return x_out, l_attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的なTransformerモデルのクラス\n",
    "\n",
    "class TransformerScoring(nn.Module):\n",
    "    '''Transformerでクラス分類させる'''\n",
    "\n",
    "    def __init__(self, d_model=12, max_seq_len=101, output_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # モデル構築\n",
    "        self.net_Positional = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
    "        \n",
    "        self.net_Attention_1 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_2 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_3 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_4 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_5 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_6 = TransformerBlock(d_model=4)\n",
    "        \n",
    "        self.net_Attention_all = TransformerBlock(d_model=24)\n",
    "        # self.net3_2 = TransformerBlock(d_model=d_model)\n",
    "        \n",
    "        # self.net_Classification = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
    "        self.net_Scoring = ScoringHead(output_dim=output_dim, d_model=d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.net_Positional(x)  # Positon情報を足し算\n",
    "        #ここでいくつのAttentionアーキテクチャを利用するか決定する\n",
    "        # num_attention_block = x.shape[2]/4\n",
    "        \n",
    "        x1, attn_weights_1 = self.net_Attention_1(x[:,:,0:4], mask[:,:,0:4])  # Self-Attentionで特徴量を変換\n",
    "        x2, attn_weights_2 = self.net_Attention_2(x[:,:,4:8], mask[:,:,4:8])\n",
    "        x3, attn_weights_3 = self.net_Attention_3(x[:,:,8:12], mask[:,:,8:12])\n",
    "        x4, attn_weights_4 = self.net_Attention_4(x[:,:,12:16], mask[:,:,12:16])\n",
    "        x5, attn_weights_5 = self.net_Attention_5(x[:,:,16:20], mask[:,:,16:20])\n",
    "        x6, attn_weights_6 = self.net_Attention_6(x[:,:,20:24], mask[:,:,20:24])\n",
    "        \n",
    "        #出力を全部つなぎ合わせる\n",
    "        x_concat = torch.cat((x1,x2,x3,x4,x5,x6), 2)\n",
    "        # x_attn, attn_weights_all = self.net_Attention_all(x_concat, mask)\n",
    "        \n",
    "        x_out, _ = self.net_Scoring(x_concat)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
    "        \n",
    "        l_attn_weights = [attn_weights_1,attn_weights_2,attn_weights_3,attn_weights_4,attn_weights_5,attn_weights_6\n",
    "                          # , attn_weights_all\n",
    "                         ] \n",
    "        return x_out, l_attn_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# validation用に1人のデータを検証データに回す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset\n",
    "# [~(dataset['subject_id'] == 4)]\n",
    "val_df = dataset[dataset['subject_id'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PyTorchのdatasetの作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kento/miniforge3/envs/torch/lib/python3.8/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 2 2 2 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = create_Xy(train_df)\n",
    "x_test, y_test = create_Xy(val_df)\n",
    "print(y_test)\n",
    "\n",
    "# y_train = y_train.astype('int64')\n",
    "# y_test = y_test.astype('int64')\n",
    "\n",
    "\n",
    "# 正解データをone hotベクトルに変換\n",
    "n_classes = len(np.unique(y_train))\n",
    "y_train_onehot = np.identity(n_classes)[y_train]\n",
    "y_test_onehot = np.identity(n_classes)[y_test]\n",
    "\n",
    "\n",
    "### 先頭にclassification用のトークンを追加する\n",
    "score_train = np.zeros((x_train.shape[0], 1 , x_train.shape[2]))\n",
    "x_train = np.concatenate([score_train, x_train], axis=1)\n",
    "\n",
    "score_test = np.zeros((x_test.shape[0], 1 , x_test.shape[2]))\n",
    "x_test = np.concatenate([score_test, x_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 先頭にclassification用のトークンを追加する\n",
    "# score_train = np.zeros((x_train.shape[0], 1 , x_train.shape[2]))\n",
    "# x_train = np.concatenate([score_train, x_train], axis=1)\n",
    "\n",
    "# score_test = np.zeros((x_test.shape[0], 1 , x_test.shape[2]))\n",
    "# x_test = np.concatenate([score_test, x_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1636987650297,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "8vf0x--aaZjE",
    "outputId": "57c2d515-00a5-443a-b22e-6fa77d359e84"
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(x_train, dtype=torch.float32)\n",
    "                                               , torch.tensor(y_train_onehot, dtype=torch.int8))\n",
    "val_dataset = torch.utils.data.TensorDataset(torch.tensor(x_test, dtype=torch.float32),\n",
    "                                             torch.tensor(y_test_onehot, dtype=torch.int8))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LakZIHM8YTp1"
   },
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力のテンソルサイズ： torch.Size([8, 1])\n",
      "出力テンソル tensor([[0.5152],\n",
      "        [0.5442],\n",
      "        [0.5203],\n",
      "        [0.5453],\n",
      "        [0.5178],\n",
      "        [0.5726],\n",
      "        [0.5596],\n",
      "        [0.5358]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 動作確認\n",
    "# ミニバッチの用意\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "# モデル構築\n",
    "\n",
    "# 変数の固定\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "\n",
    "net = TransformerScoring(\n",
    "    d_model=24, max_seq_len=101, output_dim=1)\n",
    "\n",
    "# 入出力\n",
    "_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(_device)\n",
    "x = batch[0].to(_device)\n",
    "input_pad = 1\n",
    "input_mask = (x != input_pad)\n",
    "out, l_weights = net(x, input_mask)\n",
    "\n",
    "print(\"出力のテンソルサイズ：\", out.shape)\n",
    "print(\"出力テンソル\", out)\n",
    "# print(\"出力テンソルのsigmoid：\", F.softmax(out, dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elTTH_9KYTp0"
   },
   "source": [
    "The main part of our model is now complete. We can stack multiple of those\n",
    "`transformer_encoder` blocks and we can also proceed to add the final\n",
    "Multi-Layer Perceptron classification head. Apart from a stack of `Dense`\n",
    "layers, we need to reduce the output tensor of the `TransformerEncoder` part of\n",
    "our model down to a vector of features for each data point in the current\n",
    "batch. A common way to achieve this is to use a pooling layer. For\n",
    "this example, a `GlobalAveragePooling1D` layer is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ネットワークの初期化を定義\n",
    "\n",
    "# def weights_init(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     if classname.find('Linear') != -1:\n",
    "#         # Liner層の初期化\n",
    "#         nn.init.kaiming_normal_(m.weight)\n",
    "#         if m.bias is not None:\n",
    "#             nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "# # 訓練モードに設定\n",
    "# net.train()\n",
    "\n",
    "# # TransformerBlockモジュールを初期化実行\n",
    "\n",
    "# net.net_Attention_1.apply(weights_init)\n",
    "\n",
    "\n",
    "\n",
    "# print('ネットワーク設定完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の設定\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n",
    "\n",
    "# 最適化手法の設定\n",
    "learning_rate = 3e-4\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs, patience):\n",
    "    # Early Stopping を定義\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "    print('-----start-------')\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "        # for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和\n",
    "            epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "            # データローダーからミニバッチを取り出すループ\n",
    "            for batch in (dataloaders_dict[phase]):\n",
    "                # batchはTextとLableの辞書オブジェクト\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                inputs = batch[0].to(device)  # 文章\n",
    "                labels = batch[1].to(device)  # ラベル\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    # mask作成\n",
    "                    input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "                    input_mask = (inputs != input_pad)\n",
    "\n",
    "                    # Transformerに入力\n",
    "                    outputs, _ = net(inputs, input_mask)\n",
    "                    _, labels_true = torch.max(labels.data, 1)  # ワンホットラベルを平坦化\n",
    "                    labels_true_float = labels_true / 3\n",
    "                    # print(type(labels_true_float.dtype))\n",
    "                    # print(f\"outputs shape is {outputs.flatten().shape}, label shape is {labels_true.shape}\")\n",
    "                    outputs = outputs.flatten()\n",
    "                    loss = criterion(outputs, labels_true_float)  # 損失を計算\n",
    "                    # print(f\"output is {outputs}, labels float are {labels_true_float}\")\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # 結果の計算\n",
    "                    # print(np.array(preds))\n",
    "                    # print(np.array(np.argmax(labels.data)))\n",
    "                    # print(preds == labels.data)\n",
    "                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n",
    "                    # 正解数の合計を更新\n",
    "                    \n",
    "                    # one_hot=F.one_hot(preds,num_classes=4)\n",
    "                    # epoch_corrects += torch.sum(preds == labels_true)\n",
    "                    # print(labels_true)\n",
    "                    # print(torch.flatten(preds))\n",
    "                    preds = torch.round(outputs * 3)  # ラベルを予測\n",
    "                    # print(f\"predicts are {preds}, labels {labels_true}\")\n",
    "                    # print(preds == labels_true)\n",
    "                    epoch_corrects += torch.sum(preds == labels_true)\n",
    "\n",
    "            # epochごとのlossと正解率\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
    "                                                                           phase, epoch_loss, epoch_acc))\n",
    "                # print(f\"epoch corrects {epoch_corrects.double()}\")\n",
    "                # print(f\"dataset size = {len(dataloaders_dict[phase].dataset)}\")\n",
    "                \n",
    "            if phase == 'train':\n",
    "                writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "\n",
    "            else:\n",
    "                writer.add_scalar(\"Loss/test\", loss, epoch)\n",
    "        early_stopping(loss, net) # 最良モデルならモデルパラメータ保存\n",
    "        if early_stopping.early_stop: \n",
    "        # 一定epochだけval_lossが最低値を更新しなかった場合、ここに入り学習を終了\n",
    "            print(f\"Early Stopping  !! Epoch {epoch+1}/{num_epochs} Loss: {epoch_loss} Acc: {epoch_acc}\")\n",
    "            break\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "seed is 1099\n",
      "learning_rate is 0.001\n",
      "使用デバイス： cpu\n",
      "-----start-------\n",
      "Epoch 1/300 | train |  Loss: 1.3921 Acc: 0.0000\n",
      "Epoch 1/300 |  val  |  Loss: 0.5042 Acc: 0.2500\n",
      "Validation loss decreased (inf --> 0.054857).  Saving model ...\n",
      "Validation loss decreased (0.054857 --> 0.037139).  Saving model ...\n",
      "Validation loss decreased (0.037139 --> 0.033801).  Saving model ...\n",
      "Validation loss decreased (0.033801 --> 0.031907).  Saving model ...\n",
      "Validation loss decreased (0.031907 --> 0.023830).  Saving model ...\n",
      "Validation loss decreased (0.023830 --> 0.023391).  Saving model ...\n",
      "Validation loss decreased (0.023391 --> 0.020321).  Saving model ...\n",
      "Validation loss decreased (0.020321 --> 0.018809).  Saving model ...\n",
      "Validation loss decreased (0.018809 --> 0.017212).  Saving model ...\n",
      "Validation loss decreased (0.017212 --> 0.016194).  Saving model ...\n",
      "Epoch 101/300 | train |  Loss: 0.0372 Acc: 0.6809\n",
      "Epoch 101/300 |  val  |  Loss: 0.0306 Acc: 0.5833\n",
      "Validation loss decreased (0.016194 --> 0.015929).  Saving model ...\n",
      "Validation loss decreased (0.015929 --> 0.015658).  Saving model ...\n",
      "Validation loss decreased (0.015658 --> 0.015443).  Saving model ...\n",
      "Validation loss decreased (0.015443 --> 0.014786).  Saving model ...\n",
      "Validation loss decreased (0.014786 --> 0.013854).  Saving model ...\n",
      "Validation loss decreased (0.013854 --> 0.013653).  Saving model ...\n",
      "Validation loss decreased (0.013653 --> 0.012955).  Saving model ...\n",
      "Validation loss decreased (0.012955 --> 0.012033).  Saving model ...\n",
      "Validation loss decreased (0.012033 --> 0.010536).  Saving model ...\n",
      "Validation loss decreased (0.010536 --> 0.009873).  Saving model ...\n",
      "Validation loss decreased (0.009873 --> 0.007918).  Saving model ...\n",
      "Epoch 201/300 | train |  Loss: 0.0179 Acc: 0.8298\n",
      "Epoch 201/300 |  val  |  Loss: 0.0197 Acc: 0.8333\n",
      "Validation loss decreased (0.007918 --> 0.006977).  Saving model ...\n",
      "Validation loss decreased (0.006977 --> 0.006926).  Saving model ...\n",
      "Validation loss decreased (0.006926 --> 0.006453).  Saving model ...\n",
      "Validation loss decreased (0.006453 --> 0.005054).  Saving model ...\n",
      "Validation loss decreased (0.005054 --> 0.004712).  Saving model ...\n",
      "Validation loss decreased (0.004712 --> 0.003984).  Saving model ...\n",
      "Validation loss decreased (0.003984 --> 0.003718).  Saving model ...\n",
      "Validation loss decreased (0.003718 --> 0.003411).  Saving model ...\n",
      "Validation loss decreased (0.003411 --> 0.003373).  Saving model ...\n",
      "Validation loss decreased (0.003373 --> 0.003308).  Saving model ...\n",
      "129.62972211837769\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# グリッドサーチを行う．\n",
    "# l_rate = [3e-4, 5e-4, 1e-3]\n",
    "l_rate = [1e-3]\n",
    "num_epochs = 300\n",
    "patience = 50\n",
    "\n",
    "seeds = []\n",
    "for i in range(100):\n",
    "    seeds.append(1000+i)\n",
    "\n",
    "for seed in seeds:\n",
    "    pass\n",
    "print(\"---------------------------\")\n",
    "print(f\"seed is {seed}\")\n",
    "for learning_rate in l_rate:\n",
    "    writer = SummaryWriter()\n",
    "    print(f\"learning_rate is {learning_rate}\")\n",
    "\n",
    "    # 変数の固定\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    # モデル構築\n",
    "    net = TransformerScoring(d_model=24, max_seq_len=101, output_dim=1)\n",
    "    # 訓練モードに設定\n",
    "    net.train()\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    start = time.time()\n",
    "    net_trained = train_model(net, \n",
    "                              dataloaders_dict,\n",
    "                              criterion,\n",
    "                              optimizer,\n",
    "                              num_epochs,\n",
    "                              patience\n",
    "                             )\n",
    "    print(time.time() - start)\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 学習・検証を実行する 15分ほどかかります\n",
    "# net = TransformerClassification(d_model=24, max_seq_len=101, output_dim=4)\n",
    "# # 訓練モードに設定\n",
    "# net.train()\n",
    "\n",
    "# # 損失関数の設定\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# # nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n",
    "\n",
    "# # 最適化手法の設定\n",
    "# learning_rate = 2e-4\n",
    "# optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# print('ネットワーク設定完了')\n",
    "\n",
    "# num_epochs = 300\n",
    "# net_trained = train_model(net, dataloaders_dict,\n",
    "#                           criterion, optimizer, num_epochs=num_epochs)\n",
    "# writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN2SeFtLHbyT"
   },
   "source": [
    "# SaveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net_trained' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yt/fsd0dzhn23z2jcmc2hrkjcn00000gn/T/ipykernel_18995/205518804.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnet_trained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# モデルを検証モードに\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnet_trained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net_trained' is not defined"
     ]
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net_trained.eval()   # モデルを検証モードに\n",
    "net_trained.to(device)\n",
    "\n",
    "epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "# test_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=60)\n",
    "test_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=60)\n",
    "\n",
    "for batch in (test_dataloader):  # testデータのDataLoader\n",
    "    # batchはTextとLableの辞書オブジェクト\n",
    "    \n",
    "    # GPUが使えるならGPUにデータを送る\n",
    "    inputs = batch[0].to(device)  # 文章\n",
    "    labels = batch[1].to(device)  # ラベル\n",
    "\n",
    "    # 順伝搬（forward）計算\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        # mask作成\n",
    "        input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "        input_mask = (inputs != input_pad)\n",
    "\n",
    "        # Transformerに入力\n",
    "        outputs, _ = net(inputs, input_mask)\n",
    "        _, labels_true = torch.max(labels.data, 1)  # ワンホットラベルを平坦化\n",
    "        outputs = outputs.flatten()\n",
    "\n",
    "        # 正解数の合計を更新\n",
    "        preds = torch.round(outputs*3)  # ラベルを予測\n",
    "        # print(f\"predicts are {preds}, labels {labels_true}\")\n",
    "        epoch_corrects += torch.sum(preds == labels_true)\n",
    "\n",
    "# 正解率\n",
    "epoch_acc = epoch_corrects.double() / len(test_dataloader.dataset)\n",
    "\n",
    "print('テストデータ{}個での正解率：{:.4f}'.format(len(test_dataloader.dataset),epoch_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 3. 2. 2. 2. 1. 1. 1. 0. 0. 0. 3. 3. 3. 2. 3. 2. 1. 1. 1. 1. 0. 0.\n",
      " 3. 3. 3. 2. 2. 1. 1. 1. 1. 0. 0. 3. 3. 3. 2. 2. 2. 1. 1. 1. 1. 0. 0.]\n",
      "[3 3 3 2 2 2 1 1 1 0 0 0 3 3 3 2 2 2 1 1 1 0 0 0 3 3 3 2 2 1 1 1 0 0 0 3 3\n",
      " 3 2 2 2 1 1 1 0 0 0]\n",
      "[[ 9  3  0  0]\n",
      " [ 0 12  0  0]\n",
      " [ 0  0 10  1]\n",
      " [ 0  0  0 12]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "preds_heat = np.array(preds)\n",
    "trues_heat = np.array(torch.argmax(labels.data, dim=1))\n",
    "# preds_heat[0] = \"3A\"\n",
    "print(preds_heat)\n",
    "print(trues_heat)\n",
    "\n",
    "heat = confusion_matrix(trues_heat, preds_heat)\n",
    "print(heat)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"   # 使用するフォント\n",
    "plt.rcParams[\"font.size\"] = 20        \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "xtics = [\"2C\", \"2B\", \"2A\", \"3\"]\n",
    "ytics = [\"2C\", \"2B\", \"2A\", \"3\"]\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(heat, annot=True, xticklabels=xtics, yticklabels=ytics, cmap=\"Blues\", cbar=False)\n",
    "# sns.heatmap(heat, annot=True, cmap=\"Blues\", cbar=False)\n",
    "#*以下2行がポイント*  X,Y軸ラベルを追加\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "#グラフをはみ出さないようにして画面に出力\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"nn-heatmap_4.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127d2f0d0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# サンプルごとに代償動作の度合いをセッティングしてみる\n",
    "preds = np.array(outputs)\n",
    "ans = np.array(labels_true)\n",
    "plt.scatter(preds, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_weight = np.array(attn_weights1[15, 0, 1:]).reshape(1, -1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 1))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(extract_weight, cmap='OrRd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "extract_data = np.array(X[19, 1:, 2]).flatten()\n",
    "print(extract_data.shape)\n",
    "\n",
    "\n",
    "time = np.linspace(0, 100, 100)\n",
    "fig, ax = plt.subplots(2, 1, gridspec_kw={'height_ratios': [6, 1]}, figsize=(15,10))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.lineplot(time, extract_data, ax=ax[0])\n",
    "sns.heatmap(extract_weight, cmap='OrRd', cbar=False, ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data = np.array(attn_weights1[:, 0, :])\n",
    "print(data.shape)\n",
    "data = data.reshape(attn_weights1.shape[0], -1)\n",
    "\n",
    "# print(outputs)\n",
    "print(data.shape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 20))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(data, cmap='OrRd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data[0])):\n",
    "    print(data[0,i], end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_trained.net_Attention_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelの読み込みだけ\n",
    "# 保存したモデルパラメータの読み込み\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net_trained = TransformerClassification().to(device)\n",
    "\n",
    "net_trained.load_state_dict(torch.load('highacc2.pth'))\n",
    "# print('読み込み後のモデル:\\n', model2.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(net_trained.state_dict(), 'highacc3.pth')\n",
    "\n",
    "# 新しいモデル\n",
    "model2 = TransformerClassification().to(device)\n",
    "print('新しいモデル:\\n', model2.state_dict())\n",
    "\n",
    "# 保存したモデルパラメータの読み込み\n",
    "model2.load_state_dict(torch.load('highacc3.pth'))\n",
    "print('読み込み後のモデル:\\n', model2.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention weight の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "print(data)\n",
    "print(data.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 同時に入れるデータも作成する\n",
    "# これは時系列スタンプ．0〜100がサンプル数だけ作られる\n",
    "stamp_row = [i%data.shape[1] for i in range(data.shape[0] * data.shape[1])]\n",
    "\n",
    "# いつ撮影されたのかのスタンプ\n",
    "l_date_name = np.array(df_annotate['date'].unique())\n",
    "date_row = []\n",
    "for item in l_date_name:\n",
    "    for i in range(data.shape[1]):\n",
    "        date_row.append(item)\n",
    "        \n",
    "# アテンションウエイト\n",
    "attn_weight = data.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attn = pd.DataFrame()\n",
    "df_attn['date'] = date_row\n",
    "df_attn[\"stamp\"] = stamp_row\n",
    "df_attn[\"attn_weight\"] = attn_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attn.to_excel('/Users/kento/kuhp/experiment/attention_weights.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_attn['date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "timeseries_transformer_classification.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/keras-team/keras-io/blob/master/examples/timeseries/ipynb/timeseries_classification_transformer.ipynb",
     "timestamp": 1636355482830
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
