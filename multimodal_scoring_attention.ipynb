{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyRQwYrEYTpv"
   },
   "source": [
    "# 修士論文実験 2022/01/10\n",
    "## マルチモーダルに挑戦\n",
    "## (validationが簡単に行えるようにデータセットを操作するモジュールを拡充)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 843,
     "status": "ok",
     "timestamp": 1636987406075,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "dO5GxI7RzXIc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# sys.path.append(os.path.abspath(\"..\"))\n",
    "# import scripts.compensate\n",
    "# import scripts.kinectImg2video\n",
    "# from scripts.conpemsate_suppresser import *\n",
    "# from scripts.ground_angle_analysis import ground_shoulder_angle_analyzer\n",
    "# import scripts.ground_angle_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日付の追加\n",
    "df_annotate = pd.read_excel(\"/Users/kento/kuhp/experiment/annotate_dataset.xlsx\")\n",
    "df_annotate['date'] = pd.to_datetime(df_annotate['date'], format='%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>uid</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>point</th>\n",
       "      <th>shoulder</th>\n",
       "      <th>body</th>\n",
       "      <th>flag_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-06 18:56:20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-06 18:56:20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-06 18:56:41</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-06 18:56:41</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-06 18:56:58</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  uid  subject_id  task_id point  shoulder  body  \\\n",
       "0 2021-12-06 18:56:20    1           1        1     3         0     0   \n",
       "1 2021-12-06 18:56:20    2           1        1     4         0     0   \n",
       "2 2021-12-06 18:56:41    3           1        1     3         0     0   \n",
       "3 2021-12-06 18:56:41    4           1        1     4         0     0   \n",
       "4 2021-12-06 18:56:58    5           1        1     3         0     0   \n",
       "\n",
       "   flag_usage  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           2  \n",
       "4           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>x_Pelvis</th>\n",
       "      <th>y_Pelvis</th>\n",
       "      <th>z_Pelvis</th>\n",
       "      <th>x_SpineNaval</th>\n",
       "      <th>y_SpineNaval</th>\n",
       "      <th>z_SpineNaval</th>\n",
       "      <th>x_SpineChest</th>\n",
       "      <th>...</th>\n",
       "      <th>x_REar</th>\n",
       "      <th>y_REar</th>\n",
       "      <th>z_REar</th>\n",
       "      <th>N</th>\n",
       "      <th>v_RWrist</th>\n",
       "      <th>z_v_RWrist</th>\n",
       "      <th>flag_active</th>\n",
       "      <th>flag_moving</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-158.973129</td>\n",
       "      <td>353.261841</td>\n",
       "      <td>698.233093</td>\n",
       "      <td>-149.886017</td>\n",
       "      <td>218.100922</td>\n",
       "      <td>780.778748</td>\n",
       "      <td>-142.035919</td>\n",
       "      <td>...</td>\n",
       "      <td>-178.933960</td>\n",
       "      <td>-236.272278</td>\n",
       "      <td>842.268127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.917988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-156.911919</td>\n",
       "      <td>356.031863</td>\n",
       "      <td>697.378637</td>\n",
       "      <td>-147.957493</td>\n",
       "      <td>219.063530</td>\n",
       "      <td>781.238292</td>\n",
       "      <td>-142.348493</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.788628</td>\n",
       "      <td>-241.853940</td>\n",
       "      <td>862.009244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.131710</td>\n",
       "      <td>0.480634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.891892</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-157.406120</td>\n",
       "      <td>356.970863</td>\n",
       "      <td>697.867036</td>\n",
       "      <td>-148.184343</td>\n",
       "      <td>219.214968</td>\n",
       "      <td>781.799317</td>\n",
       "      <td>-142.899719</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.093690</td>\n",
       "      <td>-243.703880</td>\n",
       "      <td>867.831643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.690953</td>\n",
       "      <td>0.198082</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.783784</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-159.493486</td>\n",
       "      <td>356.687710</td>\n",
       "      <td>699.214911</td>\n",
       "      <td>-149.753131</td>\n",
       "      <td>218.849632</td>\n",
       "      <td>782.412353</td>\n",
       "      <td>-143.553739</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.457427</td>\n",
       "      <td>-243.071735</td>\n",
       "      <td>864.096621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.280899</td>\n",
       "      <td>0.313779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.675676</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-162.211771</td>\n",
       "      <td>355.791270</td>\n",
       "      <td>700.938883</td>\n",
       "      <td>-151.850422</td>\n",
       "      <td>218.261918</td>\n",
       "      <td>783.027933</td>\n",
       "      <td>-144.174692</td>\n",
       "      <td>...</td>\n",
       "      <td>-177.488121</td>\n",
       "      <td>-241.207140</td>\n",
       "      <td>855.165480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.247976</td>\n",
       "      <td>0.307322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.567568</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1   id    x_Pelvis    y_Pelvis    z_Pelvis  \\\n",
       "0           0             0  1.0 -158.973129  353.261841  698.233093   \n",
       "1           1             1  1.0 -156.911919  356.031863  697.378637   \n",
       "2           2             2  1.0 -157.406120  356.970863  697.867036   \n",
       "3           3             3  1.0 -159.493486  356.687710  699.214911   \n",
       "4           4             4  1.0 -162.211771  355.791270  700.938883   \n",
       "\n",
       "   x_SpineNaval  y_SpineNaval  z_SpineNaval  x_SpineChest  ...      x_REar  \\\n",
       "0   -149.886017    218.100922    780.778748   -142.035919  ... -178.933960   \n",
       "1   -147.957493    219.063530    781.238292   -142.348493  ... -176.788628   \n",
       "2   -148.184343    219.214968    781.799317   -142.899719  ... -176.093690   \n",
       "3   -149.753131    218.849632    782.412353   -143.553739  ... -176.457427   \n",
       "4   -151.850422    218.261918    783.027933   -144.174692  ... -177.488121   \n",
       "\n",
       "       y_REar      z_REar   N  v_RWrist  z_v_RWrist  flag_active  flag_moving  \\\n",
       "0 -236.272278  842.268127 NaN       NaN   -0.917988          0.0          1.0   \n",
       "1 -241.853940  862.009244 NaN  7.131710    0.480634          1.0          1.0   \n",
       "2 -243.703880  867.831643 NaN  5.690953    0.198082          1.0          1.0   \n",
       "3 -243.071735  864.096621 NaN  6.280899    0.313779          1.0          1.0   \n",
       "4 -241.207140  855.165480 NaN  6.247976    0.307322          1.0          1.0   \n",
       "\n",
       "    timestamp                date  \n",
       "0    0.000000 2021-12-04 18:20:18  \n",
       "1   39.891892 2021-12-04 18:20:18  \n",
       "2   79.783784 2021-12-04 18:20:18  \n",
       "3  119.675676 2021-12-04 18:20:18  \n",
       "4  159.567568 2021-12-04 18:20:18  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataSetの呼び出し\n",
    "df_data = pd.read_csv(\"/Users/kento/kuhp/experiment/bigdata_trimmed.csv\")\n",
    "df_data['date'] = pd.to_datetime(df_data['date'], format='%Y-%m-%d-%H-%M-%S')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1636987406076,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "GZlVgJy1zXIc"
   },
   "outputs": [],
   "source": [
    "# pd_merged = pd.merge(df_annotate, df_data, on='date', how='inner')\n",
    "# pd_3 = pd_merged[pd_merged['point'] == 3]\n",
    "# pd_2A = pd_merged[pd_merged['point'] == '2A']\n",
    "# pd_2B = pd_merged[pd_merged['point'] == '2B']\n",
    "# pd_2C = pd_merged[pd_merged['point'] == '2C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### このデータセットはGraspのものかつ，usageが1のものが取り出されている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# データセットにNN入力用のスコアを割り振る．\n",
    "# これが正解ラベルになる\n",
    "dataset = pd.merge(df_annotate, df_data, on='date', how='inner')\n",
    "\n",
    "dataset = dataset[(dataset['task_id'] == 1) & (dataset['flag_usage'] == 1)]\n",
    "dataset['point'] = dataset['point'].astype(str)\n",
    "dataset.loc[dataset['point'] == '3', 'score'] = 3\n",
    "dataset.loc[dataset['point'] == '2A', 'score'] = 2\n",
    "dataset.loc[dataset['point'] == '2B', 'score'] = 1\n",
    "dataset.loc[dataset['point'] == '2C', 'score'] = 0\n",
    "print(dataset['score'].max())\n",
    "\n",
    "# Nanのものを削除\n",
    "dataset.dropna(subset=['score'], inplace=True)\n",
    "# scoreの行をintにする\n",
    "dataset['score'] = dataset['score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['uid'].unique()\n",
    "dataset['date'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grasp動作だけを抜き出す\n",
    "# dataset_grasp = dataset[dataset['task_id'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RElbow2RWrist と Rshoulder2RElbow と Pelvis2RShoulder と Pelvis2Neck の速度を入れてみる "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_annotate\n",
    "# l_date = df_annotate['date'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vector(df, joint1, joint2, word=\"\"):\n",
    "    df[f\"{word}_x_{joint1}2{joint2}\"] = df[f\"x_{joint1}\"].astype('float64') - df[f\"x_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_y_{joint1}2{joint2}\"] = df[f\"y_{joint1}\"].astype('float64') - df[f\"y_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_z_{joint1}2{joint2}\"] = df[f\"z_{joint1}\"].astype('float64') - df[f\"z_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_ave_{joint1}2{joint2}\"] = (df[f\"{word}_x_{joint1}2{joint2}\"] + df[f\"{word}_y_{joint1}2{joint2}\"] + df[f\"{word}_z_{joint1}2{joint2}\"])/3\n",
    "    return df\n",
    "\n",
    "def calc_angle(df, joint1, joint2, joint3):\n",
    "    l_theta = []\n",
    "    # 角度を算出する関数。p2を支点として、他の二点間の角度を算出する。\n",
    "    x1, y1 ,z1= df[f\"x_{joint1}\"].astype('float64'), df[f\"y_{joint1}\"].astype('float64'), df[f\"z_{joint1}\"].astype('float64')\n",
    "    x2, y2 ,z2= df[f\"x_{joint2}\"].astype('float64'), df[f\"y_{joint2}\"].astype('float64'), df[f\"z_{joint2}\"].astype('float64')\n",
    "    x3, y3 ,z3= df[f\"x_{joint3}\"].astype('float64'), df[f\"y_{joint3}\"].astype('float64'), df[f\"z_{joint3}\"].astype('float64')\n",
    "    v1 = np.array([x1-x2, y1-y2, z1-z2])\n",
    "    v2 = np.array([x3-x2, y3-y2, z3-z2])\n",
    "    for i in range(v1.shape[1]):\n",
    "        cos = np.dot(v1[:,i], v2[:,i])/(np.linalg.norm(v1[:,i], ord=2) * np.linalg.norm(v2[:,i], ord=2))\n",
    "        theta = np.degrees(math.acos(cos))\n",
    "        l_theta.append(theta)\n",
    "    return np.array(l_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 角度と角度の速度を入力とする\n",
    "angle_RElbow = calc_angle(dataset, 'RShoulder', 'RElbow', 'RWrist')\n",
    "diff_angle_RElbow = np.diff(angle_RElbow)\n",
    "\n",
    "angle_RShoulder = calc_angle(dataset, 'RElbow', 'RShoulder', 'Neck')\n",
    "diff_angle_RShoulder = np.diff(angle_RShoulder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_date_name = np.array(dataset['date'].unique())\n",
    "# l = []\n",
    "# for date in l_date_name:\n",
    "#     score = dataset[dataset[\"date\"] == date]['score'].mode()\n",
    "#     l.append(score)\n",
    "# return np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解ラベルで用いるyのone hotベクトルを作成\n",
    "def extract_y(df):\n",
    "    l = []\n",
    "    l_date_name = np.array(df['date'].unique())\n",
    "    for date in l_date_name:\n",
    "        score = df[df[\"date\"] == date]['score'].mode()\n",
    "        l.append(score)\n",
    "    y = np.array(l).flatten()\n",
    "    \n",
    "    # l_date_name = np.array(df['date'].unique())\n",
    "    # y = np.array(df[\"score\"]) #一番多いものをscoreとして最後にyとして返す\n",
    "    # y_arr = np.ones(l_date_name.shape)\n",
    "    # y_arr = y_arr * y\n",
    "    return y\n",
    "\n",
    "def interpolate1(array):\n",
    "    x_old = np.linspace(0, 1, array.shape[0])\n",
    "    y_old = array\n",
    "    \n",
    "    f = interpolate.interp1d(x_old, y_old)\n",
    "\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    y_new = f(x)\n",
    "    return y_new\n",
    "\n",
    "def zscore(x, axis = 1):\n",
    "    xmean = x.mean(axis=axis, keepdims=True)\n",
    "    xstd  = np.std(x, axis=axis, keepdims=True)\n",
    "    zscore = (x-xmean)/xstd\n",
    "    return zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ara = np.array([[[1,2,3,4,5],[4,5,6,7,8],[7,8,9,10,11]]])\n",
    "# ara.shape\n",
    "# z = zscore(ara)\n",
    "# print(z.shape)\n",
    "# print(ara)\n",
    "# print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# この関数を実行しさえすればデータセットが作成される\n",
    "def create_Xy(dataset):\n",
    "    #正解ラベルの作成\n",
    "    y = extract_y(dataset)\n",
    "    \n",
    "    # Xの作成\n",
    "    l_date_name = np.array(dataset['date'].unique())\n",
    "    for k, date in enumerate(l_date_name):\n",
    "        #一連のデータ，1サンプル\n",
    "        series = dataset[dataset['date'] == l_date_name[k]]\n",
    "        series.drop(columns='point', inplace=True)\n",
    "        series.drop(columns='date', inplace=True)\n",
    "        #差分ベクトルを取得\n",
    "        diff = series.diff()\n",
    "        diff.fillna(0, inplace=True)\n",
    "\n",
    "        # 間接点同士のベクトルのカラムをデータフレームに追加\n",
    "        # これらがデータセットになる\n",
    "        diff = add_vector(diff, 'RElbow', \"RWrist\", 'v')\n",
    "        diff = add_vector(diff, 'RShoulder', \"RElbow\", 'v')\n",
    "        diff = add_vector(diff, 'Pelvis', \"RShoulder\", 'v')\n",
    "        diff = add_vector(diff, 'Pelvis', \"Neck\", 'v')\n",
    "        diff = add_vector(diff, 'Neck', 'RShoulder', 'v')\n",
    "        diff = add_vector(diff, 'Neck', 'LShoulder', 'v')\n",
    "        \n",
    "#         diff['x_angle_RElbow'] = angle_RElbow\n",
    "#         diff['x2_angle_RElbow'] = angle_RElbow\n",
    "#         diff['x_diff_angle_RElbow'] = diff_angle_RElbow\n",
    "#         diff['diff_angle_RElbow2'] = diff_angle_RElbow\n",
    "        \n",
    "#         diff['angle_RShoulder'] = angle_RShoulder\n",
    "#         diff['angle_RShoulder2'] = angle_RShoulder\n",
    "#         diff['diff_angle_RShoulder'] = diff_angle_RShoulder\n",
    "#         diff['diff_angle_RShoulder2'] = diff_angle_RShoulder\n",
    "        \n",
    "        # arr_data = diff.loc[:, columns].values\n",
    "        arr_data = diff.loc[:, \"v_x_RElbow2RWrist\":].values\n",
    "        \n",
    "        # 補間を行う\n",
    "        for i in range(arr_data.shape[1]):\n",
    "            tmp_interpolate = interpolate1(arr_data[:, i])\n",
    "            # print(tmp_interpolate.shape)\n",
    "            #二次元に拡張\n",
    "            tmp_interpolate = tmp_interpolate.reshape(tmp_interpolate.shape[0], 1)\n",
    "            if i == 0:\n",
    "                x = tmp_interpolate\n",
    "            else:\n",
    "                x = np.concatenate([x, tmp_interpolate],1)\n",
    "                \n",
    "        # サンプル数の次元を拡張する\n",
    "        x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "        \n",
    "        #最初だけ条件分岐\n",
    "        if k == 0:\n",
    "            X = x\n",
    "        else:\n",
    "            X = np.concatenate([X, x], axis=0)\n",
    "        \n",
    "       # 最後にzscore変換\n",
    "        X = zscore(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # この関数を実行しさえすればデータセットが作成される\n",
    "# def create_scoring_Xy(dataset):\n",
    "#     #正解ラベルの作成\n",
    "#     y = (np.array(dataset[\"score\"]) - 1.5) / 1.5\n",
    "    \n",
    "#     # Xの作成\n",
    "#     l_date_name = np.array(dataset['date'].unique())\n",
    "#     for k, date in enumerate(l_date_name):\n",
    "#         #一連のデータ，1サンプル\n",
    "#         series = dataset[dataset['date'] == l_date_name[k]]\n",
    "#         series.drop(columns='point', inplace=True)\n",
    "#         series.drop(columns='date', inplace=True)\n",
    "#         #差分ベクトルを取得\n",
    "#         diff = series.diff()\n",
    "#         diff.fillna(0, inplace=True)\n",
    "\n",
    "#         # 間接点同士のベクトルのカラムをデータフレームに追加\n",
    "#         # これらがデータセットになる\n",
    "#         diff = add_vector(diff, 'RElbow', \"RWrist\", 'v')\n",
    "#         diff = add_vector(diff, 'RShoulder', \"RElbow\", 'v')\n",
    "#         diff = add_vector(diff, 'Pelvis', \"RShoulder\", 'v')\n",
    "#         diff = add_vector(diff, 'Pelvis', \"Neck\", 'v')\n",
    "#         diff = add_vector(diff, 'Neck', 'RShoulder', 'v')\n",
    "#         diff = add_vector(diff, 'Neck', 'LShoulder', 'v')\n",
    "        \n",
    "# #         diff['x_angle_RElbow'] = angle_RElbow\n",
    "# #         diff['x2_angle_RElbow'] = angle_RElbow\n",
    "# #         diff['x_diff_angle_RElbow'] = diff_angle_RElbow\n",
    "# #         diff['diff_angle_RElbow2'] = diff_angle_RElbow\n",
    "        \n",
    "# #         diff['angle_RShoulder'] = angle_RShoulder\n",
    "# #         diff['angle_RShoulder2'] = angle_RShoulder\n",
    "# #         diff['diff_angle_RShoulder'] = diff_angle_RShoulder\n",
    "# #         diff['diff_angle_RShoulder2'] = diff_angle_RShoulder\n",
    "        \n",
    "#         # arr_data = diff.loc[:, columns].values\n",
    "#         arr_data = diff.loc[:, \"v_x_RElbow2RWrist\":].values\n",
    "        \n",
    "#         # 補間を行う\n",
    "#         for i in range(arr_data.shape[1]):\n",
    "#             tmp_interpolate = interpolate1(arr_data[:, i])\n",
    "#             # print(tmp_interpolate.shape)\n",
    "#             #二次元に拡張\n",
    "#             tmp_interpolate = tmp_interpolate.reshape(tmp_interpolate.shape[0], 1)\n",
    "#             if i == 0:\n",
    "#                 x = tmp_interpolate\n",
    "#             else:\n",
    "#                 x = np.concatenate([x, tmp_interpolate],1)\n",
    "                \n",
    "#         # サンプル数の次元を拡張する\n",
    "#         x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "        \n",
    "#         #最初だけ条件分岐\n",
    "#         if k == 0:\n",
    "#             X = x\n",
    "#         else:\n",
    "#             X = np.concatenate([X, x], axis=0)\n",
    "        \n",
    "#        # 最後にzscore変換\n",
    "#         X = zscore(X)\n",
    "#     return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxW659H6YTpz"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "Our model processes a tensor of shape `(batch size, sequence length, features)`,\n",
    "where `sequence length` is the number of time steps and `features` is each input\n",
    "timeseries.\n",
    "\n",
    "You can replace your classification RNN layers with this one: the\n",
    "inputs are fully compatible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urNK4ym-YTp0"
   },
   "source": [
    "We include residual connections, layer normalization, and dropout.\n",
    "The resulting layer can be stacked multiple times.\n",
    "\n",
    "The projection layers are implemented through `keras.layers.Conv1D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    '''入力された単語の位置を示すベクトル情報を付加する'''\n",
    "\n",
    "    def __init__(self, d_model=12, max_seq_len=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model  # 単語ベクトルの次元数\n",
    "\n",
    "        # 単語の順番（pos）と埋め込みベクトルの次元の位置（i）によって一意に定まる値の表をpeとして作成\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "\n",
    "        # GPUが使える場合はGPUへ送る、ここでは省略。実際に学習時には使用する\n",
    "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # pe = pe.to(device)\n",
    "\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                \n",
    "                # 誤植修正_200510 #79\n",
    "                # pe[pos, i + 1] = math.cos(pos /\n",
    "                #                          (10000 ** ((2 * (i + 1))/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos /\n",
    "                                          (10000 ** ((2 * i)/d_model)))\n",
    "\n",
    "        # 表peの先頭に、ミニバッチ次元となる次元を足す\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "        # 勾配を計算しないようにする\n",
    "        self.pe.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 入力xとPositonal Encodingを足し算する\n",
    "        # xがpeよりも小さいので、大きくする\n",
    "        ret = math.sqrt(self.d_model)*x + self.pe\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # SAGANでは1dConvを使用したが、今回は全結合層で特徴量を変換する\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # 出力時に使用する全結合層\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Attentionの大きさ調整の変数\n",
    "        self.d_k = d_model\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        # 全結合層で特徴量を変換\n",
    "        k = self.k_linear(k)\n",
    "        q = self.q_linear(q)\n",
    "        v = self.v_linear(v)\n",
    "\n",
    "        # Attentionの値を計算する\n",
    "        # 各値を足し算すると大きくなりすぎるので、root(d_k)で割って調整\n",
    "        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)\n",
    "\n",
    "        # ここでmaskを計算\n",
    "        # mask = mask.unsqueeze(1)\n",
    "        # print(mask)\n",
    "        # weights = weights.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # softmaxで規格化をする\n",
    "        normlized_weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "        # AttentionをValueとかけ算\n",
    "        output = torch.matmul(normlized_weights, v)\n",
    "\n",
    "        # 全結合層で特徴量を変換\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, normlized_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
    "        '''Attention層から出力を単純に全結合層2つで特徴量を変換するだけのユニットです'''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.dropout(F.relu(x))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # LayerNormalization層\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=layernorm\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Attention層\n",
    "        self.attn = Attention(d_model)\n",
    "\n",
    "        # Attentionのあとの全結合層2つ\n",
    "        self.ff = FeedForward(d_model)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # 正規化とAttention\n",
    "        # print(f\"input shape is {x.shape}\")\n",
    "        x_normlized = self.norm_1(x)\n",
    "        output, attn_weights = self.attn(x_normlized, x_normlized, x_normlized, mask)\n",
    "        \n",
    "        x2 = x + self.dropout_1(output)\n",
    "\n",
    "        # 正規化と全結合層\n",
    "        x_normlized2 = self.norm_2(x2)\n",
    "        output = x2 + self.dropout_2(self.ff(x_normlized2))\n",
    "        # print(f\"output shape is {output.shape}\")\n",
    "\n",
    "        return output, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringHead(nn.Module):\n",
    "    '''Transformer_Blockの出力を使用して，最後にスコアリングを行う'''\n",
    "    \n",
    "    def __init__(self, d_model=300, output_dim=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # 全結合層\n",
    "        self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # 重み初期化処理\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n",
    "        weights = self.linear.weight\n",
    "        out = self.linear(x0)\n",
    "        \n",
    "        # print(f\"Scoring input shape is {x0.shape}\")\n",
    "        # print(f\"Scoring weight shape is {weights.shape}\")\n",
    "        # print(f\"Scoring output shape is {out.shape}\")\n",
    "\n",
    "        return out, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ClassificationHead(nn.Module):\n",
    "#     '''Transformer_Blockの出力を使用し、最後にクラス分類させる'''\n",
    "\n",
    "#     def __init__(self, d_model=300, output_dim=4):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # 全結合層\n",
    "#         self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n",
    "#         self.output_dim = output_dim\n",
    "\n",
    "#         # 重み初期化処理\n",
    "#         nn.init.normal_(self.linear.weight, std=0.02)\n",
    "#         nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n",
    "#         x1 = self.linear(x0)\n",
    "#         # print(x1.shape)\n",
    "#         out = F.softmax(x1, dim=-1)\n",
    "\n",
    "#         return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここで複数入力のAttentionにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 最終的なTransformerモデルのクラス\n",
    "\n",
    "# class TransformerClassification(nn.Module):\n",
    "#     '''Transformerでクラス分類させる'''\n",
    "\n",
    "#     def __init__(self, d_model=12, max_seq_len=101, output_dim=4):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # モデル構築\n",
    "#         self.net_Positional = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
    "        \n",
    "#         self.net_Attention_1 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_2 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_3 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_4 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_5 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_6 = TransformerBlock(d_model=4)\n",
    "        \n",
    "#         self.net_Attention_all = TransformerBlock(d_model=24)\n",
    "#         # self.net3_2 = TransformerBlock(d_model=d_model)\n",
    "        \n",
    "#         self.net_Classification = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
    "\n",
    "#     def forward(self, x, mask):\n",
    "#         x = self.net_Positional(x)  # Positon情報を足し算\n",
    "#         #ここでいくつのAttentionアーキテクチャを利用するか決定する\n",
    "#         # num_attention_block = x.shape[2]/4\n",
    "        \n",
    "#         x1, attn_weights_1 = self.net_Attention_1(x[:,:,0:4], mask[:,:,0:4])  # Self-Attentionで特徴量を変換\n",
    "#         x2, attn_weights_2 = self.net_Attention_2(x[:,:,4:8], mask[:,:,4:8])\n",
    "#         x3, attn_weights_3 = self.net_Attention_3(x[:,:,8:12], mask[:,:,8:12])\n",
    "#         x4, attn_weights_4 = self.net_Attention_4(x[:,:,12:16], mask[:,:,12:16])\n",
    "#         x5, attn_weights_5 = self.net_Attention_5(x[:,:,16:20], mask[:,:,16:20])\n",
    "#         x6, attn_weights_6 = self.net_Attention_6(x[:,:,20:24], mask[:,:,20:24])\n",
    "        \n",
    "#         #出力を全部つなぎ合わせる\n",
    "#         x_concat = torch.cat((x1,x2,x3,x4,x5,x6), 2)\n",
    "#         # x_attn, attn_weights_all = self.net_Attention_all(x_concat, mask)\n",
    "        \n",
    "#         x_out = self.net_Classification(x_concat)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
    "        \n",
    "#         l_attn_weights = [attn_weights_1,attn_weights_2,attn_weights_3,attn_weights_4,attn_weights_5,attn_weights_6\n",
    "#                           # , attn_weights_all\n",
    "#                          ] \n",
    "#         return x_out, l_attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的なTransformerモデルのクラス\n",
    "\n",
    "class TransformerScoring(nn.Module):\n",
    "    '''Transformerでクラス分類させる'''\n",
    "\n",
    "    def __init__(self, d_model=12, max_seq_len=101, output_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # モデル構築\n",
    "        self.net_Positional = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
    "        \n",
    "        self.net_Attention_1 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_2 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_3 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_4 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_5 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_6 = TransformerBlock(d_model=4)\n",
    "        \n",
    "        self.net_Attention_all = TransformerBlock(d_model=24)\n",
    "        # self.net3_2 = TransformerBlock(d_model=d_model)\n",
    "        \n",
    "        # self.net_Classification = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
    "        self.net_Scoring = ScoringHead(output_dim=output_dim, d_model=d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.net_Positional(x)  # Positon情報を足し算\n",
    "        #ここでいくつのAttentionアーキテクチャを利用するか決定する\n",
    "        # num_attention_block = x.shape[2]/4\n",
    "        \n",
    "        x1, attn_weights_1 = self.net_Attention_1(x[:,:,0:4], mask[:,:,0:4])  # Self-Attentionで特徴量を変換\n",
    "        x2, attn_weights_2 = self.net_Attention_2(x[:,:,4:8], mask[:,:,4:8])\n",
    "        x3, attn_weights_3 = self.net_Attention_3(x[:,:,8:12], mask[:,:,8:12])\n",
    "        x4, attn_weights_4 = self.net_Attention_4(x[:,:,12:16], mask[:,:,12:16])\n",
    "        x5, attn_weights_5 = self.net_Attention_5(x[:,:,16:20], mask[:,:,16:20])\n",
    "        x6, attn_weights_6 = self.net_Attention_6(x[:,:,20:24], mask[:,:,20:24])\n",
    "        \n",
    "        #出力を全部つなぎ合わせる\n",
    "        x_concat = torch.cat((x1,x2,x3,x4,x5,x6), 2)\n",
    "        # x_attn, attn_weights_all = self.net_Attention_all(x_concat, mask)\n",
    "        \n",
    "        x_out, _ = self.net_Scoring(x_concat)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
    "        \n",
    "        l_attn_weights = [attn_weights_1,attn_weights_2,attn_weights_3,attn_weights_4,attn_weights_5,attn_weights_6\n",
    "                          # , attn_weights_all\n",
    "                         ] \n",
    "        return x_out, l_attn_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# validation用に1人のデータを検証データに回す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset\n",
    "# [~(dataset['subject_id'] == 4)]\n",
    "val_df = dataset[dataset['subject_id'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PyTorchのdatasetの作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kento/miniforge3/envs/torch/lib/python3.8/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 2 2 2 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = create_Xy(train_df)\n",
    "x_test, y_test = create_Xy(val_df)\n",
    "print(y_test)\n",
    "\n",
    "y_train = y_train.astype('int64')\n",
    "# y_test = y_test.astype('int64')\n",
    "\n",
    "\n",
    "# 正解データをone hotベクトルに変換\n",
    "n_classes = len(np.unique(y_train))\n",
    "y_train_onehot = np.identity(n_classes)[y_train]\n",
    "y_test_onehot = np.identity(n_classes)[y_test]\n",
    "\n",
    "\n",
    "### 先頭にclassification用のトークンを追加する\n",
    "score_train = np.zeros((x_train.shape[0], 1 , x_train.shape[2]))\n",
    "x_train = np.concatenate([score_train, x_train], axis=1)\n",
    "\n",
    "score_test = np.zeros((x_test.shape[0], 1 , x_test.shape[2]))\n",
    "x_test = np.concatenate([score_test, x_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 先頭にclassification用のトークンを追加する\n",
    "# score_train = np.zeros((x_train.shape[0], 1 , x_train.shape[2]))\n",
    "# x_train = np.concatenate([score_train, x_train], axis=1)\n",
    "\n",
    "# score_test = np.zeros((x_test.shape[0], 1 , x_test.shape[2]))\n",
    "# x_test = np.concatenate([score_test, x_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1636987650297,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "8vf0x--aaZjE",
    "outputId": "57c2d515-00a5-443a-b22e-6fa77d359e84"
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(x_train, dtype=torch.float32)\n",
    "                                               , torch.tensor(y_train_onehot, dtype=torch.int8))\n",
    "val_dataset = torch.utils.data.TensorDataset(torch.tensor(x_test, dtype=torch.float32),\n",
    "                                             torch.tensor(y_test_onehot, dtype=torch.int8))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LakZIHM8YTp1"
   },
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力のテンソルサイズ： torch.Size([8, 1])\n",
      "出力テンソル tensor([[0.5152],\n",
      "        [0.5442],\n",
      "        [0.5203],\n",
      "        [0.5453],\n",
      "        [0.5178],\n",
      "        [0.5726],\n",
      "        [0.5596],\n",
      "        [0.5358]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 動作確認\n",
    "# ミニバッチの用意\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "# モデル構築\n",
    "\n",
    "# 変数の固定\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "\n",
    "net = TransformerScoring(\n",
    "    d_model=24, max_seq_len=101, output_dim=1)\n",
    "\n",
    "# 入出力\n",
    "_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(_device)\n",
    "x = batch[0].to(_device)\n",
    "input_pad = 1\n",
    "input_mask = (x != input_pad)\n",
    "out, l_weights = net(x, input_mask)\n",
    "\n",
    "print(\"出力のテンソルサイズ：\", out.shape)\n",
    "print(\"出力テンソル\", out)\n",
    "# print(\"出力テンソルのsigmoid：\", F.softmax(out, dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elTTH_9KYTp0"
   },
   "source": [
    "The main part of our model is now complete. We can stack multiple of those\n",
    "`transformer_encoder` blocks and we can also proceed to add the final\n",
    "Multi-Layer Perceptron classification head. Apart from a stack of `Dense`\n",
    "layers, we need to reduce the output tensor of the `TransformerEncoder` part of\n",
    "our model down to a vector of features for each data point in the current\n",
    "batch. A common way to achieve this is to use a pooling layer. For\n",
    "this example, a `GlobalAveragePooling1D` layer is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ネットワークの初期化を定義\n",
    "\n",
    "# def weights_init(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     if classname.find('Linear') != -1:\n",
    "#         # Liner層の初期化\n",
    "#         nn.init.kaiming_normal_(m.weight)\n",
    "#         if m.bias is not None:\n",
    "#             nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "# # 訓練モードに設定\n",
    "# net.train()\n",
    "\n",
    "# # TransformerBlockモジュールを初期化実行\n",
    "\n",
    "# net.net_Attention_1.apply(weights_init)\n",
    "\n",
    "\n",
    "\n",
    "# print('ネットワーク設定完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の設定\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n",
    "\n",
    "# 最適化手法の設定\n",
    "learning_rate = 3e-4\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "    print('-----start-------')\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "        # for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和\n",
    "            epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "            # データローダーからミニバッチを取り出すループ\n",
    "            for batch in (dataloaders_dict[phase]):\n",
    "                # batchはTextとLableの辞書オブジェクト\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                inputs = batch[0].to(device)  # 文章\n",
    "                labels = batch[1].to(device)  # ラベル\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    # mask作成\n",
    "                    input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "                    input_mask = (inputs != input_pad)\n",
    "\n",
    "                    # Transformerに入力\n",
    "                    outputs, _ = net(inputs, input_mask)\n",
    "                    _, labels_true = torch.max(labels.data, 1)  # ワンホットラベルを平坦化\n",
    "                    labels_true_float = (labels_true - 1.5) / 1.5\n",
    "                    # print(f\"outputs shape is {outputs.flatten().shape}, label shape is {labels_true.shape}\")\n",
    "                    outputs = outputs.flatten()\n",
    "                    loss = criterion(outputs, labels_true_float)  # 損失を計算\n",
    "                    # print(f\"output is {outputs}, labels are {labels_true.float()}\")\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # 結果の計算\n",
    "                    # print(np.array(preds))\n",
    "                    # print(np.array(np.argmax(labels.data)))\n",
    "                    # print(preds == labels.data)\n",
    "                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n",
    "                    # 正解数の合計を更新\n",
    "                    \n",
    "                    # one_hot=F.one_hot(preds,num_classes=4)\n",
    "                    # epoch_corrects += torch.sum(preds == labels_true)\n",
    "                    # print(labels_true)\n",
    "                    # print(torch.flatten(preds))\n",
    "                    preds = torch.round((outputs + 1.5)*1.5)  # ラベルを予測\n",
    "                    # print(f\"predicts are {preds}, labels {labels_true}\")\n",
    "                    # print(preds == labels_true)\n",
    "                    epoch_corrects += torch.sum(preds == labels_true)\n",
    "\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "            else:\n",
    "                writer.add_scalar(\"Loss/test\", loss, epoch)\n",
    "\n",
    "            # epochごとのlossと正解率\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            \n",
    "            # if epoch % 100 == 0:\n",
    "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
    "                                                                           phase, epoch_loss, epoch_acc))\n",
    "                # print(f\"epoch corrects {epoch_corrects.double()}\")\n",
    "                # print(f\"dataset size = {len(dataloaders_dict[phase].dataset)}\")\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "seed is 1099\n",
      "learning_rate is 0.0003\n",
      "使用デバイス： cpu\n",
      "-----start-------\n",
      "Epoch 1/300 | train |  Loss: 1.2372 Acc: 0.2553\n",
      "Epoch 1/300 |  val  |  Loss: 1.0272 Acc: 0.2500\n",
      "Epoch 2/300 | train |  Loss: 0.9534 Acc: 0.2340\n",
      "Epoch 2/300 |  val  |  Loss: 0.7881 Acc: 0.2500\n",
      "Epoch 3/300 | train |  Loss: 0.7492 Acc: 0.2340\n",
      "Epoch 3/300 |  val  |  Loss: 0.6363 Acc: 0.2500\n",
      "Epoch 4/300 | train |  Loss: 0.6351 Acc: 0.2340\n",
      "Epoch 4/300 |  val  |  Loss: 0.5677 Acc: 0.2500\n",
      "Epoch 5/300 | train |  Loss: 0.5721 Acc: 0.2340\n",
      "Epoch 5/300 |  val  |  Loss: 0.5566 Acc: 0.2500\n",
      "Epoch 6/300 | train |  Loss: 0.5833 Acc: 0.2340\n",
      "Epoch 6/300 |  val  |  Loss: 0.5616 Acc: 0.2500\n",
      "Epoch 7/300 | train |  Loss: 0.5455 Acc: 0.2766\n",
      "Epoch 7/300 |  val  |  Loss: 0.5611 Acc: 0.2500\n",
      "Epoch 8/300 | train |  Loss: 0.5498 Acc: 0.2766\n",
      "Epoch 8/300 |  val  |  Loss: 0.5575 Acc: 0.2500\n",
      "Epoch 9/300 | train |  Loss: 0.5717 Acc: 0.2340\n",
      "Epoch 9/300 |  val  |  Loss: 0.5543 Acc: 0.2500\n",
      "Epoch 10/300 | train |  Loss: 0.5385 Acc: 0.2340\n",
      "Epoch 10/300 |  val  |  Loss: 0.5539 Acc: 0.2500\n",
      "Epoch 11/300 | train |  Loss: 0.5650 Acc: 0.2340\n",
      "Epoch 11/300 |  val  |  Loss: 0.5545 Acc: 0.2500\n",
      "Epoch 12/300 | train |  Loss: 0.5799 Acc: 0.2340\n",
      "Epoch 12/300 |  val  |  Loss: 0.5543 Acc: 0.2500\n",
      "Epoch 13/300 | train |  Loss: 0.5700 Acc: 0.2340\n",
      "Epoch 13/300 |  val  |  Loss: 0.5535 Acc: 0.2500\n",
      "Epoch 14/300 | train |  Loss: 0.5632 Acc: 0.2340\n",
      "Epoch 14/300 |  val  |  Loss: 0.5523 Acc: 0.2500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yt/fsd0dzhn23z2jcmc2hrkjcn00000gn/T/ipykernel_16953/3735507930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     net_trained = train_model(net, \n\u001b[0m\u001b[1;32m     31\u001b[0m                               \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                               \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yt/fsd0dzhn23z2jcmc2hrkjcn00000gn/T/ipykernel_16953/3964071613.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, dataloaders_dict, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0;31m# 訓練時はバックプロパゲーション\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "# グリッドサーチを行う．\n",
    "l_rate = [3e-4, 5e-4, 1e-3]\n",
    "# l_rate = [1e-3]\n",
    "num_epochs = 300\n",
    "\n",
    "seeds = []\n",
    "for i in range(100):\n",
    "    seeds.append(1000+i)\n",
    "\n",
    "for seed in seeds:\n",
    "    pass\n",
    "print(\"---------------------------\")\n",
    "print(f\"seed is {seed}\")\n",
    "for learning_rate in l_rate:\n",
    "    writer = SummaryWriter()\n",
    "    print(f\"learning_rate is {learning_rate}\")\n",
    "\n",
    "    # 変数の固定\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    # モデル構築\n",
    "    net = TransformerScoring(d_model=24, max_seq_len=101, output_dim=1)\n",
    "    # 訓練モードに設定\n",
    "    net.train()\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    start = time.time()\n",
    "    net_trained = train_model(net, \n",
    "                              dataloaders_dict,\n",
    "                              criterion,\n",
    "                              optimizer,\n",
    "                              num_epochs\n",
    "                             )\n",
    "    print(time.time() - start)\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 学習・検証を実行する 15分ほどかかります\n",
    "# net = TransformerClassification(d_model=24, max_seq_len=101, output_dim=4)\n",
    "# # 訓練モードに設定\n",
    "# net.train()\n",
    "\n",
    "# # 損失関数の設定\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# # nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n",
    "\n",
    "# # 最適化手法の設定\n",
    "# learning_rate = 2e-4\n",
    "# optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# print('ネットワーク設定完了')\n",
    "\n",
    "# num_epochs = 300\n",
    "# net_trained = train_model(net, dataloaders_dict,\n",
    "#                           criterion, optimizer, num_epochs=num_epochs)\n",
    "# writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN2SeFtLHbyT"
   },
   "source": [
    "# SaveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テストデータ47個での正解率：0.0000\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net_trained.eval()   # モデルを検証モードに\n",
    "net_trained.to(device)\n",
    "\n",
    "epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "# test_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=60)\n",
    "test_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=60)\n",
    "\n",
    "for batch in (test_dataloader):  # testデータのDataLoader\n",
    "    # batchはTextとLableの辞書オブジェクト\n",
    "    \n",
    "    # GPUが使えるならGPUにデータを送る\n",
    "    inputs = batch[0].to(device)  # 文章\n",
    "    labels = batch[1].to(device)  # ラベル\n",
    "\n",
    "    # 順伝搬（forward）計算\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        # mask作成\n",
    "        input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "        input_mask = (inputs != input_pad)\n",
    "\n",
    "        # Transformerに入力\n",
    "        outputs, _ = net(inputs, input_mask)\n",
    "        _, labels_true = torch.max(labels.data, 1)  # ワンホットラベルを平坦化\n",
    "        outputs = outputs.flatten()\n",
    "\n",
    "        # 正解数の合計を更新\n",
    "        preds = torch.round(outputs)  # ラベルを予測\n",
    "        # print(f\"predicts are {preds}, labels {labels_true}\")\n",
    "        epoch_corrects += torch.sum(preds == labels_true)\n",
    "\n",
    "# 正解率\n",
    "epoch_acc = epoch_corrects.double() / len(test_dataloader.dataset)\n",
    "\n",
    "print('テストデータ{}個での正解率：{:.4f}'.format(len(test_dataloader.dataset),epoch_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  0.  0.  0. -0. -0. -0. -1. -1. -1.  1.  1.  1.  1.  1.  0.\n",
      " -0. -1. -0. -1. -1. -1.  1.  1.  1.  0.  0. -0. -1. -0. -1. -1. -1.  1.\n",
      "  1.  1.  0.  0.  0. -0. -0. -0. -1. -1. -1.]\n",
      "[3 3 3 2 2 2 1 1 1 0 0 0 3 3 3 2 2 2 1 1 1 0 0 0 3 3 3 2 2 1 1 1 0 0 0 3 3\n",
      " 3 2 2 2 1 1 1 0 0 0]\n",
      "[[ 0  0  0  0  0]\n",
      " [12  0  0  0  0]\n",
      " [ 2 10  0  0  0]\n",
      " [ 0  9  2  0  0]\n",
      " [ 0  0 12  0  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "preds_heat = np.array(preds)\n",
    "trues_heat = np.array(torch.argmax(labels.data, dim=1))\n",
    "# preds_heat[0] = \"3A\"\n",
    "print(preds_heat)\n",
    "print(trues_heat)\n",
    "\n",
    "heat = confusion_matrix(trues_heat, preds_heat)\n",
    "print(heat)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"   # 使用するフォント\n",
    "plt.rcParams[\"font.size\"] = 20        \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "xtics = [\"2C\", \"2B\", \"2A\", \"3\"]\n",
    "ytics = [\"2C\", \"2B\", \"2A\", \"3\"]\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(heat, annot=True, xticklabels=xtics, yticklabels=ytics, cmap=\"Blues\", cbar=False)\n",
    "# sns.heatmap(heat, annot=True, cmap=\"Blues\", cbar=False)\n",
    "#*以下2行がポイント*  X,Y軸ラベルを追加\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "#グラフをはみ出さないようにして画面に出力\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"nn-heatmap_4.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1234214f0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# サンプルごとに代償動作の度合いをセッティングしてみる\n",
    "preds = np.array(outputs)\n",
    "ans = np.array(labels_true)\n",
    "plt.scatter(preds, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_weight = np.array(attn_weights1[15, 0, 1:]).reshape(1, -1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 1))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(extract_weight, cmap='OrRd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "extract_data = np.array(X[19, 1:, 2]).flatten()\n",
    "print(extract_data.shape)\n",
    "\n",
    "\n",
    "time = np.linspace(0, 100, 100)\n",
    "fig, ax = plt.subplots(2, 1, gridspec_kw={'height_ratios': [6, 1]}, figsize=(15,10))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.lineplot(time, extract_data, ax=ax[0])\n",
    "sns.heatmap(extract_weight, cmap='OrRd', cbar=False, ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data = np.array(attn_weights1[:, 0, :])\n",
    "print(data.shape)\n",
    "data = data.reshape(attn_weights1.shape[0], -1)\n",
    "\n",
    "# print(outputs)\n",
    "print(data.shape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 20))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(data, cmap='OrRd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data[0])):\n",
    "    print(data[0,i], end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_trained.net_Attention_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelの読み込みだけ\n",
    "# 保存したモデルパラメータの読み込み\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net_trained = TransformerClassification().to(device)\n",
    "\n",
    "net_trained.load_state_dict(torch.load('highacc2.pth'))\n",
    "# print('読み込み後のモデル:\\n', model2.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(net_trained.state_dict(), 'highacc3.pth')\n",
    "\n",
    "# 新しいモデル\n",
    "model2 = TransformerClassification().to(device)\n",
    "print('新しいモデル:\\n', model2.state_dict())\n",
    "\n",
    "# 保存したモデルパラメータの読み込み\n",
    "model2.load_state_dict(torch.load('highacc3.pth'))\n",
    "print('読み込み後のモデル:\\n', model2.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention weight の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "print(data)\n",
    "print(data.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 同時に入れるデータも作成する\n",
    "# これは時系列スタンプ．0〜100がサンプル数だけ作られる\n",
    "stamp_row = [i%data.shape[1] for i in range(data.shape[0] * data.shape[1])]\n",
    "\n",
    "# いつ撮影されたのかのスタンプ\n",
    "l_date_name = np.array(df_annotate['date'].unique())\n",
    "date_row = []\n",
    "for item in l_date_name:\n",
    "    for i in range(data.shape[1]):\n",
    "        date_row.append(item)\n",
    "        \n",
    "# アテンションウエイト\n",
    "attn_weight = data.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attn = pd.DataFrame()\n",
    "df_attn['date'] = date_row\n",
    "df_attn[\"stamp\"] = stamp_row\n",
    "df_attn[\"attn_weight\"] = attn_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attn.to_excel('/Users/kento/kuhp/experiment/attention_weights.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_attn['date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "timeseries_transformer_classification.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/keras-team/keras-io/blob/master/examples/timeseries/ipynb/timeseries_classification_transformer.ipynb",
     "timestamp": 1636355482830
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
