{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyRQwYrEYTpv"
   },
   "source": [
    "# 修士論文実験 2022/01/10\n",
    "## マルチモーダルに挑戦\n",
    "## (validationが簡単に行えるようにデータセットを操作するモジュールを拡充)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 843,
     "status": "ok",
     "timestamp": 1636987406075,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "dO5GxI7RzXIc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# sys.path.append(os.path.abspath(\"..\"))\n",
    "# import scripts.compensate\n",
    "# import scripts.kinectImg2video\n",
    "# from scripts.conpemsate_suppresser import *\n",
    "# from scripts.ground_angle_analysis import ground_shoulder_angle_analyzer\n",
    "# import scripts.ground_angle_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日付の追加\n",
    "df_annotate = pd.read_excel(\"annotate_dataset.xlsx\")\n",
    "df_annotate['date'] = pd.to_datetime(df_annotate['date'], format='%Y-%m-%d-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>uid</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>task_id</th>\n",
       "      <th>point</th>\n",
       "      <th>shoulder</th>\n",
       "      <th>body</th>\n",
       "      <th>flag_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-06 18:56:20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-06 18:56:20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-06 18:56:41</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-06 18:56:41</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-06 18:56:58</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  uid  subject_id  task_id point  shoulder  body  \\\n",
       "0 2021-12-06 18:56:20    1           1        1     3         0     0   \n",
       "1 2021-12-06 18:56:20    2           1        1     4         0     0   \n",
       "2 2021-12-06 18:56:41    3           1        1     3         0     0   \n",
       "3 2021-12-06 18:56:41    4           1        1     4         0     0   \n",
       "4 2021-12-06 18:56:58    5           1        1     3         0     0   \n",
       "\n",
       "   flag_usage  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           2  \n",
       "4           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>x_Pelvis</th>\n",
       "      <th>y_Pelvis</th>\n",
       "      <th>z_Pelvis</th>\n",
       "      <th>x_SpineNaval</th>\n",
       "      <th>y_SpineNaval</th>\n",
       "      <th>z_SpineNaval</th>\n",
       "      <th>x_SpineChest</th>\n",
       "      <th>...</th>\n",
       "      <th>x_REar</th>\n",
       "      <th>y_REar</th>\n",
       "      <th>z_REar</th>\n",
       "      <th>N</th>\n",
       "      <th>v_RWrist</th>\n",
       "      <th>z_v_RWrist</th>\n",
       "      <th>flag_active</th>\n",
       "      <th>flag_moving</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-158.973129</td>\n",
       "      <td>353.261841</td>\n",
       "      <td>698.233093</td>\n",
       "      <td>-149.886017</td>\n",
       "      <td>218.100922</td>\n",
       "      <td>780.778748</td>\n",
       "      <td>-142.035919</td>\n",
       "      <td>...</td>\n",
       "      <td>-178.933960</td>\n",
       "      <td>-236.272278</td>\n",
       "      <td>842.268127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.917988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-156.911919</td>\n",
       "      <td>356.031863</td>\n",
       "      <td>697.378637</td>\n",
       "      <td>-147.957493</td>\n",
       "      <td>219.063530</td>\n",
       "      <td>781.238292</td>\n",
       "      <td>-142.348493</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.788628</td>\n",
       "      <td>-241.853940</td>\n",
       "      <td>862.009244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.131710</td>\n",
       "      <td>0.480634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.891892</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-157.406120</td>\n",
       "      <td>356.970863</td>\n",
       "      <td>697.867036</td>\n",
       "      <td>-148.184343</td>\n",
       "      <td>219.214968</td>\n",
       "      <td>781.799317</td>\n",
       "      <td>-142.899719</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.093690</td>\n",
       "      <td>-243.703880</td>\n",
       "      <td>867.831643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.690953</td>\n",
       "      <td>0.198082</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.783784</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-159.493486</td>\n",
       "      <td>356.687710</td>\n",
       "      <td>699.214911</td>\n",
       "      <td>-149.753131</td>\n",
       "      <td>218.849632</td>\n",
       "      <td>782.412353</td>\n",
       "      <td>-143.553739</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.457427</td>\n",
       "      <td>-243.071735</td>\n",
       "      <td>864.096621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.280899</td>\n",
       "      <td>0.313779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.675676</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-162.211771</td>\n",
       "      <td>355.791270</td>\n",
       "      <td>700.938883</td>\n",
       "      <td>-151.850422</td>\n",
       "      <td>218.261918</td>\n",
       "      <td>783.027933</td>\n",
       "      <td>-144.174692</td>\n",
       "      <td>...</td>\n",
       "      <td>-177.488121</td>\n",
       "      <td>-241.207140</td>\n",
       "      <td>855.165480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.247976</td>\n",
       "      <td>0.307322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.567568</td>\n",
       "      <td>2021-12-04 18:20:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1   id    x_Pelvis    y_Pelvis    z_Pelvis  \\\n",
       "0           0             0  1.0 -158.973129  353.261841  698.233093   \n",
       "1           1             1  1.0 -156.911919  356.031863  697.378637   \n",
       "2           2             2  1.0 -157.406120  356.970863  697.867036   \n",
       "3           3             3  1.0 -159.493486  356.687710  699.214911   \n",
       "4           4             4  1.0 -162.211771  355.791270  700.938883   \n",
       "\n",
       "   x_SpineNaval  y_SpineNaval  z_SpineNaval  x_SpineChest  ...      x_REar  \\\n",
       "0   -149.886017    218.100922    780.778748   -142.035919  ... -178.933960   \n",
       "1   -147.957493    219.063530    781.238292   -142.348493  ... -176.788628   \n",
       "2   -148.184343    219.214968    781.799317   -142.899719  ... -176.093690   \n",
       "3   -149.753131    218.849632    782.412353   -143.553739  ... -176.457427   \n",
       "4   -151.850422    218.261918    783.027933   -144.174692  ... -177.488121   \n",
       "\n",
       "       y_REar      z_REar   N  v_RWrist  z_v_RWrist  flag_active  flag_moving  \\\n",
       "0 -236.272278  842.268127 NaN       NaN   -0.917988          0.0          1.0   \n",
       "1 -241.853940  862.009244 NaN  7.131710    0.480634          1.0          1.0   \n",
       "2 -243.703880  867.831643 NaN  5.690953    0.198082          1.0          1.0   \n",
       "3 -243.071735  864.096621 NaN  6.280899    0.313779          1.0          1.0   \n",
       "4 -241.207140  855.165480 NaN  6.247976    0.307322          1.0          1.0   \n",
       "\n",
       "    timestamp                date  \n",
       "0    0.000000 2021-12-04 18:20:18  \n",
       "1   39.891892 2021-12-04 18:20:18  \n",
       "2   79.783784 2021-12-04 18:20:18  \n",
       "3  119.675676 2021-12-04 18:20:18  \n",
       "4  159.567568 2021-12-04 18:20:18  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataSetの呼び出し\n",
    "df_data = pd.read_csv(\"bigdata_trimmed.csv\")\n",
    "df_data['date'] = pd.to_datetime(df_data['date'], format='%Y-%m-%d-%H-%M-%S')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1636987406076,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "GZlVgJy1zXIc"
   },
   "outputs": [],
   "source": [
    "# pd_merged = pd.merge(df_annotate, df_data, on='date', how='inner')\n",
    "# pd_3 = pd_merged[pd_merged['point'] == 3]\n",
    "# pd_2A = pd_merged[pd_merged['point'] == '2A']\n",
    "# pd_2B = pd_merged[pd_merged['point'] == '2B']\n",
    "# pd_2C = pd_merged[pd_merged['point'] == '2C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### このデータセットはGraspのものかつ，usageが1のものが取り出されている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# データセットにNN入力用のスコアを割り振る．\n",
    "# これが正解ラベルになる\n",
    "dataset = pd.merge(df_annotate, df_data, on='date', how='inner')\n",
    "\n",
    "dataset = dataset[(dataset['task_id'] == 1) & (dataset['flag_usage'] == 1)]\n",
    "dataset['point'] = dataset['point'].astype(str)\n",
    "dataset.loc[dataset['point'] == '3', 'score'] = 3\n",
    "dataset.loc[dataset['point'] == '2A', 'score'] = 2\n",
    "dataset.loc[dataset['point'] == '2B', 'score'] = 1\n",
    "dataset.loc[dataset['point'] == '2C', 'score'] = 0\n",
    "print(dataset['score'].max())\n",
    "\n",
    "# Nanのものを削除\n",
    "dataset.dropna(subset=['score'], inplace=True)\n",
    "# scoreの行をintにする\n",
    "dataset['score'] = dataset['score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['uid'].unique()\n",
    "dataset['date'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grasp動作だけを抜き出す\n",
    "# dataset_grasp = dataset[dataset['task_id'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RElbow2RWrist と Rshoulder2RElbow と Pelvis2RShoulder と Pelvis2Neck の速度を入れてみる "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_annotate\n",
    "# l_date = df_annotate['date'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vector(df, joint1, joint2, word=\"\"):\n",
    "    df[f\"{word}_x_{joint1}2{joint2}\"] = df[f\"x_{joint1}\"].astype('float64') - df[f\"x_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_y_{joint1}2{joint2}\"] = df[f\"y_{joint1}\"].astype('float64') - df[f\"y_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_z_{joint1}2{joint2}\"] = df[f\"z_{joint1}\"].astype('float64') - df[f\"z_{joint2}\"].astype('float64')\n",
    "    df[f\"{word}_ave_{joint1}2{joint2}\"] = (df[f\"{word}_x_{joint1}2{joint2}\"] + df[f\"{word}_y_{joint1}2{joint2}\"] + df[f\"{word}_z_{joint1}2{joint2}\"])/3\n",
    "    return df\n",
    "\n",
    "def calc_angle(df, joint1, joint2, joint3):\n",
    "    l_theta = []\n",
    "    # 角度を算出する関数。p2を支点として、他の二点間の角度を算出する。\n",
    "    x1, y1 ,z1= df[f\"x_{joint1}\"].astype('float64'), df[f\"y_{joint1}\"].astype('float64'), df[f\"z_{joint1}\"].astype('float64')\n",
    "    x2, y2 ,z2= df[f\"x_{joint2}\"].astype('float64'), df[f\"y_{joint2}\"].astype('float64'), df[f\"z_{joint2}\"].astype('float64')\n",
    "    x3, y3 ,z3= df[f\"x_{joint3}\"].astype('float64'), df[f\"y_{joint3}\"].astype('float64'), df[f\"z_{joint3}\"].astype('float64')\n",
    "    v1 = np.array([x1-x2, y1-y2, z1-z2])\n",
    "    v2 = np.array([x3-x2, y3-y2, z3-z2])\n",
    "    for i in range(v1.shape[1]):\n",
    "        cos = np.dot(v1[:,i], v2[:,i])/(np.linalg.norm(v1[:,i], ord=2) * np.linalg.norm(v2[:,i], ord=2))\n",
    "        theta = np.degrees(math.acos(cos))\n",
    "        l_theta.append(theta)\n",
    "    return np.array(l_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 角度と角度の速度を入力とする\n",
    "angle_RElbow = calc_angle(dataset, 'RShoulder', 'RElbow', 'RWrist')\n",
    "diff_angle_RElbow = np.diff(angle_RElbow)\n",
    "\n",
    "angle_RShoulder = calc_angle(dataset, 'RElbow', 'RShoulder', 'Neck')\n",
    "diff_angle_RShoulder = np.diff(angle_RShoulder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_date_name = np.array(dataset['date'].unique())\n",
    "# l = []\n",
    "# for date in l_date_name:\n",
    "#     score = dataset[dataset[\"date\"] == date]['score'].mode()\n",
    "#     l.append(score)\n",
    "# return np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解ラベルで用いるyのone hotベクトルを作成\n",
    "def extract_y(df, augment_flag=False, rate_augment=10):\n",
    "    l = []\n",
    "    l_date_name = np.array(df['date'].unique())\n",
    "    for date in l_date_name:\n",
    "        score = df[df[\"date\"] == date]['score'].mode()\n",
    "        l.append(score)\n",
    "        if augment_flag:\n",
    "            for i in range(rate_augment):\n",
    "                l.append(score)\n",
    "    y = np.array(l).flatten()\n",
    "    \n",
    "    # l_date_name = np.array(df['date'].unique())\n",
    "    # y = np.array(df[\"score\"]) #一番多いものをscoreとして最後にyとして返す\n",
    "    # y_arr = np.ones(l_date_name.shape)\n",
    "    # y_arr = y_arr * y\n",
    "    return y\n",
    "\n",
    "def interpolate1(array, length=100):\n",
    "    x_old = np.linspace(0, 1, array.shape[0])\n",
    "    y_old = array\n",
    "    \n",
    "    f = interpolate.interp1d(x_old, y_old)\n",
    "\n",
    "    x = np.linspace(0, 1, length)\n",
    "    y_new = f(x)\n",
    "    return y_new\n",
    "\n",
    "def zscore(x, axis = 1):\n",
    "    xmean = x.mean(axis=axis, keepdims=True)\n",
    "    xstd  = np.std(x, axis=axis, keepdims=True)\n",
    "    zscore = (x-xmean)/xstd\n",
    "    return zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xの系列を入力とすると，rateのものを10倍作成して返す\n",
    "def augmentation(arr_data, rate=0.8, num_arr=10, origin_length=100):\n",
    "    #まず100個に補間 shape:(100, num_feature)\n",
    "    interpolate = interpolate_one_sample(arr_data)\n",
    "    interpolate = interpolate.reshape(interpolate.shape[1], -1)\n",
    "    \n",
    "    num_data = origin_length * rate #実際に用いるデータ点列\n",
    "    \n",
    "    for i in range(num_arr):\n",
    "        first_idx = round( i/num_arr * origin_length * (1-rate))\n",
    "        end_idx = round( i/num_arr * origin_length * (1-rate) + origin_length * rate )\n",
    "        # print(f\"first index is {first_idx}, end index is {end_idx}\")\n",
    "        one_trimmed = interpolate[first_idx:end_idx, :]\n",
    "        one_arr = interpolate_one_sample(one_trimmed)\n",
    "        if i == 0:\n",
    "                x = one_arr #(1, 100, num_feature)\n",
    "        else:\n",
    "            x = np.concatenate([x, one_arr],0)\n",
    "    return x # (num_arr, 100, num_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_one_sample(arr_data):\n",
    "    num_feature = arr_data.shape[1]\n",
    "    for i in range(num_feature):\n",
    "            tmp_interpolate = interpolate1(arr_data[:, i])\n",
    "            #3次元に拡張\n",
    "            origin = tmp_interpolate.reshape(1, tmp_interpolate.shape[0], 1)\n",
    "            \n",
    "            if i == 0:\n",
    "                x = origin\n",
    "            else:\n",
    "                # print(f\"x shape is {x.shape}, \")\n",
    "                x = np.concatenate([x, origin],2)\n",
    "    return x #(1, 100, num_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# この関数を実行しさえすればデータセットが作成される\n",
    "def create_Xy(dataset, augment_flag=False, rate_augment=5, rate=0.9):\n",
    "    #正解ラベルの作成\n",
    "    y = extract_y(dataset, augment_flag, rate_augment=rate_augment)\n",
    "    \n",
    "    # Xの作成\n",
    "    l_date_name = np.array(dataset['date'].unique())\n",
    "    for k, date in enumerate(l_date_name):\n",
    "        #一連のデータ，1サンプル\n",
    "        series = dataset[dataset['date'] == l_date_name[k]]\n",
    "        series.drop(columns='point', inplace=True)\n",
    "        series.drop(columns='date', inplace=True)\n",
    "        #差分ベクトルを取得\n",
    "        diff = series.diff()\n",
    "        diff.fillna(0, inplace=True)\n",
    "\n",
    "        # 間接点同士のベクトルのカラムをデータフレームに追加\n",
    "        # これらがデータセットになる\n",
    "        diff = add_vector(diff, 'RElbow', \"RWrist\", 'v')\n",
    "        diff = add_vector(diff, 'RShoulder', \"RElbow\", 'v')\n",
    "        diff = add_vector(diff, 'Pelvis', \"RShoulder\", 'v')\n",
    "        diff = add_vector(diff, 'Pelvis', \"Neck\", 'v')\n",
    "        diff = add_vector(diff, 'Neck', 'RShoulder', 'v')\n",
    "        diff = add_vector(diff, 'Neck', 'LShoulder', 'v')\n",
    "        \n",
    "#         diff['x_angle_RElbow'] = angle_RElbow\n",
    "#         diff['x2_angle_RElbow'] = angle_RElbow\n",
    "#         diff['x_diff_angle_RElbow'] = diff_angle_RElbow\n",
    "#         diff['diff_angle_RElbow2'] = diff_angle_RElbow\n",
    "        \n",
    "#         diff['angle_RShoulder'] = angle_RShoulder\n",
    "#         diff['angle_RShoulder2'] = angle_RShoulder\n",
    "#         diff['diff_angle_RShoulder'] = diff_angle_RShoulder\n",
    "#         diff['diff_angle_RShoulder2'] = diff_angle_RShoulder\n",
    "        \n",
    "        # arr_data = diff.loc[:, columns].values\n",
    "        \n",
    "        # 1サンプルに関するデータ shape = (num_timestep, num_feature)\n",
    "        arr_data = diff.loc[:, \"v_x_RElbow2RWrist\":].values\n",
    "        \n",
    "        # 補間を行う\n",
    "        # 1つの特徴量に関する動作(1, 100, 1)\n",
    "        # ここから出てくる x shape (1, 100, num_feature)\n",
    "        \n",
    "        origin = interpolate_one_sample(arr_data)\n",
    "        \n",
    "#         for i in range(num_feature):\n",
    "#             tmp_interpolate = interpolate1(arr_data[:, i])\n",
    "#             #3次元に拡張\n",
    "#             origin = tmp_interpolate.reshape(1, tmp_interpolate.shape[0], 1)\n",
    "            \n",
    "#             if i == 0:\n",
    "#                 x = origin\n",
    "#             else:\n",
    "#                 print(f\"x shape is {x.shape}, \")\n",
    "#                 x = np.concatenate([x, origin],2)\n",
    "                \n",
    "        # augmentで増やす\n",
    "        # この関数の出力 (augmented_num, 100, num_feature)\n",
    "        if augment_flag:\n",
    "            augmented_arr = augmentation(arr_data, rate=rate, num_arr=rate_augment)\n",
    "            augmented_origin_arr = np.concatenate([origin, augmented_arr], 0)\n",
    "        else:\n",
    "            augmented_origin_arr = origin\n",
    "        \n",
    "        # サンプル数の次元を拡張する\n",
    "        # x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "        \n",
    "        #最初だけ条件分岐\n",
    "        if k == 0:\n",
    "            X = augmented_origin_arr\n",
    "        else:\n",
    "            X = np.concatenate([X, augmented_origin_arr], axis=0)\n",
    "        \n",
    "       # 最後にzscore変換\n",
    "        X = zscore(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxW659H6YTpz"
   },
   "source": [
    "## Build the model\n",
    "\n",
    "Our model processes a tensor of shape `(batch size, sequence length, features)`,\n",
    "where `sequence length` is the number of time steps and `features` is each input\n",
    "timeseries.\n",
    "\n",
    "You can replace your classification RNN layers with this one: the\n",
    "inputs are fully compatible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urNK4ym-YTp0"
   },
   "source": [
    "We include residual connections, layer normalization, and dropout.\n",
    "The resulting layer can be stacked multiple times.\n",
    "\n",
    "The projection layers are implemented through `keras.layers.Conv1D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    '''入力された単語の位置を示すベクトル情報を付加する'''\n",
    "\n",
    "    def __init__(self, d_model=12, max_seq_len=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model  # 単語ベクトルの次元数\n",
    "\n",
    "        # 単語の順番（pos）と埋め込みベクトルの次元の位置（i）によって一意に定まる値の表をpeとして作成\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "\n",
    "        # GPUが使える場合はGPUへ送る、ここでは省略。実際に学習時には使用する\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        pe = pe.to(device)\n",
    "\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                \n",
    "                # 誤植修正_200510 #79\n",
    "                # pe[pos, i + 1] = math.cos(pos /\n",
    "                #                          (10000 ** ((2 * (i + 1))/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos /\n",
    "                                          (10000 ** ((2 * i)/d_model)))\n",
    "\n",
    "        # 表peの先頭に、ミニバッチ次元となる次元を足す\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "        # 勾配を計算しないようにする\n",
    "        self.pe.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 入力xとPositonal Encodingを足し算する\n",
    "        # xがpeよりも小さいので、大きくする\n",
    "        ret = math.sqrt(self.d_model)*x + self.pe\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # SAGANでは1dConvを使用したが、今回は全結合層で特徴量を変換する\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # 出力時に使用する全結合層\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Attentionの大きさ調整の変数\n",
    "        self.d_k = d_model\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        # 全結合層で特徴量を変換\n",
    "        k = self.k_linear(k)\n",
    "        q = self.q_linear(q)\n",
    "        v = self.v_linear(v)\n",
    "\n",
    "        # Attentionの値を計算する\n",
    "        # 各値を足し算すると大きくなりすぎるので、root(d_k)で割って調整\n",
    "        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)\n",
    "\n",
    "        # ここでmaskを計算\n",
    "        # mask = mask.unsqueeze(1)\n",
    "        # print(mask)\n",
    "        # weights = weights.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # softmaxで規格化をする\n",
    "        normlized_weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "        # AttentionをValueとかけ算\n",
    "        output = torch.matmul(normlized_weights, v)\n",
    "\n",
    "        # 全結合層で特徴量を変換\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, normlized_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
    "        '''Attention層から出力を単純に全結合層2つで特徴量を変換するだけのユニットです'''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.dropout(F.relu(x))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # LayerNormalization層\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=layernorm\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Attention層\n",
    "        self.attn = Attention(d_model)\n",
    "\n",
    "        # Attentionのあとの全結合層2つ\n",
    "        self.ff = FeedForward(d_model)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # 正規化とAttention\n",
    "        # print(f\"input shape is {x.shape}\")\n",
    "        x_normlized = self.norm_1(x)\n",
    "        output, attn_weights = self.attn(x_normlized, x_normlized, x_normlized, mask)\n",
    "        \n",
    "        x2 = x + self.dropout_1(output)\n",
    "\n",
    "        # 正規化と全結合層\n",
    "        x_normlized2 = self.norm_2(x2)\n",
    "        output = x2 + self.dropout_2(self.ff(x_normlized2))\n",
    "        # print(f\"output shape is {output.shape}\")\n",
    "\n",
    "        return output, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringHead(nn.Module):\n",
    "    '''Transformer_Blockの出力を使用して，最後にスコアリングを行う'''\n",
    "    \n",
    "    def __init__(self, d_model=300, output_dim=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # 全結合層\n",
    "        self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # 重み初期化処理\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n",
    "        weights = self.linear.weight\n",
    "        out = self.linear(x0)\n",
    "        \n",
    "        # print(f\"Scoring input shape is {x0.shape}\")\n",
    "        # print(f\"Scoring weight shape is {weights.shape}\")\n",
    "        # print(f\"Scoring output shape is {out.shape}\")\n",
    "\n",
    "        return out, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ClassificationHead(nn.Module):\n",
    "#     '''Transformer_Blockの出力を使用し、最後にクラス分類させる'''\n",
    "\n",
    "#     def __init__(self, d_model=300, output_dim=4):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # 全結合層\n",
    "#         self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n",
    "#         self.output_dim = output_dim\n",
    "\n",
    "#         # 重み初期化処理\n",
    "#         nn.init.normal_(self.linear.weight, std=0.02)\n",
    "#         nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n",
    "#         x1 = self.linear(x0)\n",
    "#         # print(x1.shape)\n",
    "#         out = F.softmax(x1, dim=-1)\n",
    "\n",
    "#         return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここで複数入力のAttentionにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 最終的なTransformerモデルのクラス\n",
    "\n",
    "# class TransformerClassification(nn.Module):\n",
    "#     '''Transformerでクラス分類させる'''\n",
    "\n",
    "#     def __init__(self, d_model=12, max_seq_len=101, output_dim=4):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # モデル構築\n",
    "#         self.net_Positional = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
    "        \n",
    "#         self.net_Attention_1 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_2 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_3 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_4 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_5 = TransformerBlock(d_model=4)\n",
    "#         self.net_Attention_6 = TransformerBlock(d_model=4)\n",
    "        \n",
    "#         self.net_Attention_all = TransformerBlock(d_model=24)\n",
    "#         # self.net3_2 = TransformerBlock(d_model=d_model)\n",
    "        \n",
    "#         self.net_Classification = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
    "\n",
    "#     def forward(self, x, mask):\n",
    "#         x = self.net_Positional(x)  # Positon情報を足し算\n",
    "#         #ここでいくつのAttentionアーキテクチャを利用するか決定する\n",
    "#         # num_attention_block = x.shape[2]/4\n",
    "        \n",
    "#         x1, attn_weights_1 = self.net_Attention_1(x[:,:,0:4], mask[:,:,0:4])  # Self-Attentionで特徴量を変換\n",
    "#         x2, attn_weights_2 = self.net_Attention_2(x[:,:,4:8], mask[:,:,4:8])\n",
    "#         x3, attn_weights_3 = self.net_Attention_3(x[:,:,8:12], mask[:,:,8:12])\n",
    "#         x4, attn_weights_4 = self.net_Attention_4(x[:,:,12:16], mask[:,:,12:16])\n",
    "#         x5, attn_weights_5 = self.net_Attention_5(x[:,:,16:20], mask[:,:,16:20])\n",
    "#         x6, attn_weights_6 = self.net_Attention_6(x[:,:,20:24], mask[:,:,20:24])\n",
    "        \n",
    "#         #出力を全部つなぎ合わせる\n",
    "#         x_concat = torch.cat((x1,x2,x3,x4,x5,x6), 2)\n",
    "#         # x_attn, attn_weights_all = self.net_Attention_all(x_concat, mask)\n",
    "        \n",
    "#         x_out = self.net_Classification(x_concat)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
    "        \n",
    "#         l_attn_weights = [attn_weights_1,attn_weights_2,attn_weights_3,attn_weights_4,attn_weights_5,attn_weights_6\n",
    "#                           # , attn_weights_all\n",
    "#                          ] \n",
    "#         return x_out, l_attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的なTransformerモデルのクラス\n",
    "\n",
    "class TransformerScoring(nn.Module):\n",
    "    '''Transformerでクラス分類させる'''\n",
    "\n",
    "    def __init__(self, d_model=12, max_seq_len=101, output_dim=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # モデル構築\n",
    "        self.net_Positional = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
    "        \n",
    "        self.net_Attention_1 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_2 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_3 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_4 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_5 = TransformerBlock(d_model=4)\n",
    "        self.net_Attention_6 = TransformerBlock(d_model=4)\n",
    "        \n",
    "        self.net_Attention_all = TransformerBlock(d_model=24)\n",
    "        # self.net3_2 = TransformerBlock(d_model=d_model)\n",
    "        \n",
    "        # self.net_Classification = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
    "        self.net_Scoring = ScoringHead(output_dim=output_dim, d_model=d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.net_Positional(x)  # Positon情報を足し算\n",
    "        #ここでいくつのAttentionアーキテクチャを利用するか決定する\n",
    "        # num_attention_block = x.shape[2]/4\n",
    "        \n",
    "        x1, attn_weights_1 = self.net_Attention_1(x[:,:,0:4], mask[:,:,0:4])  # Self-Attentionで特徴量を変換\n",
    "        x2, attn_weights_2 = self.net_Attention_2(x[:,:,4:8], mask[:,:,4:8])\n",
    "        x3, attn_weights_3 = self.net_Attention_3(x[:,:,8:12], mask[:,:,8:12])\n",
    "        x4, attn_weights_4 = self.net_Attention_4(x[:,:,12:16], mask[:,:,12:16])\n",
    "        x5, attn_weights_5 = self.net_Attention_5(x[:,:,16:20], mask[:,:,16:20])\n",
    "        x6, attn_weights_6 = self.net_Attention_6(x[:,:,20:24], mask[:,:,20:24])\n",
    "        \n",
    "        #出力を全部つなぎ合わせる\n",
    "        x_concat = torch.cat((x1,x2,x3,x4,x5,x6), 2)\n",
    "        # x_attn, attn_weights_all = self.net_Attention_all(x_concat, mask)\n",
    "        \n",
    "        x_out, _ = self.net_Scoring(x_concat)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
    "        \n",
    "        l_attn_weights = [attn_weights_1,attn_weights_2,attn_weights_3,attn_weights_4,attn_weights_5,attn_weights_6\n",
    "                          # , attn_weights_all\n",
    "                         ] \n",
    "        return x_out, l_attn_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# validation用に1人のデータを検証データに回す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset\n",
    "# [~(dataset['subject_id'] == 4)]\n",
    "val_df = dataset[dataset['subject_id'] == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PyTorchのdatasetの作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suzuk\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = create_Xy(train_df, augment_flag=True, rate_augment=5, rate=0.9)\n",
    "x_test, y_test = create_Xy(val_df, augment_flag=True, rate_augment=5, rate=0.9)\n",
    "\n",
    "# y_train = y_train.astype('int64')\n",
    "# y_test = y_test.astype('int64')\n",
    "\n",
    "\n",
    "# 正解データをone hotベクトルに変換\n",
    "n_classes = len(np.unique(y_train))\n",
    "y_train_onehot = np.identity(n_classes)[y_train]\n",
    "y_test_onehot = np.identity(n_classes)[y_test]\n",
    "\n",
    "\n",
    "### 先頭にclassification用のトークンを追加する\n",
    "score_train = np.zeros((x_train.shape[0], 1 , x_train.shape[2]))\n",
    "x_train = np.concatenate([score_train, x_train], axis=1)\n",
    "\n",
    "score_test = np.zeros((x_test.shape[0], 1 , x_test.shape[2]))\n",
    "x_test = np.concatenate([score_test, x_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(282, 101, 24)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 先頭にclassification用のトークンを追加する\n",
    "# score_train = np.zeros((x_train.shape[0], 1 , x_train.shape[2]))\n",
    "# x_train = np.concatenate([score_train, x_train], axis=1)\n",
    "\n",
    "# score_test = np.zeros((x_test.shape[0], 1 , x_test.shape[2]))\n",
    "# x_test = np.concatenate([score_test, x_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1636987650297,
     "user": {
      "displayName": "Kento Suzuki",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16345288529127918743"
     },
     "user_tz": -540
    },
    "id": "8vf0x--aaZjE",
    "outputId": "57c2d515-00a5-443a-b22e-6fa77d359e84"
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(x_train, dtype=torch.float32)\n",
    "                                               , torch.tensor(y_train_onehot, dtype=torch.int8))\n",
    "val_dataset = torch.utils.data.TensorDataset(torch.tensor(x_test, dtype=torch.float32),\n",
    "                                             torch.tensor(y_test_onehot, dtype=torch.int8))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LakZIHM8YTp1"
   },
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力のテンソルサイズ： torch.Size([8, 1])\n",
      "出力テンソル tensor([[0.5447],\n",
      "        [0.5341],\n",
      "        [0.5265],\n",
      "        [0.5296],\n",
      "        [0.5316],\n",
      "        [0.5464],\n",
      "        [0.5441],\n",
      "        [0.5530]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 動作確認\n",
    "# ミニバッチの用意\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "# モデル構築\n",
    "\n",
    "# 変数の固定\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "\n",
    "net = TransformerScoring(\n",
    "    d_model=24, max_seq_len=101, output_dim=1)\n",
    "\n",
    "# 入出力\n",
    "_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(_device)\n",
    "x = batch[0].to(_device)\n",
    "input_pad = 1\n",
    "input_mask = (x != input_pad)\n",
    "out, l_weights = net(x, input_mask)\n",
    "\n",
    "print(\"出力のテンソルサイズ：\", out.shape)\n",
    "print(\"出力テンソル\", out)\n",
    "# print(\"出力テンソルのsigmoid：\", F.softmax(out, dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elTTH_9KYTp0"
   },
   "source": [
    "The main part of our model is now complete. We can stack multiple of those\n",
    "`transformer_encoder` blocks and we can also proceed to add the final\n",
    "Multi-Layer Perceptron classification head. Apart from a stack of `Dense`\n",
    "layers, we need to reduce the output tensor of the `TransformerEncoder` part of\n",
    "our model down to a vector of features for each data point in the current\n",
    "batch. A common way to achieve this is to use a pooling layer. For\n",
    "this example, a `GlobalAveragePooling1D` layer is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ネットワークの初期化を定義\n",
    "\n",
    "# def weights_init(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     if classname.find('Linear') != -1:\n",
    "#         # Liner層の初期化\n",
    "#         nn.init.kaiming_normal_(m.weight)\n",
    "#         if m.bias is not None:\n",
    "#             nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "# # 訓練モードに設定\n",
    "# net.train()\n",
    "\n",
    "# # TransformerBlockモジュールを初期化実行\n",
    "\n",
    "# net.net_Attention_1.apply(weights_init)\n",
    "\n",
    "\n",
    "\n",
    "# print('ネットワーク設定完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の設定\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "# nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n",
    "\n",
    "# 最適化手法の設定\n",
    "learning_rate = 3e-4\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs, patience):\n",
    "    # Early Stopping を定義\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "    print('-----start-------')\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # epochのループ\n",
    "    flag = False\n",
    "    for epoch in range(num_epochs):\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "        # for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和\n",
    "            epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "            # データローダーからミニバッチを取り出すループ\n",
    "            for batch in (dataloaders_dict[phase]):\n",
    "                # batchはTextとLableの辞書オブジェクト\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                inputs = batch[0].to(device)  # 文章\n",
    "                labels = batch[1].to(device)  # ラベル\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    # mask作成\n",
    "                    input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "                    input_mask = (inputs != input_pad)\n",
    "\n",
    "                    # Transformerに入力\n",
    "                    outputs, _ = net(inputs, input_mask)\n",
    "                    _, labels_true = torch.max(labels.data, 1)  # ワンホットラベルを平坦化\n",
    "                    labels_true_float = labels_true / 3\n",
    "                    # print(type(labels_true_float.dtype))\n",
    "                    # print(f\"outputs shape is {outputs.flatten().shape}, label shape is {labels_true.shape}\")\n",
    "                    outputs = outputs.flatten()\n",
    "                    loss = criterion(outputs, labels_true_float)  # 損失を計算\n",
    "                    # print(f\"output is {outputs}, labels float are {labels_true_float}\")\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # 結果の計算\n",
    "                    # print(np.array(preds))\n",
    "                    # print(np.array(np.argmax(labels.data)))\n",
    "                    # print(preds == labels.data)\n",
    "                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n",
    "                    # 正解数の合計を更新\n",
    "                    \n",
    "                    # one_hot=F.one_hot(preds,num_classes=4)\n",
    "                    # epoch_corrects += torch.sum(preds == labels_true)\n",
    "                    # print(labels_true)\n",
    "                    # print(torch.flatten(preds))\n",
    "                    preds = torch.round(outputs * 3)  # ラベルを予測\n",
    "                    # print(f\"predicts are {preds}, labels {labels_true}\")\n",
    "                    # print(preds == labels_true)\n",
    "                    epoch_corrects += torch.sum(preds == labels_true)\n",
    "\n",
    "            # epochごとのlossと正解率\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
    "                                                                           phase, epoch_loss, epoch_acc))\n",
    "                # print(f\"epoch corrects {epoch_corrects.double()}\")\n",
    "                # print(f\"dataset size = {len(dataloaders_dict[phase].dataset)}\")\n",
    "                \n",
    "            if phase == 'train':\n",
    "                writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "\n",
    "            else:\n",
    "                writer.add_scalar(\"Loss/test\", loss, epoch)\n",
    "                early_stopping(loss, net) # 最良モデルならモデルパラメータ保存\n",
    "                if early_stopping.early_stop: \n",
    "                # 一定epochだけval_lossが最低値を更新しなかった場合、ここに入り学習を終了\n",
    "                    print(f\"Early Stopping  !! Epoch {epoch+1}/{num_epochs} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "                    flag = True\n",
    "        if flag:\n",
    "            break\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 159,
=======
   "execution_count": 46,
>>>>>>> mac_dev
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "seed is 1000\n",
      "learning_rate is 0.001\n",
      "使用デバイス： cpu\n",
      "-----start-------\n",
      "Epoch 1/1000 | train |  Loss: 0.7224 Acc: 0.1896\n",
      "Epoch 1/1000 |  val  |  Loss: 0.1822 Acc: 0.2727\n",
      "Epoch 101/1000 | train |  Loss: 0.0399 Acc: 0.6190\n",
      "Epoch 101/1000 |  val  |  Loss: 0.0212 Acc: 0.8017\n",
      "Early Stopping  !! Epoch 108/1000 Loss: 0.0358 Acc: 0.6364\n",
      "539.5814988613129\n",
      "---------------------------------------------------------------------------------\n",
      "seed is 1001\n",
      "learning_rate is 0.001\n",
      "使用デバイス： cpu\n",
      "-----start-------\n",
<<<<<<< HEAD
      "Epoch 1/1000 | train |  Loss: 0.2625 Acc: 0.1315\n",
      "Epoch 1/1000 |  val  |  Loss: 0.1485 Acc: 0.2727\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yt/fsd0dzhn23z2jcmc2hrkjcn00000gn/T/ipykernel_19020/4039244511.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         net_trained = train_model(net, \n\u001b[0m\u001b[1;32m     32\u001b[0m                                   \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                                   \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yt/fsd0dzhn23z2jcmc2hrkjcn00000gn/T/ipykernel_19020/2511580203.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, dataloaders_dict, criterion, optimizer, num_epochs, patience)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;31m# Transformerに入力\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ワンホットラベルを平坦化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0mlabels_true_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_true\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yt/fsd0dzhn23z2jcmc2hrkjcn00000gn/T/ipykernel_19020/49609649.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_Attention_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_Attention_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mx6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights_6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_Attention_6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#出力を全部つなぎ合わせる\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yt/fsd0dzhn23z2jcmc2hrkjcn00000gn/T/ipykernel_19020/1696604676.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# 正規化と全結合層\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx_normlized2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_normlized2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;31m# print(f\"output shape is {output.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yt/fsd0dzhn23z2jcmc2hrkjcn00000gn/T/ipykernel_19020/1980019944.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
=======
      "Epoch 1/300 | train |  Loss: 1.3921 Acc: 0.0000\n",
      "Epoch 1/300 |  val  |  Loss: 0.5042 Acc: 0.2500\n",
      "Validation loss decreased (inf --> 0.054857).  Saving model ...\n",
      "Validation loss decreased (0.054857 --> 0.037139).  Saving model ...\n",
      "Validation loss decreased (0.037139 --> 0.033801).  Saving model ...\n",
      "Validation loss decreased (0.033801 --> 0.031907).  Saving model ...\n",
      "Validation loss decreased (0.031907 --> 0.023830).  Saving model ...\n",
      "Validation loss decreased (0.023830 --> 0.023391).  Saving model ...\n",
      "Validation loss decreased (0.023391 --> 0.020321).  Saving model ...\n",
      "Validation loss decreased (0.020321 --> 0.018809).  Saving model ...\n",
      "Validation loss decreased (0.018809 --> 0.017212).  Saving model ...\n",
      "Validation loss decreased (0.017212 --> 0.016194).  Saving model ...\n",
      "Epoch 101/300 | train |  Loss: 0.0372 Acc: 0.6809\n",
      "Epoch 101/300 |  val  |  Loss: 0.0306 Acc: 0.5833\n",
      "Validation loss decreased (0.016194 --> 0.015929).  Saving model ...\n",
      "Validation loss decreased (0.015929 --> 0.015658).  Saving model ...\n",
      "Validation loss decreased (0.015658 --> 0.015443).  Saving model ...\n",
      "Validation loss decreased (0.015443 --> 0.014786).  Saving model ...\n",
      "Validation loss decreased (0.014786 --> 0.013854).  Saving model ...\n",
      "Validation loss decreased (0.013854 --> 0.013653).  Saving model ...\n",
      "Validation loss decreased (0.013653 --> 0.012955).  Saving model ...\n",
      "Validation loss decreased (0.012955 --> 0.012033).  Saving model ...\n",
      "Validation loss decreased (0.012033 --> 0.010536).  Saving model ...\n",
      "Validation loss decreased (0.010536 --> 0.009873).  Saving model ...\n",
      "Validation loss decreased (0.009873 --> 0.007918).  Saving model ...\n",
      "Epoch 201/300 | train |  Loss: 0.0179 Acc: 0.8298\n",
      "Epoch 201/300 |  val  |  Loss: 0.0197 Acc: 0.8333\n",
      "Validation loss decreased (0.007918 --> 0.006977).  Saving model ...\n",
      "Validation loss decreased (0.006977 --> 0.006926).  Saving model ...\n",
      "Validation loss decreased (0.006926 --> 0.006453).  Saving model ...\n",
      "Validation loss decreased (0.006453 --> 0.005054).  Saving model ...\n",
      "Validation loss decreased (0.005054 --> 0.004712).  Saving model ...\n",
      "Validation loss decreased (0.004712 --> 0.003984).  Saving model ...\n",
      "Validation loss decreased (0.003984 --> 0.003718).  Saving model ...\n",
      "Validation loss decreased (0.003718 --> 0.003411).  Saving model ...\n",
      "Validation loss decreased (0.003411 --> 0.003373).  Saving model ...\n",
      "Validation loss decreased (0.003373 --> 0.003308).  Saving model ...\n",
      "129.62972211837769\n"
>>>>>>> mac_dev
     ]
    }
   ],
   "source": [
    "import time\n",
    "# グリッドサーチを行う．\n",
    "l_rate = [1e-3]\n",
    "# l_rate = [1e-3]\n",
    "num_epochs = 1000\n",
    "patience = 100\n",
    "\n",
    "seeds = []\n",
    "for i in range(1):\n",
    "    seeds.append(1000+i)\n",
    "\n",
    "for seed in seeds:\n",
    "    print(\"---------------------------------------------------------------------------------\")\n",
    "    print(f\"seed is {seed}\")\n",
    "    for learning_rate in l_rate:\n",
    "        writer = SummaryWriter()\n",
    "        print(f\"learning_rate is {learning_rate}\")\n",
    "\n",
    "        # 変数の固定\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # モデル構築\n",
    "        net = TransformerScoring(d_model=24, max_seq_len=101, output_dim=1)\n",
    "        # 訓練モードに設定\n",
    "        net.train()\n",
    "\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "        start = time.time()\n",
    "        net_trained = train_model(net, \n",
    "                                  dataloaders_dict,\n",
    "                                  criterion,\n",
    "                                  optimizer,\n",
    "                                  num_epochs,\n",
    "                                  patience\n",
    "                                 )\n",
    "        print(time.time() - start)\n",
    "        writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 学習・検証を実行する 15分ほどかかります\n",
    "# net = TransformerClassification(d_model=24, max_seq_len=101, output_dim=4)\n",
    "# # 訓練モードに設定\n",
    "# net.train()\n",
    "\n",
    "# # 損失関数の設定\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# # nn.LogSoftmax()を計算してからnn.NLLLoss(negative log likelihood loss)を計算\n",
    "\n",
    "# # 最適化手法の設定\n",
    "# learning_rate = 2e-4\n",
    "# optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# print('ネットワーク設定完了')\n",
    "\n",
    "# num_epochs = 300\n",
    "# net_trained = train_model(net, dataloaders_dict,\n",
    "#                           criterion, optimizer, num_epochs=num_epochs)\n",
    "# writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN2SeFtLHbyT"
   },
   "source": [
    "# SaveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テストデータ11個での正解率：0.7273\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 新しいモデル\n",
    "net_trained.eval()\n",
    "net_trained.to(device)\n",
    "\n",
    "epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=60)\n",
    "# test_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=60)\n",
    "\n",
    "for batch in (test_dataloader):  # testデータのDataLoader\n",
    "    # batchはTextとLableの辞書オブジェクト\n",
    "    \n",
    "    # GPUが使えるならGPUにデータを送る\n",
    "    inputs = batch[0].to(device)  # 文章\n",
    "    labels = batch[1].to(device)  # ラベル\n",
    "\n",
    "    # 順伝搬（forward）計算\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        # mask作成\n",
    "        input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
    "        input_mask = (inputs != input_pad)\n",
    "\n",
    "        # Transformerに入力\n",
    "        outputs, _ = net_trained(inputs, input_mask)\n",
    "        _, labels_true = torch.max(labels.data, 1)  # ワンホットラベルを平坦化\n",
    "        outputs = outputs.flatten()\n",
    "\n",
    "        # 正解数の合計を更新\n",
    "        preds = torch.round(outputs*3)  # ラベルを予測\n",
    "        # print(f\"predicts are {preds}, labels {labels_true}\")\n",
    "        epoch_corrects += torch.sum(preds == labels_true)\n",
    "\n",
    "# 正解率\n",
    "epoch_acc = epoch_corrects.double() / len(test_dataloader.dataset)\n",
    "\n",
    "print('テストデータ{}個での正解率：{:.4f}'.format(len(test_dataloader.dataset),epoch_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  3.  3.  3.  2.  2.  1.  1. -0.  0.  1.]\n",
      "[3 3 3 2 2 1 1 1 0 0 0]\n",
      "[[2 1 0 0]\n",
      " [0 2 1 0]\n",
      " [0 0 1 1]\n",
      " [0 0 0 3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "preds_heat = np.array(preds.cpu())\n",
    "trues_heat = np.array(torch.argmax(labels.data, dim=1).cpu())\n",
    "# preds_heat[0] = \"3A\"\n",
    "print(preds_heat)\n",
    "print(trues_heat)\n",
    "\n",
    "heat = confusion_matrix(trues_heat, preds_heat)\n",
    "print(heat)\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"   # 使用するフォント\n",
    "plt.rcParams[\"font.size\"] = 20        \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "xtics = [\"2C\", \"2B\", \"2A\", \"3\"]\n",
    "ytics = [\"2C\", \"2B\", \"2A\", \"3\"]\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(heat, annot=True, xticklabels=xtics, yticklabels=ytics, cmap=\"Blues\", cbar=False)\n",
    "# sns.heatmap(heat, annot=True, cmap=\"Blues\", cbar=False)\n",
    "#*以下2行がポイント*  X,Y軸ラベルを追加\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "#グラフをはみ出さないようにして画面に出力\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"nn-heatmap_4.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1996f9657f0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# サンプルごとに代償動作の度合いをセッティングしてみる\n",
    "preds = np.array(outputs.cpu())\n",
    "ans = np.array(labels_true.cpu())\n",
    "plt.scatter(preds, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_weight = np.array(attn_weights1[15, 0, 1:]).reshape(1, -1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 1))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(extract_weight, cmap='OrRd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "extract_data = np.array(X[19, 1:, 2]).flatten()\n",
    "print(extract_data.shape)\n",
    "\n",
    "\n",
    "time = np.linspace(0, 100, 100)\n",
    "fig, ax = plt.subplots(2, 1, gridspec_kw={'height_ratios': [6, 1]}, figsize=(15,10))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.lineplot(time, extract_data, ax=ax[0])\n",
    "sns.heatmap(extract_weight, cmap='OrRd', cbar=False, ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data = np.array(attn_weights1[:, 0, :])\n",
    "print(data.shape)\n",
    "data = data.reshape(attn_weights1.shape[0], -1)\n",
    "\n",
    "# print(outputs)\n",
    "print(data.shape)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 20))\n",
    "# Set the palette using the name of a palette:\n",
    "sns.heatmap(data, cmap='OrRd')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data[0])):\n",
    "    print(data[0,i], end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_trained.net_Attention_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelの読み込みだけ\n",
    "# 保存したモデルパラメータの読み込み\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net_trained = TransformerClassification().to(device)\n",
    "\n",
    "net_trained.load_state_dict(torch.load('highacc2.pth'))\n",
    "# print('読み込み後のモデル:\\n', model2.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(net_trained.state_dict(), 'highacc3.pth')\n",
    "\n",
    "# 新しいモデル\n",
    "model2 = TransformerClassification().to(device)\n",
    "print('新しいモデル:\\n', model2.state_dict())\n",
    "\n",
    "# 保存したモデルパラメータの読み込み\n",
    "model2.load_state_dict(torch.load('highacc3.pth'))\n",
    "print('読み込み後のモデル:\\n', model2.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention weight の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "print(data)\n",
    "print(data.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 同時に入れるデータも作成する\n",
    "# これは時系列スタンプ．0〜100がサンプル数だけ作られる\n",
    "stamp_row = [i%data.shape[1] for i in range(data.shape[0] * data.shape[1])]\n",
    "\n",
    "# いつ撮影されたのかのスタンプ\n",
    "l_date_name = np.array(df_annotate['date'].unique())\n",
    "date_row = []\n",
    "for item in l_date_name:\n",
    "    for i in range(data.shape[1]):\n",
    "        date_row.append(item)\n",
    "        \n",
    "# アテンションウエイト\n",
    "attn_weight = data.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attn = pd.DataFrame()\n",
    "df_attn['date'] = date_row\n",
    "df_attn[\"stamp\"] = stamp_row\n",
    "df_attn[\"attn_weight\"] = attn_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attn.to_excel('/Users/kento/kuhp/experiment/attention_weights.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_attn['date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "timeseries_transformer_classification.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/keras-team/keras-io/blob/master/examples/timeseries/ipynb/timeseries_classification_transformer.ipynb",
     "timestamp": 1636355482830
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
